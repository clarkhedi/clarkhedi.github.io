[{"title":"Hexo Start","date":"2022-11-18T06:12:23.780Z","path":"2022/11/18/hexo-start/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://clarkhedi.github.io/tags/Hexo/"}]},{"title":"2021年，教程 | 个性化定制你的 GitHub 主页","date":"2021-06-16T20:09:55.000Z","path":"2021/06/16/ge-xing-hua-ding-zhi-ni-de-github-zhu-ye/","text":"前言Github称为全球最大的”同性交友”平台，因为这里是程序员的天堂，在这里，很多程序员利用工作之余，无私的贡献了很多优秀的开源代码和框架。开源是一个利人利己的事，一方面，其他开发者在开发某个功能或者实现某个方案的时候，可以借鉴你的思路和经验，甚至是使用你已经封装好的开源库，很方便快速的完成功能开发，另一方面，可以吸引更多优秀的开发者共同参与一个开源项目的开发，也是一个彼此学习和成长的机会。 Github 也是一个很好的展示你自己的地方，比如我自己，通过Github,经常就会收到BAT的面试邀约，他们的招聘，也喜欢从Github这个社区来找人，通过贡献的开源项目，更能展现一个开发者的能力。那么如何让其人能通过Github更快认识你呢？你的Github主页就显得至关重要了！ 首先我们来看一下JayZhou技术大佬的最终效果 下面是 Profile 的制作教程。 创建 Repo首先新建一个仓库，仓库的名称需要和用户名一致。如果填写正确，会出现绿色的提示框，提示你正在创建一个 GitHub profile。 注意将仓库仓库设置为 Public，并选择初始化这个仓库Add一个 README 文件，点击 Create repository 按钮创建仓库。 创建好后，页面会自动跳转到仓库主页，默认的README.md有一句话：Hi there 👋，如下： 这个时候再回到个人主页，神奇的事情发生了！右边的顶部就会出现同名仓库的 README 的内容，如下： 然后再进入这个仓库中点击左上角的 Edit README 开始制作。 定制页面内容方面，GitHub 给出了默认的欢迎内容，同时提供了一些建议和提示，这一部分默认被注释掉了。 你可以删除这个注释，或者按照这个模板来进行编写相关的介绍。另外也可选择一些更加个性化的展示方式。 那么如何制作文章开头JayZhou技术大佬的那种效果图呢？这就得介绍了一个工具了，它就是 github-readme-stats，Github地址为：https://github.com/anuraghazra/github-readme-stats，里面有很多教程例子。 仓库统计信息github-readme-stats 可以在你的 README 中 获取动态生成的 GitHub 统计信息！ 要显示上面的那种GitHub 统计卡片，只需要将下面这行代码复制到你的 markdown 文件中，将?username= 的值更改为你的 GitHub 用户名，也就是你刚刚创建好的仓库名。 1[![Anurag&#39;s github stats](https:&#x2F;&#x2F;github-readme-stats.vercel.app&#x2F;api?username&#x3D;anuraghazra)](https:&#x2F;&#x2F;github.com&#x2F;anuraghazra&#x2F;github-readme-stats) 此外，还可以选择显示的主题模式，在后面调用?theme=THEME_NAME 参数就可以了，内置了很多。THEME_NAM参数有：dark, radical, merko, gruvbox, tokyonight, onedark, cobalt, synthwave, highcontrast, dracula。具体可以查看https://github.com/anuraghazra/github-readme-stats，里面有很多教程例子。 如果你熟悉 Markdown 语法或者 HTML 的话，你还可以在此基础上进行样式上的设置。 使用徽标使用徽标可以使得主页更加吸引眼球，可以在 shield.io这个网站，即 https://shields.io/ 去搜索找到你想要的图标。 徽标相关可以参考 @moshfiqrony 的个人介绍。 更多更多玩法，你在 awesome-github-profile-readme 仓库（https://github.com/abhisheknaiidu/awesome-github-profile-readme）中找到 Profile 的更多玩法。还有https://awesomegithubprofile.tech/这个页面里有很多技术大佬的展示。 总结Github这个隐藏的功能非常棒！有了它，我们就能打造个性化或者说是炫酷的个人主页了。上面只是一个示例，也可以根据自己的喜好，放不同的内容。如果你正在找工作，甚至可以放你的整个简历到这里。 参考博客 https://blog.csdn.net/zwluoyuxi/article/details/107600491 https://blog.csdn.net/qq_37954086/article/details/107947088","tags":[{"name":"GitHub","slug":"GitHub","permalink":"http://clarkhedi.github.io/tags/GitHub/"}]},{"title":"优美的Sublime Text","date":"2021-06-07T22:41:55.000Z","path":"2021/06/07/you-mei-de-sublime-text/","text":"Sublime Text 是一个轻量、简洁、高效、跨平台的编辑器。 Sublime 的下载与安装直接去sublime的官网：http://www.sublimetext.com/ 下载Sublime Text 4，或者https://www.423down.com/4966.html这个网站上下载。 然后通过下载得到的.exe文件进行安装，可以自行选择安装的路径，安装过程很简单，直接按照默认选项进行安装即可，其中注意如下图：（记得勾选Add to explorer context menu,这样在右键单击文件时就可以直接使用Sublime Text打开。） sublime本身是免费使用的，但不购买的话标题栏上会出现UNREGISTERD，你也可以使用破解的方法消除它，如 完美永久破解最新Sublime Text 4 Build 4107的方法： 使用浏览器打开网站：https://hexed.it/ 在网站中打开Sublime Text安装目录并选择文件：sublime_text.exe 搜索80 38 00并更改为FE 00 90（第一个匹配） 另存文件到本地，即备份sublime_text.exe文件（只需重命名） 将修改过的sublime_text.exe复制到sublime text 4安装目录中 参考: https://shimo.im/docs/Xvc3vPTtKXhPtdHJ/read https://www.w3cschool.cn/sublimetext/xhoazozt.html 安装Package ControlSublime Text支持大量插件，如何找到并管理这些插件就成了一个问题，Package Control正是为了解决这个问题而出现的，利用它我们可以很方便的浏览、安装和卸载Sublime Text中的插件。 首先说一下以前老版本(Sublime Text 2和3)中的Package Control安装，比如在Sublime Text 3中的安装流程如下： 使用**Ctrl + `**打开Sublime Text控制台。 将下面的代码粘贴到控制台里： 1import urllib.request,os,hashlib; h = &#x27;7183a2d3e96f11eeadd761d777e62404&#x27; + &#x27;e330c659d4bb41d3bdf022e94cab3cd0&#x27;; pf = &#x27;Package Control.sublime-package&#x27;; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( &#x27;http://sublime.wbond.net/&#x27; + pf.replace(&#x27; &#x27;, &#x27;%20&#x27;)).read(); dh = hashlib.sha256(by).hexdigest(); print(&#x27;Error validating download (got %s instead of %s), please try manual install&#x27; % (dh, h)) if dh != h else open(os.path.join( ipp, pf), &#x27;wb&#x27; ).write(by) 等待Package Control安装完成。之后使用Ctrl + Shift + P打开命令板，输入PC应出现Package Control：Install Package 成功安装Package Control之后，我们就可以方便的安装使用Sublime Text的各种插件。 本文主要讲的是安装Sublime Text 4，所以在安装Package Control时，不需要在控制台里输入以上那段代码来进行安装Package Control了，直接Ctrl + Shift + P选择Install Package Control按回车进行安装，成功提示如下： 你也可以进入Package Control的官网，里面有详细的安装教程(https://packagecontrol.io/installation)，还有很多主题。这里我选择的是`Theme - Spacegray，其中官方这个主题的字体选择的是*[**Source Code Pro**](https://github.com/adobe-fonts/source-code-pro)*（配置字体参考https://www.jianshu.com/p/1d5e1aaeb3f6），且包括三种风格[Spacegray，Spacegray Light，Spacegray Eighties]，我选择的是Spacegray Eighties，然后你在[官网](https://packagecontrol.io/)搜索Theme - Spacegray`，这个里面会有详细的安装教程与配置。如： 按照给的教程配置好以后记得重启sublime就可以看到自己配置的喜欢主题了。当然你也可以直接在Sublime Text中用鼠标点击 Preferences -&gt; Select Theme/Select Color Scheme直接挑选主题风格与颜色风格。 图标库如：安装A File Icon图标。 ​ 按下Ctrl + Shift + P后选择Package Control：Install Package，搜索A File Icon，选中按回车即可安装。 常用插件 SideBarTools：扩展左侧面板 https://packagecontrol.io/packages/SideBarTools SideBarEnhancements：扩展左侧面板(功能更多) https://packagecontrol.io/packages/SideBarEnhancements AdvancedNewFile：快速创建文件，使用ctrl+alt+n就可以快速创建文件 https://packagecontrol.io/packages/AdvancedNewFile Local History：本地历史记录 https://packagecontrol.io/packages/Local%20History ChineseLocalizations 可以选择中文 https://packagecontrol.io/packages/ChineseLocalizations ConvertToUTF8 解决中文乱码问题 程序员常用插件 emmet：快速编写html/css https://docs.emmet.io DocBlockr：代码注释提示插件 https://packagecontrol.io/packages/DocBlockr BracketHighlighter：以高亮显示配对括号以及当前光标所在区域 https://packagecontrol.io/packages/BracketHighlighter AutoPEP8：格式化Python代码 https://packagecontrol.io/packages/AutoPEP8 SublimeCodeIntel：提供了很多IDE提供的功能，例如代码自动补齐，快速跳转到变量定义，在状态栏显示函数快捷信息等 https://packagecontrol.io/packages/SublimeCodeIntel AutoFileName：自动补全文件路径 https://packagecontrol.io/packages/AutoFileName PackageResourceViewer：修改主题字体颜色和大小，以及侧边栏字体大小 https://packagecontrol.io/packages/PackageResourceViewer sublimeTmpl：自定义自己的模板 https://packagecontrol.io/packages/SublimeTmpl Anaconda：python代码自动补全和提示 https://packagecontrol.io/packages/Anaconda Jedi：代码自动补全和提示(比Anaconda轻巧) Terminal：快捷键 ctrl+shift+T呼出当前文件路径的控制台 https://packagecontrol.io/packages/Terminal SublimeLinter：错误语法提示 https://packagecontrol.io/packages/SublimeLinter SublimeREPL：利用命令行进行一些编码实验 https://packagecontrol.io/packages/SublimeREPL 对于Anaconda的配置和SublimeLinter配置（参考https://www.cnblogs.com/zhaof/p/8126306.html）如下： Default settings中修改如下： 1&quot;python_interpreter&quot;: &quot;D:/miniconda3/envs/hd/python.exe&quot; //（此路径为你的python路径）。 User settings中配置如下： 123456789 &#123; &quot;python_interpreter&quot;:&quot;D:/miniconda3/envs/hd/python.exe&quot;, //此路径为你的python路径 &quot;suppress_word_completions&quot;:true, &quot;suppress_explicit_completions&quot;:true, &quot;comlete_parameters&quot;:true, &quot;swallow_startup_errors&quot;:true, &quot;anaconda_linting&quot;:false, &quot;pep8&quot;: false&#125; 对于SublimeREPL，配置编译和InteractiveConsole的快捷键：选择Preferences -&gt; Key Bindings，然后在右边输入如下代码： 12345678910111213141516171819202122[ &#123; &quot;keys&quot;:[&quot;f5&quot;], &quot;caption&quot;: &quot;SublimeREPL: Python - RUN current file&quot;, &quot;command&quot;: &quot;run_existing_window_command&quot;, &quot;args&quot;: &#123; &quot;id&quot;: &quot;repl_python_run&quot;, &quot;file&quot;: &quot;config/Python/Main.sublime-menu&quot; &#125; &#125;, &#123; &quot;keys&quot;:[&quot;f6&quot;], &quot;caption&quot;: &quot;SublimeREPL: Python - IPython&quot;, &quot;command&quot;: &quot;run_existing_window_command&quot;, &quot;args&quot;: &#123; &quot;id&quot;: &quot;repl_python_ipython&quot;, &quot;file&quot;: &quot;config/Python/Main.sublime-menu&quot; &#125; &#125;] 对于左边的py文件，按F5出现如下中间的结果，按F6出现右边的InteractiveConsole。 对于sublimeTmpl，配置一键生成头注释模板的快捷键 1234&#123; &quot;caption&quot;: &quot;Tmpl: Create python&quot;, &quot;command&quot;: &quot;sublime_tmpl&quot;, &quot;keys&quot;: [&quot;ctrl+alt+p&quot;], &quot;args&quot;: &#123;&quot;type&quot;: &quot;python&quot;&#125;&#125;, 配置python3环境打开软件后点击 Tools-&gt;Build System-&gt;New Build System。 点击New Build System后，会生成一个空的配置文件，将以下配置文件复制到该文件中，记得改一下第一行的python.exe文件的目录，每个人的位置不一样。然后按ctrl+s保存在默认路径，不要改路径，文件名命名随你。代码命令如下： 12345678&#123; &quot;cmd&quot;: [&quot;D://Python/python.exe&quot;,&quot;-u&quot;,&quot;$file&quot;], &quot;file_regex&quot;: &quot;^[ ]*File \\&quot;(...*?)\\&quot;, line ([0-9]*)&quot;, &quot;selector&quot;: &quot;source.python&quot;, //通过下面两句，使编码一致，都是utf8，避免中文乱码的问题出现 &quot;encoding&quot;: &quot;utf-8&quot; , &quot;env&quot;: &#123;&quot;PYTHONIOENCODING&quot;: &quot;utf8&quot;&#125;&#125; 配置字体(.ttf)Source Code Pro参考：https://www.jianshu.com/p/1d5e1aaeb3f6，进行配置。 Ubuntu font：https://design.ubuntu.com/font/。 修改侧边栏字体大小参考：https://www.jianshu.com/p/906c48f2da5c，需要安装 **PackageResourceViewer **插件。 修改侧边栏字体大小(对应主题) 打开 Command Palette （快捷键 Ctrl+Shift+P ） 输入 PackageResourceViewer: Open Resource 回车在包列表中输入 Theme - Spacegray 回车再输入Spacegray.sublime-theme 回车在打开的文件中搜索 “class”: “sidebar_label”在 “class”: “sidebar_label” 后面追加如下代码：”font.size”:16, // 将字体大小设置为16。保存，修改完成。 修改行间距 在Spacegray.sublimt-theme 中搜索”class”: “sidebar_tree” 根据需要调整”row_padding”: [8, 8], 的值即可。 // 参数说明: 第一个参数为文字与左侧边框的距离, 第二个参数为行间距。 修改文档标题字体大小 在Spacegray.sublimt-theme 中搜索”tab_label”调整”font.size”: 13。 删除包按下Ctrl + Shift + P输入remove选择Package Control：Remove Package。 函数快速查找默认情况下，Sublime Text支持函数快速查找，按Ctrl+Shift+R打开查找面板，就可以快速定位函数所在的文件，如果安装了emmet插件 将会失效，我们需要做以下操作进行修复。 编辑emmet插件配置项： 1&#123;&quot;disabled_keymap_actions&quot;: &quot;reflect_css_value&quot;&#125; 函数跟踪鼠标移动到函数上面，会自动显示方法的文件列表。或者按F12键显示函数的文件列表。 快捷键使用快捷键可以显著提高程序员的开发效率，所以是有必要掌握的。 搜索文件：ctrl+p 输入文件名 搜索函数/方法：ctrl+p 输入文件名@方法名 如 Process@show_img 跳转到指定行：ctrl+p 输入文件名:行号，只输入:时在当前文件跳转 查找当前文件方法：ctrl+r 查找当前项目文件中的所有方法：ctrl+shift+r 返回/前进编辑位置：alt + -、alt + shift + - 切换标签页：ctrl+PgUp、ctrl+PgDp 选中单词：ctrl+d 连续按会选中页面中所有单词，以实现批量编辑 以单词为单位快速移动光标：ctrl + ⬅、ctrl + ➡ 选中当前行：ctrl+L Ctrl+Shift+L：选择多行 跳转到第几行：ctrl+g Ctrl+W：关闭当前打开文件 Ctrl+Shift+W：关闭所有打开文件 跳转到对应括号：ctrl+m 开关侧栏：ctrl+K+B 选中当前括号内容，重复(如按两次) 可选着括号本身：ctrl+shift+m 注释当前html标签块：ctrl+shift+/ 专注编写模式：shift+F11 分屏显示：atl+shift+数字 ctrl+Enter 在下一行插入新行，即使光标不在行尾也能快速向下插入一个空行 ctrl+Shift+Enter 在上一行插入新行，即使光标不在行首也能快速向上插入一个空行 ctrl+Shift+[ 选中代码，按下快捷键，折叠代码 ctrl+Shift+] 选中代码，按下快捷键，展开代码 最后附上我的配置123456789101112131415161718192021222324252627282930313233343536&#123; &quot;update_check&quot;: false, //禁止更新 &quot;ignored_packages&quot;: [ &quot;Vintage&quot;, ], // 主题风格&quot;theme&quot;: &quot;Spacegray.sublime-theme&quot;,&quot;color_scheme&quot;: &quot;Packages/Theme - Spacegray/base16-eighties.dark.tmTheme&quot;,// 设置字体，以便阅读&quot;font_face&quot;: &quot;Source Code Pro&quot;,// 字体大小&quot;font_size&quot;: 14,// 使光标闪动更加柔和&quot;caret_style&quot;: &quot;phase&quot;,// 高亮当前行&quot;highlight_line&quot;: true,// 高亮有修改的标签&quot;highlight_modified_tabs&quot;: true,// 设置tab的大小为2&quot;tab_size&quot;: 4,// 使用空格代替tab&quot;translate_tabs_to_spaces&quot;: true,// 添加行宽标尺&quot;rulers&quot;: [80, 100],// 保存时自动去除行末空白&quot;trim_trailing_white_space_on_save&quot;: true,// 保存时自动增加文件末尾换行&quot;ensure_newline_at_eof_on_save&quot;: true,//设置保存时自动转换&quot;expand_tabs_on_save&quot;: true,//对于Jedi和Anaconda中按tab键进行自动填充&quot;auto_complete_commit_on_tab&quot;: true,&#125; 参考卸载Notepad++！事实已证明，它更牛逼…… 后盾人在线文档 Sublime Text3 搭建python环境 sublime text 3 修改侧边栏字体大小 让你用sublime写出最完美的python代码–windows环境","tags":[{"name":"Python","slug":"Python","permalink":"http://clarkhedi.github.io/tags/Python/"}]},{"title":"PyQt5学习笔记（一）","date":"2021-05-08T19:22:56.000Z","path":"2021/05/08/pyqt5-xue-xi-bi-ji-yi/","text":"最近几天新入坑了python的GUI设计，回想一下我为什么会入门这个？？？好像是在知乎上看到你都用 Python 来做什么？这篇文章，看到有人回答说将python打包成exe文件。 PyQt5简介PyQt5是作为一套Python模块实现的。它有超过620个的类和6000个函数和方法。它是一个跨平台的工具集,可以运行在所有的主流操作系统上，包括Unix, Windows和Mac OS。PyQt5中的类可划分为以下几个模块，包括： QtCore模块包含了核心非GUI功能.这个模块是用于时间、文件和目录、变量数量类型、数据流、URLs、mime(多用途因特网邮件扩展)类型、线程和进程。 QtGui模块包含了窗口系统集成、事件处理、2D绘画、基本成像、字体和文本. QtWidgets模块包含了一系列UI元素,用于创建典型的桌面风格用户接口. QtMultimedia包含了处理多媒体内容和访问摄像机、无线电等功能的APIs. QtBluetooth模块包含了设备扫描和设备接接与互动. QtNetwork模块包含了网络编程的类.这些类用于TCP/IP和UDP客户端、服务端编程,使之网络编程更加方便和快捷. QtPositioning模块包含了使用一系列包括卫星、Wi-Fi或文本文件在内的可能源变量来决定位置的类. Enginio模块包含了用于访问Qt云服务管理应用运行时的客户端的库. QtWebSockets模块包含了实现WebSocket协议的类. QtWebKit包含了基于WebKit2库的实现网络浏览器的类. QtWebKitWidgets包含了基于WebKit1库的实现网络浏览器的类,它是用在基于应用的QtWidgets上的. QtXml包含了用于XML文件的类.这个模块提供了SAX和DOM接口的实现. QtSvg模块提供了用于显示SVG文件内容的类.SVG(Scalable Vector Graphics)是用于描述在XML中二维图像和图像应用的语言. QtSql模块提供了用于数据库的类. QtTest包含了PyQt5的单元测试功能. PyQt5安装及Qt Designer介绍pyqt5安装使用Anaconda，其实Anaconda里面是含有pyqt的，在环境里搜索可以看到，但是针对实际开发，并没有全部的qt5工具，所以需要再次重新安装PyQt。这里选择PyQt5，通过创建conda环境，然后在环境中使用如下命令进行PyQt5的安装。 1pip install PyQt5 安装常用的Qt工具使用如下命令进行安装，工具中包含有Qt designer。 1pip install PyQt5-tools 在PyQt中编写UI界面可以直接通过代码来实现，也可以通过Qt Designer来完成。Qt Designer的设计符合MVC的架构，其实现了视图和逻辑的分离，从而实现了开发的便捷。 Qt Designer中的操作方式十分灵活，其通过拖拽的方式放置控件可以随时查看控件效果。 Qt Designer生成的.ui文件（实质上是XML格式的文件）也可以通过pyuic5工具转换成.py文件。 Qt Designer随PyQt5-tools包一起安装，其安装路径在“Python安装路径\\Lib\\site-packages\\pyqt5-tools”下。 关于安装新版PyQt5和PyQt5_tools后配置QtDesigner是找不到designer.exe的问题。按照网上的操作方法，装完PyQt5和PyQt5_tools后，配置QtDesigner时找不到designer.exe；按网上的路径查找的话根本就找不到；其实新版本安装的路径不是网上说的那种，已经换地方了。例如我的designer.exe路径是：D:\\Program Files\\Miniconda3\\envs\\pyqt05\\Lib\\site-packages\\qt5_applications\\Qt\\bin\\designer.exe。 若要启动Qt Designer可以直接到上述目录下，双击designer.exe打开Qt Designer；或将上述路径加入环境变量，在命令行输入designer打开；或在PyCharm中将其配置为外部工具打开。 下面以PyCharm为例，讲述PyCharm中Qt Designer的配置方法。 配置Pycharm推荐使用在PyCharm中将其配置为外部工具打开，主要包括添加以下三个外部工具。 工具 *.exe 说明 Qt Desinger *./designer.exe 打开Qt Designer界面，对软件的界面进行设计 PyUIC *./python.exe 将Qt Designer设计的UI文件转换为.py文件 PyRCC *./pyrcc5.exe 将资源文件(如图片等)转换成python代码能识别的文件 打开Pycharm，找到Settings，根据上图所示，点击＋号添加外部工具。 添加Qt Designer 位置 内容 Name 随意设置，方便记忆即可 Program designer.exe路径,一般在anaconda配置环境中的pyqt5_tools中，如：D:\\Program Files\\Miniconda3\\envs\\pyqt05\\Lib\\site-packages\\pyqt5_tools\\designer.exe Arguments $FileDir$\\$FileName$或者为空(不设置) Working dierctory $FileDir$ 添加PyUIC 位置 内容 Name 随意设置，方便记忆即可 Program python.exe路径,一般在anaconda配置的环境中，如：D:\\Program Files\\Miniconda3\\envs\\pyqt05\\python.exe Arguments -m PyQt5.uic.pyuic $FileName​$ -o $FileNameWithoutExtension$.py Working dierctory $FileDir$ 添加PyRCC 位置 内容 Name 随意设置，方便记忆即可 Program pyrcc5.exe路径,一般在anaconda配置的环境中的Scripts中，如：D:\\Program Files\\Miniconda3\\envs\\pyqt05\\Scripts\\pyrcc5.exe Arguments $FileName​$ -o $FileNameWithoutExtension$_rc.py Working dierctory $FileDir$ Qt Designer界面简介刚打开的Qt Designer，会弹出如下图所示的窗口。 要想创建新的Forms，给出了5个模板，其中Widget与Main Window最为常用。这里我们选择创建一个Main Window。 上面界面的最左侧菜单为Widget Box，且Widget Box中包含PyQt5中的所有Widget组件，我们可以从左侧的Widget Box中拖拽出诸如Button、View和Input等组件到中间的窗口(我们刚刚创建的Main Window)中。点击Form -&gt; Preview（快捷键为Ctrl+R）则可以预览我们设计好的界面，也可以用Preview In来选择在相应的主题风格下预览。 接下来，我们试着拖拽一个Label与Button进入主窗口（Main Window）。 此时在右上角的Object Inspector（对象查看器）中可以看到主窗口中的已放置的对象（label与pushButton）以及其相对应的Qt类。 以Label为例，此时我们点击Main Window中的label或是在Object Inspector中选取label后，查看右侧的一块区域——Property Editor（属性编辑器）。 其主要包含属性有如下： PS：将minimumSize和maximumSize设为一样的数值之后，则窗口的大小固定。 最右下角的部分则为Resource Browser（资源浏览器），资源浏览器中可以添加相应地如图片素材，作为Label或Button等控件的背景图片等。 Qt Designer的UI文件使用Qt Designer设计保存的文件为.ui格式的文件。通过保存并使用记事本等软件打开，我们可以看到.ui文件的内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;ui version&#x3D;&quot;4.0&quot;&gt; &lt;class&gt;MainWindow&lt;&#x2F;class&gt; &lt;widget class&#x3D;&quot;QMainWindow&quot; name&#x3D;&quot;MainWindow&quot;&gt; &lt;property name&#x3D;&quot;geometry&quot;&gt; &lt;rect&gt; &lt;x&gt;0&lt;&#x2F;x&gt; &lt;y&gt;0&lt;&#x2F;y&gt; &lt;width&gt;800&lt;&#x2F;width&gt; &lt;height&gt;600&lt;&#x2F;height&gt; &lt;&#x2F;rect&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;windowTitle&quot;&gt; &lt;string&gt;MainWindow&lt;&#x2F;string&gt; &lt;&#x2F;property&gt; &lt;widget class&#x3D;&quot;QWidget&quot; name&#x3D;&quot;centralwidget&quot;&gt; &lt;widget class&#x3D;&quot;QLabel&quot; name&#x3D;&quot;label&quot;&gt; &lt;property name&#x3D;&quot;geometry&quot;&gt; &lt;rect&gt; &lt;x&gt;240&lt;&#x2F;x&gt; &lt;y&gt;80&lt;&#x2F;y&gt; &lt;width&gt;72&lt;&#x2F;width&gt; &lt;height&gt;15&lt;&#x2F;height&gt; &lt;&#x2F;rect&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;text&quot;&gt; &lt;string&gt;TextLabel&lt;&#x2F;string&gt; &lt;&#x2F;property&gt; &lt;&#x2F;widget&gt; &lt;widget class&#x3D;&quot;QPushButton&quot; name&#x3D;&quot;pushButton&quot;&gt; &lt;property name&#x3D;&quot;geometry&quot;&gt; &lt;rect&gt; &lt;x&gt;240&lt;&#x2F;x&gt; &lt;y&gt;120&lt;&#x2F;y&gt; &lt;width&gt;93&lt;&#x2F;width&gt; &lt;height&gt;28&lt;&#x2F;height&gt; &lt;&#x2F;rect&gt; &lt;&#x2F;property&gt; &lt;property name&#x3D;&quot;text&quot;&gt; &lt;string&gt;PushButton&lt;&#x2F;string&gt; &lt;&#x2F;property&gt; &lt;&#x2F;widget&gt; &lt;&#x2F;widget&gt; &lt;widget class&#x3D;&quot;QMenuBar&quot; name&#x3D;&quot;menubar&quot;&gt; &lt;property name&#x3D;&quot;geometry&quot;&gt; &lt;rect&gt; &lt;x&gt;0&lt;&#x2F;x&gt; &lt;y&gt;0&lt;&#x2F;y&gt; &lt;width&gt;800&lt;&#x2F;width&gt; &lt;height&gt;26&lt;&#x2F;height&gt; &lt;&#x2F;rect&gt; &lt;&#x2F;property&gt; &lt;&#x2F;widget&gt; &lt;widget class&#x3D;&quot;QStatusBar&quot; name&#x3D;&quot;statusbar&quot;&#x2F;&gt; &lt;&#x2F;widget&gt; &lt;resources&#x2F;&gt; &lt;connections&#x2F;&gt;&lt;&#x2F;ui&gt; 从.ui文件的第一行我们便能看出，其实质是一个XML文件。ui文件中存放了在主窗口中的一切控件的相关属性。使用XML文件来存储UI文件，具有高可读性和移植性，因此我们可以方便地将.ui文件转换到.py文件，从而使得我们可以使用Python语言在设计的GUI上面编程。 将.ui文件转换为.py文件pyuic可以将.ui文件转换为为.py文件，实现此过程的方法有三个： 方法一：使用Python命令 1python -m PyQt5.uic.pyuic demo.ui -o demo.py 方法二：直接调用pyuic5命令 1pyuic5 -o demo.py demo.ui 方法三：如果在PyCharm中设置了PyUIC扩展插件 则直接在PyCharm中，找到.ui文件，右键 打开菜单找到External Tools-&gt;PyUIC。点击PyUIC之后，我们在相应工程目录下会产生一个.py文件。（注意，.ui文件必须存放在我们的External Tools中设置的相应项目目录下） 转换完成之后，打开.py文件如下。观察这个文件，可以看到如果不通过Qt Designer来制作界面的话，我们将会一次次地调试程序，来讲按钮和Label等放在合适的位置，这将是极其痛苦的过程。而通过Qt Designer，我们可以快速地制作UI，并生成Python的代码，从而实现快速地UI的开发。 123456789101112131415161718192021222324252627282930313233343536373839# -*- coding: utf-8 -*-# Form implementation generated from reading ui file &#x27;mainWindow.ui&#x27;## Created by: PyQt5 UI code generator 5.10.1## WARNING! All changes made in this file will be lost!from PyQt5 import QtCore, QtGui, QtWidgetsclass Ui_MainWindow(object): def setupUi(self, MainWindow): MainWindow.setObjectName(&quot;MainWindow&quot;) MainWindow.resize(800, 600) self.centralwidget = QtWidgets.QWidget(MainWindow) self.centralwidget.setObjectName(&quot;centralwidget&quot;) self.label = QtWidgets.QLabel(self.centralwidget) self.label.setGeometry(QtCore.QRect(240, 80, 72, 15)) self.label.setObjectName(&quot;label&quot;) self.pushButton = QtWidgets.QPushButton(self.centralwidget) self.pushButton.setGeometry(QtCore.QRect(240, 120, 93, 28)) self.pushButton.setObjectName(&quot;pushButton&quot;) MainWindow.setCentralWidget(self.centralwidget) self.menubar = QtWidgets.QMenuBar(MainWindow) self.menubar.setGeometry(QtCore.QRect(0, 0, 800, 26)) self.menubar.setObjectName(&quot;menubar&quot;) MainWindow.setMenuBar(self.menubar) self.statusbar = QtWidgets.QStatusBar(MainWindow) self.statusbar.setObjectName(&quot;statusbar&quot;) MainWindow.setStatusBar(self.statusbar) self.retranslateUi(MainWindow) QtCore.QMetaObject.connectSlotsByName(MainWindow) def retranslateUi(self, MainWindow): _translate = QtCore.QCoreApplication.translate MainWindow.setWindowTitle(_translate(&quot;MainWindow&quot;, &quot;MainWindow&quot;)) self.label.setText(_translate(&quot;MainWindow&quot;, &quot;TextLabel&quot;)) self.pushButton.setText(_translate(&quot;MainWindow&quot;, &quot;PushButton&quot;)) 使用转换的.py文件进行界面显示然而，此时若运行这个转换好的Python文件是无法显示任何窗口的。因为这个Python文件只有定义主窗口以及其控件的代码，并没有程序入口的代码。为了秉持视图与逻辑分离的原则，我们再编写一个新的脚本来调用这个文件，并且创建一个窗口。 12345678910111213141516import sysfrom PyQt5.QtWidgets import QApplication, QMainWindowfrom mainWindow import *class MyWindow(QMainWindow, Ui_MainWindow): def __init__(self, parent=None): super(MyWindow, self).__init__(parent) self.setupUi(self)if __name__ == &#x27;__main__&#x27;: app = QApplication(sys.argv) myWin = MyWindow() myWin.show() sys.exit(app.exec_()) 通过上述代码，我们继承了QMainWindow和Ui_MainWindow类，使用构造方法构造主窗口，并定义了程序的入口，通过创建QApplication对象来创建Qt窗口。其运行结果如下： PyQT5：ImportError: DLL load failed: 找不到指定的模块可以选择重新安装PyQt5： 12pip uninstall PyQt5pip install PyQt5 详细请看（已解决）PyQT5：ImportError: DLL load failed: 找不到指定的模块或者见参考博客3。 参考博客： https://www.jianshu.com/p/5b063c5745d0 https://blog.csdn.net/hon8215/article/details/110673015 https://blog.csdn.net/lxh19920114/article/details/103819279 https://blog.csdn.net/qq_35451572/article/details/85229408","tags":[{"name":"PyQt5","slug":"PyQt5","permalink":"http://clarkhedi.github.io/tags/PyQt5/"},{"name":"GUI","slug":"GUI","permalink":"http://clarkhedi.github.io/tags/GUI/"}]},{"title":"Kaiming He初始化的学习","date":"2021-04-17T20:35:30.000Z","path":"2021/04/17/kaiming-he-chu-shi-hua-de-xue-xi/","text":"在CNN的训练中，权重初始化是一个比较关键的点。好的权重初始化可以让网络的训练过程更加稳定和高效。本文为大家介绍了kaiming初始化以及详细的推导过程，希望可以让大家更好的理解CNN初始化。 以下文章来源于公众号GiantPandaCV 1. 为什么需要好的权重初始化网络训练的过程中, 容易出现梯度消失(梯度特别的接近0)和梯度爆炸(梯度特别的大)的情况,导致大部分反向传播得到的梯度不起作用或者起反作用. 研究人员希望能够有一种好的权重初始化方法: 让网络前向传播或者反向传播的时候, 卷积的输出和前传的梯度比较稳定. 合理的方差既保证了数值一定的不同, 又保证了数值一定的稳定.(通过卷积权重的合理初始化, 让计算过程中的数值分布稳定) 2. kaiming初始化的两个方法2.1 先来个结论 前向传播的时候, 每一层的卷积计算结果的方差为1. 反向传播的时候, 每一层的继续往前传的梯度方差为1(因为每层会有两个梯度的计算, 一个用来更新当前层的权重, 一个继续传播, 用于前面层的梯度的计算.) 2.2 再来个源码方差的计算需要两个值：gain和fan。gain值由激活函数决定。fan值由权重参数的数量和传播的方向决定。fan_in表示前向传播，fan_out表示反向传播。 12345678def kaiming_normal_(tensor, a=0, mode=&#x27;fan_in&#x27;, nonlinearity=&#x27;leaky_relu&#x27;): fan = _calculate_correct_fan(tensor, mode) # 通过mode判断是前向传播还是反向传播, 生成不同的一个fan值. gain = calculate_gain(nonlinearity, a) # 通过判断是哪种激活函数生成一个gain值 std = gain / math.sqrt(fan) # 通过fan值和gain值进行标准差的计算 with torch.no_grad(): return tensor.normal_(0, std) 下面的代码根据网络设计时卷积权重的形状和是前向传播还是反向传播，进行fan值的计算。 1234567891011121314151617181920212223242526def _calculate_fan_in_and_fan_out(tensor): dimensions = tensor.dim() # 返回的是维度 if dimensions &lt; 2: raise ValueError(&quot;Fan in and fan out can not be computed for tensor with fewer than 2 dimensions&quot;) if dimensions == 2: # Linear fan_in = tensor.size(1) fan_out = tensor.size(0) else: num_input_fmaps = tensor.size(1) # 卷积的输入通道大小 num_output_fmaps = tensor.size(0) # 卷积的输出通道大小 receptive_field_size = 1 if tensor.dim() &gt; 2: receptive_field_size = tensor[0][0].numel() # 卷积核的大小:k*k fan_in = num_input_fmaps * receptive_field_size # 输入通道数量*卷积核的大小. 用于前向传播 fan_out = num_output_fmaps * receptive_field_size # 输出通道数量*卷积核的大小. 用于反向传播 return fan_in, fan_outdef _calculate_correct_fan(tensor, mode): mode = mode.lower() valid_modes = [&#x27;fan_in&#x27;, &#x27;fan_out&#x27;] if mode not in valid_modes: raise ValueError(&quot;Mode &#123;&#125; not supported, please use one of &#123;&#125;&quot;.format(mode, valid_modes)) fan_in, fan_out = _calculate_fan_in_and_fan_out(tensor) return fan_in if mode == &#x27;fan_in&#x27; else fan_out 下面是通过不同的激活函数返回一个gain值，当然也说明了是recommend。可以自己修改。 12345678910111213141516171819202122232425262728293031323334353637383940def calculate_gain(nonlinearity, param=None): r&quot;&quot;&quot;Return the recommended gain value for the given nonlinearity function. The values are as follows: ================= ==================================================== nonlinearity gain ================= ==================================================== Linear / Identity :math:`1` Conv&#123;1,2,3&#125;D :math:`1` Sigmoid :math:`1` Tanh :math:`\\frac&#123;5&#125;&#123;3&#125;` ReLU :math:`\\sqrt&#123;2&#125;` Leaky Relu :math:`\\sqrt&#123;\\frac&#123;2&#125;&#123;1 + \\text&#123;negative\\_slope&#125;^2&#125;&#125;` ================= ==================================================== Args: nonlinearity: the non-linear function (`nn.functional` name) param: optional parameter for the non-linear function Examples: &gt;&gt;&gt; gain = nn.init.calculate_gain(&#x27;leaky_relu&#x27;, 0.2) # leaky_relu with negative_slope=0.2 &quot;&quot;&quot; linear_fns = [&#x27;linear&#x27;, &#x27;conv1d&#x27;, &#x27;conv2d&#x27;, &#x27;conv3d&#x27;, &#x27;conv_transpose1d&#x27;, &#x27;conv_transpose2d&#x27;, &#x27;conv_transpose3d&#x27;] if nonlinearity in linear_fns or nonlinearity == &#x27;sigmoid&#x27;: return 1 elif nonlinearity == &#x27;tanh&#x27;: return 5.0 / 3 elif nonlinearity == &#x27;relu&#x27;: return math.sqrt(2.0) elif nonlinearity == &#x27;leaky_relu&#x27;: if param is None: negative_slope = 0.01 elif not isinstance(param, bool) and isinstance(param, int) or isinstance(param, float): # True/False are instances of int, hence check above negative_slope = param else: raise ValueError(&quot;negative_slope &#123;&#125; not a valid number&quot;.format(param)) return math.sqrt(2.0 / (1 + negative_slope ** 2)) else: raise ValueError(&quot;Unsupported nonlinearity &#123;&#125;&quot;.format(nonlinearity)) 下面是kaiming初始化均匀分布的计算。为啥还有个均匀分布？权重初始化推导的只是一个方差，并没有限定是正态分布，均匀分布也是有方差的，并且均值为0的时候，可以通过方差算出均匀分布的最小值和最大值。 12345678def kaiming_uniform_(tensor, a=0, mode=&#x27;fan_in&#x27;, nonlinearity=&#x27;leaky_relu&#x27;): fan = _calculate_correct_fan(tensor, mode) gain = calculate_gain(nonlinearity, a) std = gain / math.sqrt(fan) bound = math.sqrt(3.0) * std # Calculate uniform bounds from standard deviation with torch.no_grad(): return tensor.uniform_(-bound, bound) 3. 推导的先验知识3.1 用变量来看待问题![图片](Kaiming He初始化的学习/640) 参照上面的卷积图, 对输入的特征图进行的卷积. 具体要研究的是输出的一个点的方差(紫色点). 所以是通过黄色的输入(个)和绿色的卷积参数(个)去计算一个输出值(紫色输出)的方差. 一个点对应于原论文里面的说法为a response. 感觉这个是理解权重初始化的重点. 基于独立同分布的强假设: 输入的每个值都是独立同分布的, 所以和独立同分布的参数进行卷积得到结果的分布也是相同的. 所以其他的3个输出点的方差也是一样的. 进一步说, 虽然输入是个不同的值. 但是我们可以这样认为: 有一个满足某分布的随机变量, 然后随机抽样48次, 这48个值就可以组成了输入, 且独立同分布(也可称输入的每个像素点是独立同分布的). 卷积的参数也可以这么认为. 那么我们可以用一个随机变量表示48个输入, 也可以用一个随机变量表示27个卷积参数, 亦可以用一个随机变量表示4个输出值. 3.2 几个公式$$var(X_1+\\cdots+X_n)=var(X_1)+\\cdots+var(X_n)$$ $(1)$式表示独立随机变量之和的方差等于各变量的方差之和, 如果$X_1$和$X_2$还是同分布的,那么$var(X_1)=var(X_2)\\Rightarrow var(X_1)+var(X_2)=2var(X_1)=2var(X_2)$. 将这个应用在卷积求和的那一步(卷积先相乘, 再求和).$$var(X)=E(X^2)-(E(X))^2$$$(2)$式是通过期望求方差的公式, 方差等于平方的期望减去期望的平方. 如果$E(X)=0$, 那么$var(X)=E(X^2)$.$$var(XY)=var(X)var(Y)+var(X)(E(Y))^2+var(Y)var(E(X))^2$$$(3)$式是独立变量乘积的一个公式(协方差为0). 如果$E(X)=E(Y)=0$, 那么$var(XY)=var(X)var(Y)$. 4. kaiming初始化kaiming初始化的推导过程只包含卷积和ReLU激活函数, 默认是vgg类似的网络, 没有残差, concat之类的结构, 也没有BN层.$$Y_l = W_lX_l + B_l$$此处,$Y_l$表示某个位置的输出值，$X_l$表示被卷积的输入,有$k×k×c$形状(对应于上图的黄色部分), $k$表示卷积核的大小,$c$表示输入的通道.令$n=k×k×c$,则$n$的大小表示一个输出值是由多少个输入值计算出来的(求方差的时候用到).$W$有$d×n$形状, $d$表示的输出通道的数量.下标$l$表示第几层.$X_l=f(Y_{l-1})$, $f$表示激活函数ReLU, 表示前一层的输出经过激活函数变成下一层的输入. $c_l=d_{l-1}$表示网络下一层的输入通道数等于上一层的输出通道数.(这里是对应原论文的翻译了) 4.1 前向传播时每层的方差都是1因为一个输出的$y$是由$n$个输入的$x$和其$n$个权重相乘再求和得到的(卷积的过程), 且假设权重数值之间是独立同分布的,$x$数值之间也是独立同分布的,且$x$和权重相互独立。那么根据(1)式得$$var(y_l)=n_lvar(w_l\\cdot x_l)$$其中的$y,w,x$都表示随机变量，$l$表示第几层。举个例子：$$y=w_1×x_1+w_2×x_2+w_3×x_3+w_4×x_4+w_5×x_5+w_6×x_6$$其中，$w_几×x_几$看作一个整体，且1到6之间相互独立，就能得到$$var(y)=var(w_1×x_1)+var(w_2×x_2)+var(w_3×x_3)+var(w_4×x_4)+var(w_5×x_5)+var(w_6×x_6)$$又如果$w_几×x_几$之间又是同分布的, 那么他们的方差就是相同的, 就能得到$var(y)=6var(w×x)$. 进一步,因为$w_l,x_l$是相互独立的, 所以根据(3)式，可将(5)式推导为$$var(y_l)=n_l[var(w_l)var(x_l)+var(w_l)(E(x_l))^2+(E(w_l))^2var(x_l)]$$初始化的时候令权重的均值是0, 且假设更新的过程中权重的均值一直是0,则$E(w_l)=0$,但是$x_l$是上一层通过ReLU得到的,所以$E(x_l)\\ne0$.$$var(y_l)=n_l[var(w_l)var(x_l)+var(w_l)(E(x_l))^2=n_lvar(w_l)(var(x_l)+(E(x_l))^2)$$通过(2)式可得$var(x_l)+(E(x_l))^2=E(x_l^2)$,则（9）式推导为$$var(y_l)=n_lvar(w_l)E(x_l^2)$$接下来求$E(x_l^2)$, 通过第$l-1$层的输出来求此期望, 我们有$x_l=f(y_{l-1})$, 其中$f$表示ReLU函数.$$E(x_l^2)=E(f^2(y_{l-1}))=\\int_{-\\infty}^{+\\infty}p(y_{l-1})(y_{l-1})^2dy_{l-1}$$因为$y_{l-1}\\in(-\\infty,0)$的时候$f(y_{l-1})=0$，所以可以去掉小于0的区间，并且大于0的时候$f(y_{l-1})=y_{l-1}$，所以可得$$E(x_l^2)=E(f^2(y_{l-1}))=\\int_{0}^{+\\infty}p(y_{l-1})(y_{l-1})^2dy_{l-1}$$现因为$w_{l-1}$是假设在0周围对称分布且均值为0, 所以$y_{l-1}$也是在0附近分布是对称的, 并且均值为0(此处假设偏置为0,). 则$\\int_{0}^{+\\infty}p(y_{l-1})(y_{l-1})^2dy_{l-1}=\\int_{-\\infty}^{0}p(y_{l-1})(y_{l-1})^2dy_{l-1}$, 进一步可以得到$$E(x_l^2)=E(f^2(y_{l-1}))=\\frac 12(\\int_{0}^{+\\infty}p(y_{l-1})(y_{l-1})^2dy_{l-1}+\\int_{-\\infty}^{0}p(y_{l-1})(y_{l-1})^2dy_{l-1})=\\frac 12\\int_{-\\infty}^{+\\infty}p(y_{l-1})(y_{l-1})^2dy_{l-1}=\\frac 12E(y^2_{l-1})$$现在通过公式(2),$var(y_{l-1})=E(y^2_{l-1})-(E(y_{l-1}))^2$ ,其中$y_{l-1}$的均值是0, 则$var(y_{l-1})=E(y^2_{l-1})$,那么（13）式可进一步推导为$$E(x^2_l)=\\frac 12E(y^2_{l-1})=\\frac 12var(y_{l-1})$$将(14)式带入(10)式则为$$var(y_l)=\\frac 12n_lvar(w_l)var(y_{l-1})$$然后从第一层一直往前进行前向传播, 可以得到某层的方差为$$var(y_l)=var(y_1)(\\prod_{i=0}^L\\frac 12n_lvar(w_l))$$这里的$y_1$就是输入的样本, 我们会将其归一化处理, 所以$var(y_1)=1$, 现在让每层输出方差等于1, 即$$\\frac 12n_lvar(w_l)=1$$ $$var(w_l)=\\frac 2{n_l}$$ 举例层卷积, 输入大小为$32×16×16$, 分别表示通道数量、高、宽, 卷积核大小为$64×32×3×3$, 分别表示输出通道数量、输入通道数量、卷积核高、卷积核宽. 则该层的权重$w\\sim N(0,\\frac 2{32×3×3})$, 偏置初始化为0. $64×32×3×3=18432$个参数都是从这个分布里面采样. 也对应了Pytorch里面的kaiming初始化只要传卷积核的参数进去就行了, 可以看下源码对应的计算. 4.2 反向传播时梯度的方差都是1$$\\Delta X_l=\\hat W_l\\Delta Y_l$$ 其中, $\\Delta$表示损失函数对其求导. 与正常的反向传播推导不一样, 这里假设$\\Delta Y_l$表示$d$个通道,每个通道$k×k$大小,$\\hat n=k×k×d$ ,与正向传播的时候一样, $\\Delta X_l$有个$c$通道, $\\Delta Y_l$有$d$个通道. $\\hat W_l$的大小为$c×\\hat n$,所以$\\Delta X_l$的形状为$c×1$.$\\hat W$和$W$只差了一个转置(涉及到反向传播). 同样的想法是, 一个$\\Delta x_l$的值是很多个$\\Delta y_l$求得到, 继续通过多个独立同分布变量求一个变量(梯度)的方差. 假设随机变量$\\hat w_l,\\Delta y_l$都是独立同分布的,$\\hat w_l$的分布在0附近对称的, 则$\\Delta x_l$对每层$l$,均值都是0, 即$E(\\Delta x_l)=0$. 因为前向传播的时候$$x_{l+1}=f(y_l)$$所以反向传播则为$$\\Delta y_l=f’(y_l)\\Delta x_{l+1}$$又因为$f$是ReLU, 导数要么是0要么是1, 那么假设两者各占一半, 同时假设$f’(y_l)$和$\\Delta x_{l+1}$相互独立.那么$$E(\\Delta y_l)=\\frac 12×0×\\Delta x_{l+1}+\\frac 12×1×\\Delta x_{l+1}=\\frac 12E(\\Delta x_{l+1})=0$$其中, 将概率分为了两部分,一部分对应的ReLU导数为0，一部分对应的ReLU导数为1 (且这两部分假设都是50%的可能). 公式（22）表示对于一个$\\Delta y_l$的取值, 有一半概率对应ReLU导数为0，一般对应为1. 根据(2)式又得$$var(\\Delta y_l)=E(\\Delta y^2_l)$$ $$var(\\Delta y_l)=var(f’(y_l)\\Delta x_{l+1})=\\frac 12var(0\\Delta x_{l+1})+\\frac 12var(1\\Delta x_{l+1})=\\frac 12var(\\Delta x_{l+1})$$ (24)式也可以通过(13)式用类似的方法求出. 那么,$$var(\\Delta x_l)=\\hat nvar(\\hat w_l\\Delta y_l)=\\hat n[var(\\hat w_l)var(\\Delta y_l)+var(\\hat w_l)(E(\\Delta y_l))^2+var(\\Delta y_l)(E(\\hat w_l))^2]=\\hat nvar(\\hat w_l)var(\\Delta y_l)=\\frac 12\\hat nvar(\\hat w_l)var(\\Delta x_{l+1})$$所以,按照前向推导的方法,最后得出的公式是$$\\frac 12\\hat n_lvar(w_l)=1$$按照前向传播最后的示例, 此处的应该为$w\\sim N(0,\\frac 2{64×3×3})$","tags":[{"name":"论文学习","slug":"论文学习","permalink":"http://clarkhedi.github.io/tags/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/"}]},{"title":"autograd与逻辑回归","date":"2021-04-05T19:52:09.000Z","path":"2021/04/05/autograd-yu-luo-ji-hui-gui/","text":"autograd 与逻辑回归1、自动求导 (autograd)在深度学习中，权值的更新是依赖于梯度的计算，因此梯度的计算是至关重要的。在 PyTorch 中，只需要搭建好前向计算图，然后利用torch.autograd自动求导得到所有张量的梯度。 torch.autograd.backward()功能：自动求取梯度 tensors: 用于求导的张量，如 loss retain_graph: 保存计算图。PyTorch 采用动态图机制，默认每次反向传播之后都会释放计算图。这里设置为 True 可以不释放计算图 create_graph: 创建导数计算图，用于高阶求导 grad_tensors: 多梯度权重。当有多个 loss 混合需要计算梯度时，设置每个 loss 的权重。 retain_graph 参数代码示例： 1234567891011121314w = torch.tensor([1.], requires_grad=True)x = torch.tensor([2.], requires_grad=True)# y=(x+w)*(w+1)a = torch.add(w, x)b = torch.add(w, 1)y = torch.mul(a, b)# 第一次执行梯度求导y.backward()print(w.grad)# 第二次执行梯度求导，出错y.backward()## 报错信息：RuntimeError: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling .backward() or autograd.grad() the first time. 其中y.backward()方法调用的是torch.autograd.backward(self, gradient, retain_graph, create_graph)。但是在第二次执行y.backward()时会出错。因为 PyTorch 默认是每次求取梯度之后不保存计算图的，因此我们第二次求导梯度时，计算图已经不存在了。报错信息提示我们在第一次求梯度时使用y.backward(retain_graph=True)即可。如下代码所示： 123456789101112w = torch.tensor([1.], requires_grad=True)x = torch.tensor([2.], requires_grad=True)# y=(x+w)*(w+1)a = torch.add(w, x)b = torch.add(w, 1)y = torch.mul(a, b)# 第一次求导，设置 retain_graph=True，保留计算图y.backward(retain_graph=True)print(w.grad)# 第二次求导成功y.backward() grad_tensors 参数代码示例： 1234567891011121314151617w = torch.tensor([1.], requires_grad=True)x = torch.tensor([2.], requires_grad=True)a = torch.add(w, x)b = torch.add(w, 1)y0 = torch.mul(a, b) # y0 = (x+w) * (w+1)y1 = torch.add(a, b) # y1 = (x+w) + (w+1) dy1/dw = 2# 把两个 loss 拼接都到一起loss = torch.cat([y0, y1], dim=0) # [y0, y1]# 设置两个 loss 的权重: y0 的权重是 1，y1 的权重是 2grad_tensors = torch.tensor([1., 2.])loss.backward(gradient=grad_tensors) # gradient 传入 torch.autograd.backward()中的grad_tensors# 最终的 w 的导数由两部分组成。∂y0/∂w * 1 + ∂y1/∂w * 2print(w.grad) 结果为：tensor([9.]) 该 loss 由两部分组成：$y{0}$ 和 $y{1}$。其中 $\\frac{\\partial y{0}}{\\partial w}=5$，$\\frac{\\partial y{1}}{\\partial w}=2$。而 grad*tensors 设置两个 loss 对 w 的权重分别为 1 和 2。因此最终 w 的梯度为：$$\\frac{\\partial y{0}}{\\partial w} \\times 1+ \\frac{\\partial y_{1}}{\\partial w} \\times 2=9$$ torch.autograd.grad()1torch.autograd.grad(outputs, inputs, grad_outputs=None, retain_graph=None, create_graph=False, only_inputs=True, allow_unused=False) 功能：求取梯度。 outputs: 用于求导的张量，如 loss inputs: 需要梯度的张量 create_graph: 创建导数计算图，用于高阶求导 retain_graph:保存计算图 grad_outputs: 多梯度权重计算 torch.autograd.grad()的返回结果是一个 tuple，需要取出第 0 个元素才是真正的梯度。 下面使用torch.autograd.grad()求二阶导。在求一阶导时，需要设置 create_graph=True，让一阶导数 grad_1 也拥有计算图，然后再使用一阶导求取二阶导： 12345678x = torch.tensor([3.], requires_grad=True)y = torch.pow(x, 2) # y = x**2# 如果需要求 2 阶导，需要设置 create_graph=True，让一阶导数 grad_1 也拥有计算图grad_1 = torch.autograd.grad(y, x, create_graph=True) # grad_1 = dy/dx = 2x = 2 * 3 = 6print(grad_1)# 这里求 2 阶导grad_2 = torch.autograd.grad(grad_1[0], x) # grad_2 = d(dy/dx)/dx = d(2x)/dx = 2print(grad_2) 输出为： 12(tensor([6.], grad_fn=&lt;MulBackward0&gt;),)(tensor([2.]),) 需要注意的 3 点： 在每次反向传播求导时，计算的梯度不会自动清零。如果进行多次迭代计算梯度而没有清零，那么梯度会在前一次的基础上叠加。 代码示例： 123456789w = torch.tensor([1.], requires_grad=True)x = torch.tensor([2.], requires_grad=True)# 进行 4 次反向传播求导，每次最后都没有清零for i in range(4): a = torch.add(w, x) b = torch.add(w, 1) y = torch.mul(a, b) y.backward() print(w.grad) 结果为： 1234tensor([5.])tensor([10.])tensor([15.])tensor([20.]) 每一次的梯度都比上一次的梯度多 5，这是由于梯度不会自动清零而在上一次计算的梯度结果上累加。应使用w.grad.zero_()在每次梯度计算完后将梯度清零。 12345678for i in range(4): a = torch.add(w, x) b = torch.add(w, 1) y = torch.mul(a, b) y.backward() print(w.grad) # 每次都把梯度清零 # w.grad.zero_() 依赖于叶子节点的节点，requires_grad 属性默认为 True。 叶子节点不可执行 inplace 操作。 以加法来说，``inplace 操作有a += x，a.add_(x)，**改变后的值和原来的值内存地址是同一个**。非inplace 操作有a = a + x，a.add(x)`，改变后的值和原来的值内存地址不是同一个。 代码示例： 12345678910111213print(&quot;非 inplace 操作&quot;)a = torch.ones((1, ))print(id(a), a)# 非 inplace 操作，内存地址不一样a = a + torch.ones((1, ))print(id(a), a)print(&quot;inplace 操作&quot;)a = torch.ones((1, ))print(id(a), a)# inplace 操作，内存地址一样a += torch.ones((1, ))print(id(a), a) 结果为： 123456非 inplace 操作1743355122752 tensor([1.])1743355124032 tensor([2.])inplace 操作1743355122688 tensor([1.])1743355122688 tensor([2.]) 如果在反向传播之前 inplace 改变了叶子节点的值，再执行 backward() 会报错。 123456789w = torch.tensor([1.], requires_grad=True)x = torch.tensor([2.], requires_grad=True)# y = (x + w) * (w + 1)a = torch.add(w, x)b = torch.add(w, 1)y = torch.mul(a, b)# 在反向传播之前 inplace 改变了 w 的值，再执行 backward() 会报错w.add_(1)y.backward() 这是因为在进行前向传播时，计算图中依赖于叶子节点的那些节点，会记录叶子节点的地址，在反向传播时就会利用叶子节点的地址所记录的值来计算梯度。比如在 $y=a \\times b$ ，其中 $a=x+w$，$b=w+1$，$x$ 和 $w$ 是叶子节点。当求导 $\\frac{\\partial y}{\\partial a} = b = w+1$，需要用到叶子节点 $w$。 2、逻辑回归 (Logistic Regression)逻辑回归是线性的二分类模型。模型表达式：$$y=f(z)=\\frac{1}{1+e^{-z}}$$其中 $z=WX+b$。$f(z)$ 称为 sigmoid 函数，也被称为 Logistic 函数。函数曲线如下：(横坐标是 $z$，而 $z=WX+b$，纵坐标是 $y$)。 分类原则：当$y&lt;0.5$时，类别为0（class=0）；当 $0.5 \\leq y$ 时，类别为 1（class=1）。 其中 $z=WX+b$ 就是原来的线性回归的模型。从横坐标来看，当 $z&lt;0$ 时，类别为 0；当 $0 \\leq z$ 时，类别为 1，直接使用线性回归也可以进行分类。逻辑回归是在线性回归的基础上加入了一个 sigmoid 函数，这是为了更好地描述置信度，把输入映射到 (0,1) 区间中，符合概率取值。 逻辑回归也被称为对数几率回归 $\\ln \\frac{y}{1-y}=W X+b$，几率的表达式为：$\\frac{y}{1-y}$，$y$ 表示正类别的概率，$1-y$ 表示另一个类别的概率。根据对数几率回归可以推导出逻辑回归表达式： $\\ln \\frac{y}{1-y}=W X+b$ $\\frac{y}{1-y}=e^{W X+b}$ $y=e^{W X+b}-y * e^{W X+b}$ $y\\left(1+e^{W X+b}\\right)=e^{W X+b}$ $y=\\frac{e^{W X+b}}{1+e^{W X+b}}=\\frac{1}{1+e^{-(W X+b)}}$ PyTorch 实现逻辑回归 PyTorch 构建模型的 5 大步骤： 数据：包括数据清洗，数据读取，进行数据划分和数据预处理，比如读取图片如何预处理及数据增强。 模型：包括构建模型模块，组织复杂网络，初始化网络参数，定义网络层。 损失函数：包括创建损失函数，设置损失函数超参数，根据不同任务选择合适的损失函数。 优化器：包括根据梯度使用某种优化器更新参数，管理模型参数，管理多个参数组实现不同学习率，调整学习率。 迭代训练：组织上面 4 个模块进行反复训练。包括观察训练效果，绘制 Loss/ Accuracy 曲线，用 TensorBoard 进行可视化分析。 代码示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import torchimport torch.nn as nnimport matplotlib.pyplot as pltimport numpy as nptorch.manual_seed(10)# ============================ step 1/5 生成数据 ============================sample_nums = 100mean_value = 1.7bias = 1n_data = torch.ones(sample_nums, 2)# 使用正态分布随机生成样本，均值为张量，方差为标量x0 = torch.normal(mean_value * n_data, 1) + bias # 类别0 数据 shape=(100, 2)# 生成对应标签y0 = torch.zeros(sample_nums) # 类别0 标签 shape=(100, 1)# 使用正态分布随机生成样本，均值为张量，方差为标量x1 = torch.normal(-mean_value * n_data, 1) + bias # 类别1 数据 shape=(100, 2)# 生成对应标签y1 = torch.ones(sample_nums) # 类别1 标签 shape=(100, 1)train_x = torch.cat((x0, x1), 0)train_y = torch.cat((y0, y1), 0)# ============================ step 2/5 选择模型 ============================class LR(nn.Module): def __init__(self): super(LR, self).__init__() self.features = nn.Linear(2, 1) self.sigmoid = nn.Sigmoid() def forward(self, x): x = self.features(x) x = self.sigmoid(x) return xlr_net = LR() # 实例化逻辑回归模型# ============================ step 3/5 选择损失函数 ============================loss_fn = nn.BCELoss()# ============================ step 4/5 选择优化器 ============================lr = 0.01 # 学习率optimizer = torch.optim.SGD(lr_net.parameters(), lr=lr, momentum=0.9)# ============================ step 5/5 模型训练 ============================for iteration in range(1000): # 前向传播 y_pred = lr_net(train_x) # 计算 loss loss = loss_fn(y_pred.squeeze(), train_y) # 反向传播 loss.backward() # 更新参数 optimizer.step() # 清空梯度 optimizer.zero_grad() # 绘图 if iteration % 20 == 0: mask = y_pred.ge(0.5).float().squeeze() # 以0.5为阈值进行分类 correct = (mask == train_y).sum() # 计算正确预测的样本个数 acc = correct.item() / train_y.size(0) # 计算分类准确率 plt.scatter(x0.data.numpy()[:, 0], x0.data.numpy()[:, 1], c=&#x27;r&#x27;, label=&#x27;class 0&#x27;) plt.scatter(x1.data.numpy()[:, 0], x1.data.numpy()[:, 1], c=&#x27;b&#x27;, label=&#x27;class 1&#x27;) w0, w1 = lr_net.features.weight[0] w0, w1 = float(w0.item()), float(w1.item()) plot_b = float(lr_net.features.bias[0].item()) plot_x = np.arange(-6, 6, 0.1) plot_y = (-w0 * plot_x - plot_b) / w1 plt.xlim(-5, 7) plt.ylim(-7, 7) plt.plot(plot_x, plot_y) plt.text(-5, 5, &#x27;Loss=%.4f&#x27; % loss.data.numpy(), fontdict=&#123;&#x27;size&#x27;: 20, &#x27;color&#x27;: &#x27;red&#x27;&#125;) plt.title(&quot;Iteration: &#123;&#125;\\nw0:&#123;:.2f&#125; w1:&#123;:.2f&#125; b: &#123;:.2f&#125; accuracy:&#123;:.2%&#125;&quot;.format(iteration, w0, w1, plot_b, acc)) plt.legend() # plt.savefig(str(iteration / 20)+&quot;.png&quot;) plt.show() plt.pause(0.5) # 如果准确率大于 99%，则停止训练 if acc &gt; 0.99: break 训练的分类直线的可视化如下：","tags":[{"name":"Pytorch","slug":"Pytorch","permalink":"http://clarkhedi.github.io/tags/Pytorch/"}]},{"title":"计算图与动态图机制","date":"2021-04-05T19:34:36.000Z","path":"2021/04/05/ji-suan-tu-yu-dong-tai-tu-ji-zhi/","text":"计算图与动态图机制1、计算图深度学习就是对张量进行一系列的操作，随着操作种类和数量的增多，会出现各种值得思考的问题。比如多个操作之间是否可以并行，如何协同底层的不同设备，如何避免冗余的操作，以实现最高效的计算效率，同时避免一些 bug。因此产生了计算图 (Computational Graph)。 计算图是用来描述运算的有向无环图，有两个主要元素：节点 (Node) 和边 (Edge)。节点表示数据，如向量、矩阵、张量。边表示运算，如加减乘除卷积等。 用计算图表示：$y=(x+w)*(w+1)$，如下所示： 可以看作， $y=a \\times b$ ，其中 $a=x+w$，$b=w+1$。 计算图与梯度求导这里求 $y$ 对 $w$ 的导数。根复合函数的求导法则，可以得到如下过程。 $\\begin{aligned} \\frac{\\partial y}{\\partial w} &amp;=\\frac{\\partial y}{\\partial a} \\frac{\\partial a}{\\partial w}+\\frac{\\partial y}{\\partial b} \\frac{\\partial b}{\\partial w} \\ &amp;=b 1+a 1 \\ &amp;=b+a \\ &amp;=(w+1)+(x+w) \\ &amp;=2 w+x+1 \\ &amp;=2 1+2+1=5\\end{aligned}$ 体现到计算图中，就是根节点 $y$ 到叶子节点 $w$ 有两条路径 y -&gt; a -&gt; w和y -&gt;b -&gt; w。根节点依次对每条路径的孩子节点求导，一直到叶子节点w，最后把每条路径的导数相加即可。 代码如下： 1234567891011import torchw = torch.tensor([1.], requires_grad=True)x = torch.tensor([2.], requires_grad=True)# y=(x+w)*(w+1)a = torch.add(w, x) # retain_grad()b = torch.add(w, 1)y = torch.mul(a, b)# y 求导y.backward()# 打印 w 的梯度，就是 y 对 w 的导数print(w.grad) 结果为tensor([5.])。 我们回顾前面说过的 Tensor 中有一个属性is_leaf标记是否为叶子节点。 在上面的例子中，$x$ 和 $w$ 是叶子节点，其他所有节点都依赖于叶子节点。叶子节点的概念主要是为了节省内存，在计算图中的一轮反向传播结束之后，非叶子节点的梯度是会被释放的。 代码示例： 12345# 查看叶子结点print(&quot;is_leaf:\\n&quot;, w.is_leaf, x.is_leaf, a.is_leaf, b.is_leaf, y.is_leaf)# 查看梯度print(&quot;gradient:\\n&quot;, w.grad, x.grad, a.grad, b.grad, y.grad) 结果为： 1234is_leaf: True True False False Falsegradient: tensor([5.]) tensor([2.]) None None None 非叶子节点的梯度为空，如果在反向传播结束之后仍然需要保留非叶子节点的梯度，可以对节点使用retain_grad()方法。 而 Tensor 中的 grad_fn 属性记录的是创建该张量时所用的方法 (函数)。而在反向传播求导梯度时需要用到该属性。 示例代码： 123456# 查看梯度print(&quot;w.grad_fn = &quot;, w.grad_fn)print(&quot;x.grad_fn = &quot;, x.grad_fn)print(&quot;a.grad_fn = &quot;, a.grad_fn)print(&quot;b.grad_fn = &quot;, b.grad_fn)print(&quot;y.grad_fn = &quot;, y.grad_fn) 结果为： 12345w.grad_fn = Nonex.grad_fn = Nonea.grad_fn = &lt;AddBackward0 object at 0x000001EDC1E67520&gt;b.grad_fn = &lt;AddBackward0 object at 0x000001EDC1E67520&gt;y.grad_fn = &lt;MulBackward0 object at 0x000001EDC1E67520&gt; 2、PyTorch 的动态图机制PyTorch 采用的是动态图机制 (Dynamic Computational Graph)，而 Tensorflow 采用的是静态图机制 (Static Computational Graph)。 动态图是运算和搭建同时进行，也就是可以先计算前面的节点的值，再根据这些值搭建后面的计算图。优点是灵活，易调节，易调试。PyTorch 里的很多写法跟其他 Python 库的代码的使用方法是完全一致的，没有任何额外的学习成本。 静态图是先搭建图，然后再输入数据进行运算。优点是高效，因为静态计算是通过先定义后运行的方式，之后再次运行的时候就不再需要重新构建计算图，所以速度会比动态图更快。但是不灵活。TensorFlow 每次运行的时候图都是一样的，是不能够改变的，所以不能直接使用 Python 的 while 循环语句，需要使用辅助函数 tf.while_loop 写成 TensorFlow 内部的形式。","tags":[{"name":"Pytorch","slug":"Pytorch","permalink":"http://clarkhedi.github.io/tags/Pytorch/"}]},{"title":"张量操作与线性回归","date":"2021-04-05T19:28:08.000Z","path":"2021/04/05/zhang-liang-cao-zuo-yu-xian-xing-hui-gui/","text":"张量操作与线性回归1、张量的操作拼接torch.cat()1torch.cat(tensors, dim=0, out=None) 功能：将张量按照 dim 维度进行拼接 tensors: 张量序列 dim: 要拼接的维度 代码示例： 1234t = torch.ones((2, 3))t_0 = torch.cat([t, t], dim=0)t_1 = torch.cat([t, t], dim=1)print(&quot;t_0:&#123;&#125; shape:&#123;&#125;\\nt_1:&#123;&#125; shape:&#123;&#125;&quot;.format(t_0, t_0.shape, t_1, t_1.shape)) 输出是： 123456t_0:tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) shape:torch.Size([4, 3])t_1:tensor([[1., 1., 1., 1., 1., 1.], [1., 1., 1., 1., 1., 1.]]) shape:torch.Size([2, 6]) torch.stack()1torch.stack(tensors, dim=0, out=None) 功能：将张量在新创建的 dim 维度上进行拼接 tensors: 张量序列 dim: 要拼接的维度 代码示例： 1234567t = torch.ones((2, 3))# dim =2t_stack = torch.stack([t, t, t], dim=2)print(&quot;\\nt_stack.shape:&#123;&#125;&quot;.format(t_stack.shape))# dim =0t_stack = torch.stack([t, t, t], dim=0)print(&quot;\\nt_stack.shape:&#123;&#125;&quot;.format(t_stack.shape)) 输出为： 12t_stack.shape:torch.Size([2, 3, 3])t_stack.shape:torch.Size([3, 2, 3]) 注：第一次指定拼接的维度 dim =2，结果的维度是 [2, 3, 3]。后面指定拼接的维度 dim =0，由于原来的 tensor 已经有了维度 0，因此会把tensor 往后移动一个维度变为 [1,2,3]，再拼接变为 [3,2,3]。 切分torch.chunk()1torch.chunk(input, chunks, dim=0) 功能：将张量按照维度 dim 进行平均切分。若不能整除，则最后一份张量小于其他张量。 input: 要切分的张量 chunks: 要切分的份数 dim: 要切分的维度 代码示例： 1234a = torch.ones((2, 7)) # 7list_of_tensors = torch.chunk(a, dim=1, chunks=3) # 3for idx, t in enumerate(list_of_tensors):print(&quot;第&#123;&#125;个张量：&#123;&#125;, shape is &#123;&#125;&quot;.format(idx+1, t, t.shape)) 输出为： 123456第1个张量：tensor([[1., 1., 1.], [1., 1., 1.]]), shape is torch.Size([2, 3])第2个张量：tensor([[1., 1., 1.], [1., 1., 1.]]), shape is torch.Size([2, 3])第3个张量：tensor([[1.], [1.]]), shape is torch.Size([2, 1]) 注：由于 7 不能整除 3，7/3 再向上取整是 3，因此前两个维度是 [2, 3]，所以最后一个切分的张量维度是 [2,1]。 torch.split()1torch.split(tensor, split_size_or_sections, dim=0) 功能：将张量按照维度 dim 进行平均切分。可以指定每一个分量的切分长度。 tensor: 要切分的张量 split_size_or_sections: 为 int 时，表示每一份的长度，如果不能被整除，则最后一份张量小于其他张量；为 list 时，按照 list 元素作为每一个分量的长度切分。如果 list 元素之和不等于切分维度 (dim) 的值，就会报错。 dim: 要切分的维度 代码示例： 1234t = torch.ones((2, 5))list_of_tensors = torch.split(t, [2, 1, 2], dim=1)for idx, t in enumerate(list_of_tensors):print(&quot;第&#123;&#125;个张量：&#123;&#125;, shape is &#123;&#125;&quot;.format(idx+1, t, t.shape)) 结果为： 123456第1个张量：tensor([[1., 1.], [1., 1.]]), shape is torch.Size([2, 2])第2个张量：tensor([[1.], [1.]]), shape is torch.Size([2, 1])第3个张量：tensor([[1., 1.], [1., 1.]]), shape is torch.Size([2, 2]) 索引torch.index_select()1torch.index_select(input, dim, index, out=None) 功能：在维度 dim 上，按照 index 索引取出数据拼接为张量 返回。 input: 要索引的张量 dim: 要索引的维度 index: 要索引数据的序号 代码示例： 1234567# 创建均匀分布t = torch.randint(0, 9, size=(3, 3))# 注意 idx 的 dtype 不能指定为 torch.floatidx = torch.tensor([0, 2], dtype=torch.long)# 取出第 0 行和第 2 行t_select = torch.index_select(t, dim=0, index=idx)print(&quot;t:\\n&#123;&#125;\\nt_select:\\n&#123;&#125;&quot;.format(t, t_select)) 输出为： 1234567t:tensor([[4, 2, 6], [6, 4, 0], [7, 3, 5]])t_select:tensor([[4, 2, 6], [7, 3, 5]]) torch.mask_select()1torch.masked_select(input, mask, out=None) 功能：按照 mask 中的 True 进行索引拼接得到一维张量 返回。 要索引的张量 mask: 与 input 同形状的布尔类型张量 代码示例： 12345t = torch.randint(0, 9, size=(3, 3))mask = t.le(5) # ge is mean greater than or equal/ gt: greater than le lt# 取出大于 5 的数t_select = torch.masked_select(t, mask)print(&quot;t:\\n&#123;&#125;\\nmask:\\n&#123;&#125;\\nt_select:\\n&#123;&#125; &quot;.format(t, mask, t_select)) 结果为： 12345678910t:tensor([[5, 5, 7], [2, 2, 8], [2, 6, 7]])mask:tensor([[ True, True, True], [False, False, True], [False, True, True]])t_select:tensor([5, 5, 7, 8, 6, 7]) 注：最后返回的是一维张量。 变换torch.reshape()1torch.reshape(input, shape) 功能：变换张量的形状。当张量在内存中是连续时，返回的张量和原来的张量共享数据内存，改变一个变量时，另一个变量也会被改变。 input: 要变换的张量 shape: 新张量的形状 代码示例： 12345# 生成 0 到 8 的随机排列t = torch.randperm(8)# -1 表示这个维度是根据其他维度计算得出的(自动计算分配) [2x2x2=8]t_reshape = torch.reshape(t, (-1, 2, 2))print(&quot;t:&#123;&#125;\\nt_reshape:\\n&#123;&#125;&quot;.format(t, t_reshape)) 结果为： 1234567t:tensor([1, 7, 2, 5, 3, 6, 0, 4])t_reshape:tensor([[[1, 7], [2, 5]], [[3, 6], [0, 4]]]) 注：在上面代码的基础上，修改原来的张量的一个元素，新张量也会被改变。 代码示例： 12345# 修改张量 t 的第 0 个元素，张量 t_reshape 也会被改变t[0] = 1024print(&quot;t:&#123;&#125;\\nt_reshape:\\n&#123;&#125;&quot;.format(t, t_reshape))print(&quot;t.data 内存地址:&#123;&#125;&quot;.format(id(t.data)))print(&quot;t_reshape.data 内存地址:&#123;&#125;&quot;.format(id(t_reshape.data))) 结果为： 123456789t:tensor([1024, 4, 3, 6, 5, 2, 7, 0])t_reshape:tensor([[[1024, 4], [ 3, 6]], [[ 5, 2], [ 7, 0]]])t.data 内存地址:2395125092288t_reshape.data 内存地址:2395125089152 torch.transpose()1torch.transpose(input, dim0, dim1) 功能：交换张量的两个维度。常用于图像的变换，比如把c*h*w变换为h*w*c。 input: 要交换的张量 dim0: 要交换的第一个维度 dim1: 要交换的第二个维度 代码示例： 12345678#把 c * h * w 变换为 h * w * ct = torch.rand((2, 3, 4))# print(t)t_transpose_0 = torch.transpose(t, dim0=0, dim1=1) # c*h*w -&gt; h*c*w# print(t_transpose_0)t_transpose_1 = torch.transpose(t_transpose_0, dim0=1, dim1=2) # c*h*w -&gt; h*w*c# print(t_transpose_1)print(&quot;t shape:&#123;&#125;\\nt_transpose shape: &#123;&#125;&quot;.format(t.shape, t_transpose_1.shape)) 结果为： 12t shape:torch.Size([2, 3, 4])t_transpose shape: torch.Size([3, 4, 2]) torch.t()功能：2 维张量转置，对于 2 维矩阵而言，等价于torch.transpose(input, 0, 1)。 torch.squeeze()1torch.squeeze(input, dim=None, out=None) 功能：压缩长度为 1 的维度。 dim: 若为 None，则移除所有长度为 1 的维度；若指定维度，则当且仅当该维度长度为 1 时可以移除。 代码示例： 123456789101112# 维度 0 和 3 的长度是 1t = torch.rand((1, 2, 3, 1))# 可以移除维度 0 和 3t_sq = torch.squeeze(t)# 可以移除维度 0t_0 = torch.squeeze(t, dim=0)# 不能移除 1t_1 = torch.squeeze(t, dim=1)print(&quot;t.shape: &#123;&#125;&quot;.format(t.shape))print(&quot;t_sq.shape: &#123;&#125;&quot;.format(t_sq.shape))print(&quot;t_0.shape: &#123;&#125;&quot;.format(t_0.shape))print(&quot;t_1.shape: &#123;&#125;&quot;.format(t_1.shape)) 结果为： 1234t.shape: torch.Size([1, 2, 3, 1])t_sq.shape: torch.Size([2, 3])t_0.shape: torch.Size([2, 3, 1])t_1.shape: torch.Size([1, 2, 3, 1]) torch.unsqueeze()1torch.unsqueeze(input, dim) 功能：根据 dim 扩展维度，长度为 1。 2、张量的数学运算主要分为：加减乘除，对数，指数，幂函数 和三角函数。 这里介绍一下常用的几种方法。 torch.add()12torch.add(input, other, out=None)torch.add(input, other, *, alpha=1, out=None) 功能：逐元素计算 input + alpha * other。因为在深度学习中经常用到先乘后加的操作。 input: 第一个张量 alpha: 乘项因子 other: 第二个张量 torch.addcdiv()1torch.addcdiv(input, tensor1, tensor2, *, value=1, out=None) 计算公式为：out ${i}=\\operatorname{input}{i}+$ value $\\times \\frac{\\text { tensor } 1*{i}}{\\text { tensor } 2*{i}}$ torch.addcmul()1torch.addcmul(input, tensor1, tensor2, *, value=1, out=None) 计算公式为：out ${i}=$ input ${i}+$ value $\\times$ tensor $1*{i} \\times$ tensor $2*{i}$ 3、线性回归线性回归是分析一个变量 ($y$) 与另外一 (多) 个变量 ($x$) 之间的关系的方法。一般可以写成 $y=wx+b$。线性回归的目的就是求解参数$w, b$。 线性回归的求解可以分为 3 步： 确定模型：$y=wx+b$ 选择损失函数，一般使用均方误差 MSE：$\\frac{1}{m} \\sum*{i=1}^{m}\\left(y*{i}-\\hat{y}{i}\\right)^{2}$。其中 $ \\hat{y}{i} $ 是预测值，$y$ 是真实值。 使用梯度下降法求解梯度 (其中 $lr$ 是学习率)，并更新参数： $w = w - lr * w.grad$ $b = b - lr * b.grad$ 代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import torchimport matplotlib.pyplot as plttorch.manual_seed(10)lr = 0.05 # 学习率# 创建训练数据x = torch.rand(20, 1) * 10 # x data (tensor), shape=(20, 1)# torch.randn(20, 1) 用于添加噪声y = 2*x + (5 + torch.randn(20, 1)) # y data (tensor), shape=(20, 1)# 构建线性回归参数w = torch.randn((1), requires_grad=True) # 设置梯度求解为 trueb = torch.zeros((1), requires_grad=True) # 设置梯度求解为 true# 迭代训练 1000 次for iteration in range(1000): # 前向传播，计算预测值 wx = torch.mul(w, x) y_pred = torch.add(wx, b) # 计算 MSE loss loss = (0.5 * (y - y_pred) ** 2).mean() # 反向传播 loss.backward() # 更新参数 b.data.sub_(lr * b.grad) w.data.sub_(lr * w.grad) # 每次更新参数之后，都要清零张量的梯度 w.grad.zero_() b.grad.zero_() # 绘图，每隔 20 次重新绘制直线 if iteration % 20 == 0: plt.scatter(x.data.numpy(), y.data.numpy()) plt.plot(x.data.numpy(), y_pred.data.numpy(), &#x27;r-&#x27;, lw=5) plt.text(2, 20, &#x27;Loss=%.4f&#x27; % loss.data.numpy(), fontdict=&#123;&#x27;size&#x27;: 20, &#x27;color&#x27;: &#x27;red&#x27;&#125;) plt.xlim(1.5, 10) plt.ylim(8, 28) plt.title(&quot;Iteration: &#123;&#125;\\nw: &#123;&#125; b: &#123;&#125;&quot;.format(iteration, w.data.numpy(), b.data.numpy())) plt.pause(0.5) # 如果 MSE 小于 1，则停止训练 if loss.data.numpy() &lt; 1: break 训练的直线的可视化如下： 在 80 次的时候，Loss 已经小于 1 了，因此停止了训练。","tags":[{"name":"Pytorch","slug":"Pytorch","permalink":"http://clarkhedi.github.io/tags/Pytorch/"}]},{"title":"Tensor（张量）介绍","date":"2021-04-05T19:22:48.000Z","path":"2021/04/05/tensor-zhang-liang-jie-shao/","text":"Tensor(张量)介绍1、Tensor 的概念Tensor 中文为张量。张量的意思是一个多维数组，它是标量、向量、矩阵的高维扩展。 例如：标量可以称为 0 维张量，向量可以称为 1 维张量，矩阵可以称为 2 维张量，RGB 图像可以表示 3 维张量。你也可以把张量看作多维数组。 2、Tensor 与 Variable在 PyTorch 0.4.0 之前，torch.autograd 包中存在 Variable 这种数据类型，主要是用于封装 Tensor，进行自动求导。Variable 主要包含下面几种属性。 data: 被包装的 Tensor。 grad: data 的梯度。 grad_fn: 创建 Tensor 所使用的 Function，是自动求导的关键，因为根据所记录的函数才能计算出导数。 requires_grad: 指示是否需要梯度，并不是所有的张量都需要计算梯度。 is_leaf: 指示是否叶子节点(张量)，叶子节点的概念在计算图中会用到，后面详细介绍。 在 PyTorch 0.4.0 之后，Variable 并入了 Tensor。在之后版本的 Tensor 中，除了具有上面 Variable 的 5 个属性，还有另外 3 个属性。 dtype: 张量的数据类型，如 torch.FloatTensor，torch.cuda.FloatTensor。 shape: 张量的形状。如 (64, 3, 224, 224) device: 张量所在设备 (CPU/GPU)，GPU 是加速计算的关键 关于 dtype，PyTorch 提供了 9 种数据类型，共分为 3 大类：float (16-bit, 32-bit, 64-bit)、integer (unsigned-8-bit ,8-bit, 16-bit, 32-bit, 64-bit)、Boolean。模型参数和数据用的最多的类型是 float-32-bit。label 常用的类型是 integer-64-bit。 3、Tensor 创建的方法利用torch直接创建tensortorch.tensor()1torch.tensor(data, dtype=None, device=None, requires_grad=False, pin_memory=False) data: 数据，可以是 list，numpy dtype: 数据类型，默认与 data 的一致 device: 所在设备，cuda/cpu requires_grad: 是否需要梯度 pin_memory: 是否存于锁页内存 代码示例： 123456arr = np.ones((3, 3))print(&quot;ndarray的数据类型：&quot;, arr.dtype)# 创建存放在 GPU 的数据# t = torch.tensor(arr, device=&#x27;cuda&#x27;)t = torch.tensor(arr)print(t) 输出为： 1234ndarray的数据类型：float64tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], dtype=torch.float64) 从 numpy 创建 tensortorch.from_numpy(ndarray)利用这个方法创建的 tensor 和原来的 ndarray 共享内存，当修改其中一个数据，另外一个也会被改动。 代码示例： 1234567891011121314arr = np.array([[1, 2, 3], [4, 5, 6]])t = torch.from_numpy(arr)# 修改 array，tensor 也会被修改# print(&quot;\\n修改arr&quot;)# arr[0, 0] = 0# print(&quot;numpy array: &quot;, arr)# print(&quot;tensor : &quot;, t)# 修改 tensor，array 也会被修改print(&quot;\\n修改tensor&quot;)t[0, 0] = -1print(&quot;numpy array: &quot;, arr)print(&quot;tensor : &quot;, t) 输出为： 12345修改tensornumpy array: [[-1 2 3] [ 4 5 6]]tensor : tensor([[-1, 2, 3], [ 4, 5, 6]], dtype=torch.int32) 根据数值创建 tensortorch.zeros()1torch.zeros(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：根据 size 创建全 0 张量 size: 张量的形状 out: 输出的张量，如果指定了 out，那么torch.zeros()返回的张量和 out 指向的是同一个地址 layout: 内存中布局形式，有 strided，sparse_coo 等。当是稀疏矩阵时，设置为 sparse_coo 可以减少内存占用。 device: 所在设备，cuda/cpu requires_grad: 是否需要梯度 代码示例： 123456out_t = torch.tensor([1])# 这里制定了 outt = torch.zeros((3, 3), out=out_t)print(t, &#x27;\\n&#x27;, out_t)# id 是取内存地址。最终 t 和 out_t 是同一个内存地址print(id(t), id(out_t), id(t) == id(out_t)) 输出是： 1234567tensor([[0, 0, 0], [0, 0, 0], [0, 0, 0]]) tensor([[0, 0, 0], [0, 0, 0], [0, 0, 0]])2984903203072 2984903203072 True torch.zeros_like1torch.zeros_like(input, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format) 功能：根据 input 形状创建全 0 张量 input: 创建与 input 同形状的全 0 张量 dtype: 数据类型 layout: 内存中布局形式，有 strided，sparse_coo 等。当是稀疏矩阵时，设置为 sparse_coo 可以减少内存占用。 同理还有全 1 张量的创建方法：torch.ones()，torch.ones_like()。 torch.full()，torch.full_like()1torch.full(size, fill_value, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：创建自定义数值的张量 size: 张量的形状，如 (3,3) fill_value: 张量中每一个元素的值 代码示例： 12t = torch.full((3, 3), 1)print(t) 输出为： 123tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]) torch.arange()1torch.arange(start=0, end, step=1, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：创建等差的 1 维张量。注意区间为[start, end)。 start: 数列起始值 end: 数列结束值，开区间，取不到结束值 step: 数列公差，默认为 1 代码示例： 12t = torch.arange(2, 10, 2)print(t) 输出为： 1tensor([2, 4, 6, 8]) torch.linspace()1torch.linspace(start, end, steps=100, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：创建均分的 1 维张量。数值区间为 [start, end] start: 数列起始值 end: 数列结束值 steps: 数列长度 (元素个数) 代码示例： 123# t = torch.linspace(2, 10, 5)t = torch.linspace(2, 10, 6)print(t) 输出为： 1tensor([ 2.0000, 3.6000, 5.2000, 6.8000, 8.4000, 10.0000]) torch.logspace()1torch.logspace(start, end, steps=100, base=10.0, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：创建对数均分的 1 维张量。数值区间为 [start, end]，底为 base。 start: 数列起始值 end: 数列结束值 steps: 数列长度 (元素个数) base: 对数函数的底，默认为 10 代码示例： 123# t = torch.linspace(2, 10, 5)t = torch.linspace(2, 10, 6)print(t) 输出为： 1tensor([ 2.0000, 3.6000, 5.2000, 6.8000, 8.4000, 10.0000]) torch.eye()1torch.eye(n, m=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：创建单位对角矩阵( 2 维张量)，默认为方阵 n: 矩阵行数。通常只设置 n，为方阵。 m: 矩阵列数 根据概率创建 Tensortorch.normal()1torch.normal(mean, std, *, generator=None, out=None) 功能：生成正态分布 (高斯分布) mean: 均值 std: 标准差 有 4 种模式： mean 为标量，std 为标量。这时需要设置 size。 代码示例： 1234# mean：标量 std: 标量# 这里需要设置 sizet_normal = torch.normal(0., 1., size=(4,))print(t_normal) 输出为： 1tensor([0.6614, 0.2669, 0.0617, 0.6213]) mean 为标量，std 为张量 mean 为张量，std 为标量 代码示例： 123456# mean：张量 std: 标量mean = torch.arange(1, 5, dtype=torch.float)std = 1t_normal = torch.normal(mean, std)print(&quot;mean:&#123;&#125;\\nstd:&#123;&#125;&quot;.format(mean, std))print(t_normal) 输出为： 123mean:tensor([1., 2., 3., 4.])std:1tensor([1.6614, 2.2669, 3.0617, 4.6213]) 这 4 个数采样分布的均值不同，但是方差都是 1。 mean 为张量，std 为张量 代码示例： 123456# mean：张量 std: 张量mean = torch.arange(1, 5, dtype=torch.float)std = torch.arange(1, 5, dtype=torch.float)t_normal = torch.normal(mean, std)print(&quot;mean:&#123;&#125;\\nstd:&#123;&#125;&quot;.format(mean, std))print(t_normal) 输出为： 123mean:tensor([1., 2., 3., 4.])std:tensor([1., 2., 3., 4.])tensor([1.6614, 2.5338, 3.1850, 6.4853]) 其中 1.6614 是从正态分布 $N(1,1)$ 中采样得到的，其他数字以此类推。 torch.randn() 和 torch.randn_like()1torch.randn(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：生成标准正态分布。 size: 张量的形状 torch.rand() 和 torch.rand_like()1torch.rand(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：在区间 [0, 1) 上生成均匀分布。 torch.randint() 和 torch.randint_like()12randint(low=0, high, size, *, generator=None, out=None,dtype=None, layout=torch.strided, device=None, requires_grad=False) 功能：在区间 [low, high) 上生成整数均匀分布。 size: 张量的形状 torch.randperm()1torch.randperm(n, out=None, dtype=torch.int64, layout=torch.strided, device=None, requires_grad=False) 功能：生成从 0 到 n-1 的随机排列。常用于生成索引。 n: 张量的长度 torch.bernoulli()1torch.bernoulli(input, *, generator=None, out=None) 功能：以 input 为概率，生成伯努利分布 (0-1 分布，两点分布) input: 概率值","tags":[{"name":"Pytorch","slug":"Pytorch","permalink":"http://clarkhedi.github.io/tags/Pytorch/"}]},{"title":"triplet-loss学习","date":"2020-12-13T14:59:59.000Z","path":"2020/12/13/triplet-loss-xue-xi/","text":"一些参考资料： torch.max/eq()… torch.expand/squeeze()… torch.contiguous() torch.gather() loss funtion Triplet-Loss原理及其实现、应用 batch-hard-strategy PyTorch triphard代码理解 三元组怎么挑选？batch的形成/PK取样​ 随机的从dataset中取样P个人、每个人取K张图片，比如P=16，K=4，则一个batch中有16*4=64张图片。 构建三元组​ 由上面得到一个batch中的图片都经过网络提取特征，得到64个特征。接下来构建三元组： 把每一个图片都当成anchor，总共可以选出64个三元组（其实按照排列组合可以选出很多三元组的，In defense of triplet loss这篇文章就只构建有代表性的64个三元组） 每个三元组的anchor选定后，positive从K-1个中选一个与anchor特征距离最远的样本，negative从P*K-K个中选一个与anchor特征距离最近的样本，这样子对这个anchor来说，选出来的positive和negative都是最困难的。这样组建了P*K个三元组，计算出P*K个triplet loss，把这些loss取平均进行反传。 数据集迭代的过程是按照person id来循环的，假设数据集有751个id，一个batch取掉了16个id，这样经过int(751/16)个batch就循环了一次（一个epoch），接下来把id的顺序打乱，进行下一轮迭代（下一个epoch）。 训练方法offline 训练集所有数据经过计算得到对应的 embeddings, 可以得到 很多&lt;i, j, k&gt; 的三元组，然后再计算 triplet loss 效率不高，因为需要过一遍所有的数据得到三元组，然后训练反向更新网络 online 从训练集中抽取B个样本，然后计算 B 个embeddings，可以产生 B*B*B个 triplets （当然其中有不合法的，因为需要的是&lt;a, p, n&gt;） 实际使用中采用此方法，又分为两种策略 （是在一篇行人重识别的论文中提到的 In Defense of the Triplet Loss for Person Re-Identification），假设 B = P*K , 其中P个身份的人，每个身份的人K张图片（一般K 取 4） Batch All: 计算batch_size中所有valid的的hard triplet 和 semi-hard triplet， 然后取平均得到Loss。 注意因为很多 easy triplets的情况，所以平均会导致Loss很小，所以是对所有 valid 的所有求平均。 可以产生 P K ( K − 1 ) ( P K − K ) 个 triplets PK个 anchor K-1 个 positive PK-K 个 negative Batch Hard: 对于每一个anchor， 选择距离最大的d(a, p) 和 距离最小的 d(a, n) 共有 P K个 三元组triplets margin的选择？ 当 margin 值越小时，loss 也就较容易的趋近于 0，于是 Anchor 与 Positive 都不需要拉的太近，Anchor 与 Negative 不需要拉的太远，就能使得 loss 很快的趋近于 0。这样训练得到的结果，不能够很好的区分相似的图像。 当 margin 值越大时，就需要使得网络参数要拼命地拉近 Anchor、Positive 之间的距离，拉远 Anchor、Negative 之间的距离。如果 margin 值设置的太大，很可能最后 loss 保持一个较大的值，难以趋近于 0 。 torch.nn.MarginRankingLoss() 两个N维向量之间的相似度，用于排序任务，该方法计算两组数据之间的差异，返回一个N*N的loss矩阵 y=1，希望x1比x2大，当x1&gt;x2时，不产生loss y=-1，希望x1比x2小，当x2&gt;x1时，不产生loss 1234567891011x1 = torch.tensor([[1], [2], [3]], dtype=torch.float)x2 = torch.tensor([[2], [2], [2]], dtype=torch.float)target = torch.tensor([1, 1, -1], dtype=torch.float) #这是yloss_f_none = nn.MarginRankingLoss(margin=0, reduction=&#x27;none&#x27;) # margin ：边界值，reduction：计算模式loss = loss_f_none(x1, x2, target)# y=-1 x1[2]=3 3-2 3-2 3-2 1 1 -1 ---&gt;0 0 1#输出：loss:tensor([[1., 1., 0.], [0., 0., 0.], [0., 0., 1.]]) torch.nn.SoftMarginLoss() 二分类logistic损失： 其中，x.nelement()是平均值，y=1或-1 1234567inputs = torch.tensor([[0.3, 0.7], [0.5, 0.5]])target = torch.tensor([[-1, 1], [1, -1]], dtype=torch.float)loss_f = nn.SoftMarginLoss(reduction=&#x27;none&#x27;)loss = loss_f(inputs, target)#输出：SoftMargin: tensor([[0.8544, 0.4032],[0.4741, 0.9741]]) 123456idx = 0inputs_i = inputs[idx, idx]target_i = target[idx, idx]loss_h = np.log(1 + np.exp(-target_i * inputs_i))#输出：tensor(0.8544)","tags":[{"name":"损失函数","slug":"损失函数","permalink":"http://clarkhedi.github.io/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"}]},{"title":"Python多线程入门","date":"2020-11-25T15:37:56.000Z","path":"2020/11/25/python-duo-xian-cheng-ru-men/","text":"操作系统的设计 可以归结为三点： （1）以多进程形式，允许多个任务同时运行； （2）以多线程形式，允许单个任务分成不同的部分运行； （3）提供协调机制，一方面防止进程之间和线程之间产生冲突，另一方面允许进程之间和线程之间共享资源。 线程和进程进程就是处于运行中的程序，并且具有一定独立的功能。比如说，我们在电脑上打开一个软件，就是开启了一个进程，更具体的来说，Windows 系统你可以通过资源管理器进行查看当前电脑启动的进程数。所以也可以说进程是操作系统进行资源分配和调度的一个独立单位。 线程是进程的组成部分，一个进程可以包含多个线程，多个线程可以共用这个进程的资源，相比于进程，线程更加轻量级。 线程的几种状态线程状态一共有五种,包括如下: 新建 就绪 运行 阻塞 死亡 它们之间的关系如下图所示： 实现方式接下来，我们就来看看如何在 Python 里面实现多线程。总的来说，如果你了解过其他语言实现多线程的方式，比如说 Java的话，那对于理解 Python 实现多线程是非常有帮助的。Python 实现多线程有两种方式: 使用 threading 模块的 Thread 类的构造器创建线程 继承 threading 模块的 Thread 类创造线程类 我们先用第一种方式来编写一个多线程程序，即使用 threading 模块的 Thread 类的构造器创建线程。 123456789101112131415161718192021#!/usr/bin/python# -*- coding: utf-8 -*-import threading# 定义一个简单的方法，用于多线程的执行体def action(number): for i in range(number): # 调用 threading 模块的 current_thread() 函数来获取当前线程 # 调用当前线程的 getName() 函数来获取线程名 print(&quot;&#123;&#125;,&#123;&#125;&quot;.format(threading.current_thread().getName(), i))number = 5for i in range(5): print(&quot;&#123;&#125;,&#123;&#125;&quot;.format(threading.current_thread().getName(), i)) if i == 3: # 创建并启动第一个线程 t1 = threading.Thread(target=action, args=(number, )) t1.start() # 创建并启动第二个线程 t2 = threading.Thread(target=action, args=(number, )) t2.start() 看起来是不是很简单，很我们平常写的 Python 程序并没有特别大的不同，但是还是有很一些情况是需要注意的，其中最重要的就是 threading.Thread()，我在这里重点介绍下。 首先它是一个类，我们可以通过 type(threading.Thread) 来进行查看，它的构造函数如下所示： __init__(self, group=None, target=None, name=None, args=(), kwargs=&#123;&#125;, *, daemon=None) group 应该为None，这个我们不用管，它是为了日后扩展 ThreadGroup 类实现而保留的一个参数。 target 是我们需要重视的一个参数， 我们想让哪个函数并发执行，这个函数就是 target 的参数值，注意只写函数名，不需要写 ()。 name 是线程名称，默认情况下，由”Thread-N”的格式构成一个唯一的名称，其中 N 是小的十进制数。 args 是用于调用目标函数的参数元祖， 注意是元祖， 如果你只想传一个参数的话，也应该这样写 (args1,), 而不是 (args)。 kwargs 是用于调用目标函数的关键字参数字典。默认是 {}。 daemon 用于设置该线程是否为守护模式，如果是 None， 线程默认将继承当前线程的守护模式属性。 一般来说，我们需要注意的就是 target 参数、args 参数，其他的参数用到的时候可以再查。 另一点需要我们需要注意的一点就是启动线程的方法是 start 方法，可能你也知道线程也有 run 方法，这一块也会在第二种方式中进行介绍，但是启动线程的方法是 start 方法，要不然就变成了单线程程序。 接下来我们来看下如何使用第二种方式实现多线程，即继承 threading 模块的 Thread 类创造线程类。 1234567891011121314151617181920212223#! /usr/bin/python# -*- coding:utf-8 -*-import threadingfrom threading import Thread# 继承 threading.Threadclass MyThread(Thread): def __init__(self, number): super().__init__() self.number = number # 重载 run() 方法 def run(self): for i in range(self.number): print(&quot;&#123;&#125;, &#123;&#125;&quot;.format(threading.current_thread().getName(), i))number = 5for i in range(5): print(&quot;&#123;&#125;, &#123;&#125;&quot;.format(threading.current_thread().getName(), i)) if i == 3: t1 = MyThread(number=number) t1.start() t2 = MyThread(number=number) t2.start() 第二种方式就是继承 Threading.Thread 类。然后重载 run() 方法。 其实我看来的话，感觉第二种方式更适合在项目中使用，因为它更加模块化，比较清晰。 另外还有一个方法需要注意的就是 join() 方法，它的作用就是协调主线程和子线程的，调用 join() 后，当前线程就会阻塞，或者来说，暂停运行，执行子线程，等子线程执行完成后，主线程再接着运行。 生产者、消费者模型提到多线程，最著名的就是生产者、消费者模型了，那应该如何实现呢？ 说实话，我当初最开始学习生产者、消费者模型的时候，心里是有点犯嘀咕的，感觉涉及到线程间的通信，太好解决。但是查阅了一些资料后，发现还是可以理解的。 生产者、消费者二者不属于竞争关系，更多的是一种捕食关系，生产者生产资源，消费者进行消费，就像圣湖中的牛吃草一样。 不知道这时候你有没有想到一种数据结构，那就是队列，队列呢是一种操作受限的线性表，它只允许在队尾入队，在队头出队，也就是先进先出 (FIFO) 策略。 生产者、消费者模型，不就是生产者生产元素，放到队尾，然后消费者从队头消费元素嘛。 只不过有时候会出现特殊的情况 队列空了，消费者还要消费数据 队列满了，生产者还要生产数据 这是我们需要重点考虑了，解决了以上两点，这个模型也就实现了。 接下来我们就来看看 Python 如何实现吧！ 1234567891011121314151617181920212223242526272829303132333435363738394041424344#!/usr/bin/python# -*- coding:utf-8from threading import Thread, current_threadimport timeimport randomfrom queue import Queuequeue = Queue(5)class ProducerThread(Thread): def run(self): name = current_thread().getName() nums = range(100) global queue while True: num = random.choice(nums) queue.put(num) print(&quot;生产者 &#123;&#125; 生产了数据 &#123;&#125;&quot;.format(name, num)) t = random.randint(1, 3) time.sleep(t) print(&quot;生产者 &#123;&#125; 睡眠了 &#123;&#125; 秒&quot;.format(name, t))class ConsumerThread(Thread): def run(self): name = current_thread().getName() global queue while True: num = queue.get() queue.task_done() print(&quot;消费者 &#123;&#125; 消耗了数据 &#123;&#125;&quot;.format(name, num)) t = random.randint(1, 5) time.sleep(t) print(&quot;消费者 &#123;&#125; 睡眠了 &#123;&#125; 秒&quot;.format(name, t))p1 = ProducerThread(name=&quot;producer1&quot;)p1.start()c1 = ConsumerThread(name=&quot;consumer1&quot;)c1.start()c2 = ConsumerThread(name=&quot;consumer2&quot;)c2.start() 看了上面的代码，不知道你有没有一种错觉，你不是说要考虑上面的两种情况，但是你并没有考虑啊。 确实，我没有考虑，那是因为 Queue 在设计实现的时候已经替我们考虑好了，我们直接使用就好了。 具体就是 task_done() 函数，它在队列为空时会自动阻塞当前线程 而队列在满的时候再添加元素也会阻塞当前线程，这就实现了上面我们提到的那两种情况。 接下来呢，我再给你讲解一个例子，带你看看如何使用锁。 银行取钱问题从银行取钱的基本流程大致可以分为以下几个步骤: 用户输入账户、密码，系统判断当前的账户、密码是否匹配。 用户输入取款金额 系统判断账户余额是否大于取款金额 如果余额大于取款金额，则取款成功；如果余额小于取款金额，则取款失败。 乍一看，这就是日常生活中的取款操作啊，但是把它放到多线程并发的情况下，就可能会出现问题。不信的话，你可以试着写下多线程的程序，然后再看下我的程序。 12345678910111213141516171819202122232425262728293031323334353637383940#!/usr/bin/python# -*- coding:utf-8 -*-import threadingimport timeclass Account: def __init__(self, account_no, balance): self.account_no = account_no self._balance = balance # 定义一个锁 self.lock = threading.RLock() def get_balance(self): return self._balance def draw(self, draw_amount): # 对 RLock 对象进行加锁 self.lock.acquire() try: if self._balance &gt;= draw_amount: print(threading.current_thread().getName() + &quot;取钱成功，吐出钞票：&quot; + str(draw_amount)) time.sleep(0.001) self._balance -= draw_amount print(&quot;\\t余额为：&quot; + str(self._balance)) else: print(threading.current_thread().getName() + &quot;取钱失败，余额不足！&quot;) finally: # 释放锁 self.lock.release()# 定义一个函数来模拟取钱操作def draw(account, draw_count): account.draw(draw_count)acct = Account(&quot;1234567&quot;, 1000)threading.Thread(name=&quot;甲&quot;, target=draw, args=(acct, 800)).start()threading.Thread(name=&quot;乙&quot;, target=draw, args=(acct, 800)).start() 如果你想尝试下不加锁的情况下是否会出现问题，你可以把我的程序进行修改，把加锁的那部分去掉，然后尝试运行下。 这里呢，不是说每次运行都会出现问题，可能你运行了十次也都没有出现问题，但是呢，这个安全隐患是确确实实存在的，不容忽视。","tags":[{"name":"Python","slug":"Python","permalink":"http://clarkhedi.github.io/tags/Python/"}]},{"title":"Github Actions全自动博客部署","date":"2020-11-19T16:14:12.000Z","path":"2020/11/19/github-actions-quan-zi-dong-bo-ke-bu-shu/","text":"假如现在有两个仓库，一个是存放网页静态文件的github.io仓库,为公有仓库；一个是存放博客源码的hexo仓库，因为里面的配置涉及到私人的密码信息，因此设置为私有仓库。 那么现在博客部署分为两步：见使用Hexo，换电脑也能更新博客 当添加新文章或更改配置后，需要将源码push到私有仓库 博客编译三步曲将网页静态文件上传到github.io. 123hexo clhexo ghexo d 有没有什么方法能实现全自动的博客部署， 每次只需要push源码到私有仓库，hexo会自动编译上传网页静态文件。 方法有很多，本文介绍一个Github新推出的功能–Actions. 首先介绍一下Github Actions:作为一种CI/CD工具(Continuous Integration/Continuous，持续集成/持续部署)它可以实现许多任务的自动化，能够进行测试，进行质量检查，然后部署。 这介绍有点官方，简而言之就是，当你将源代码push到Github之后，你可以自己定义一套操作流程。比如说你想让你的代码push上去之后在其他平台上看看会不会报错，那么你定义的流程就是首先将你上传的源码clone到本地（当然不是你的本地，类似于docker，都在云上），然后安装相关环境，再去执行你定义的操作。如果发现有什么错误信息，你好去修改你的源码。 拉回到本文的主题，我们想定义的一套流程是：当我push源码的时候，它会自动编译博客而不需要我再去执行那三步曲。 下面是具体步骤： 准备密钥公钥+私钥 12ssh-keygen -t rsa -C &quot;Github邮箱地址&quot;# 比如 ssh-keygen -t rsa -C &quot;123@gmail.com&quot; 公钥内容：~/.ssh/id_rsa.pub 私钥内容：~/.ssh/id_rsa 密钥设置 在github的Settings中,设置SSH keys为公钥内容，命名随意。 在自己创建的私有仓库hexo的Settings中，设置Secrets，新增内容为私钥，命名为DEPLOY_KEY。 添加Actions配置文件这一步就是定义当我们push源码后的操作： 在Actions中新增workflow，点击Actions，然后新建workflows，这时GitHub会自动生成一个main.yml文件。 最后修改main.yml文件，用如下内容替换去配置文件，你只需要修改下Git的配置信息，然后点击Start commit即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# workflow namename: Hexo Blog CI# master branch on push, auto runon: push: branches: - master jobs: build: runs-on: ubuntu-latest steps: # check it to your workflow can access it # from: https://github.com/actions/checkout - name: Checkout Repository master branch uses: actions/checkout@v2 # from: https://github.com/actions/setup-node - name: Setup Node.js 10.x uses: actions/setup-node@main with: node-version: &quot;10.x&quot; - name: Setup Hexo Dependencies run: | npm install hexo-cli -g npm install hexo-deployer-git --save npm install - name: Setup Deploy Private Key env: HEXO_DEPLOY_PRIVATE_KEY: $&#123;&#123; secrets.DEPLOY_KEY &#125;&#125; run: | mkdir -p ~/.ssh/ echo &quot;$HEXO_DEPLOY_PRIVATE_KEY&quot; &gt; ~/.ssh/id_rsa chmod 600 ~/.ssh/id_rsa ssh-keyscan github.com &gt;&gt; ~/.ssh/known_hosts - name: Setup Git Infomation run: | git config --global user.name &quot;your name&quot; git config --global user.email &quot;your email&quot; git config --global core.quotepath false - name: Deploy Hexo run: | rm -rf .deploy_git hexo clean hexo generate hexo deploy 当我们每次push源码的时候，Github Actions会自动执行上面的操作。 注意事项 当push博客的静态网站文件到GitHub时，一定是master分支，不然博客Pages上不会更新内容。 修改你博客根目录下的_config.yml文件，将HTTP修改为SSH形式，内容如下(将yourname改为自己的)： 1234deploy: type: git repo: git@github.com:yourname/yourname.github.io.git branch: master","tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://clarkhedi.github.io/tags/Hexo/"}]},{"title":"使用Hexo，换电脑也能更新博客","date":"2020-11-19T10:11:12.000Z","path":"2020/11/19/shi-yong-hexo-huan-dian-nao-ye-neng-geng-xin-bo-ke/","text":"解决方法：使用git分支进行多终端工作 在这里我们就可以利用git的分支系统进行多终端工作了，这样每次打开不一样的电脑，只需要进行简单的配置和在github上把文件同步下来，就可以无缝操作了。 机制由于hexo d上传部署到github的其实是hexo编译后的文件，是用来生成网页的，不包含源文件。 也就是上传的是在本地目录里自动生成的.deploy_git里面。 其他文件 ，包括我们写在source 里面的，和配置文件，主题文件，都没有上传到github。 所以可以利用git的分支管理，将源文件上传到github的另一个分支即可。 上传分支首先，先在github上新建一个hexo分支，如图： 然后在这个仓库的settings中，选择默认分支为hexo分支（这样每次同步的时候就不用指定分支，比较方便）。 然后在本地的任意目录下，打开git bash， 1$ git clone git@github.com:clarkhedi&#x2F;clarkhedi.github.io.git 将其克隆到本地，因为默认分支已经设成了hexo，所以clone时只clone了hexo。 接下来在克隆到本地的clarkhedi.github.io中，把除了.git 文件夹外的所有文件都删掉。 把之前我们写的博客源文件全部复制过来，除了.deploy_git。这里应该说一句，复制过来的源文件应该有一个.gitignore，用来忽略一些不需要的文件，如果没有的话，自己新建一个，在里面写上如下，表示这些类型文件不需要git： 1234567.DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/ 注意，如果你之前克隆过theme中的主题文件，那么应该把主题文件中的.git文件夹删掉，因为git不能嵌套上传，最好是显示隐藏文件，检查一下有没有，否则上传的时候会出错，导致你的主题文件无法上传，这样你的配置在别的电脑上就用不了了。 然后在本地的clarkhedi.github.io打开git bash输入如下命令（此时当前分支应显示为hexo）： 123$ git add .$ git commit –m &quot;add branch&quot;$ git push 这样就上传完了，可以去你的github上看一看hexo分支有没有上传上去，其中node_modules、public、db.json已经被忽略掉了，没有关系，不需要上传的，因为在别的电脑上需要重新输入命令安装 。 这样一来，在GitHub上的clarkhedi.github.io仓库就有两个分支，一个hexo分支用来存放网站的原始文件，一个master分支用来存放生成的静态网页。完美( •̀ ω •́ )y！ 关于日常的改动流程在本地对博客进行修改（添加新博文、修改样式等等）后，通过下面的流程进行管理。 依次执行git add .、git commit -m “…”、git push origin hexo指令将改动推送到GitHub（此时当前分支应为hexo）； 然后才执行hexo g -d发布网站到master分支上。 虽然两个过程顺序调转一般不会有问题，不过逻辑上这样的顺序是绝对没问题的（例如突然死机要重装了，悲催….的情况，调转顺序就有问题了）。 更换电脑后的操作如在Linux系统上，跟第一次的环境搭建一样的。 1.安装git1sudo apt-get install git 2.设置git全局邮箱和用户名12$ git config --global user.name &quot;your github name&quot;$ git config --global user.email &quot;your github email&quot; 3.设置ssh key12345$ ssh-keygen -t rsa -C &quot;youremail&quot; #生成后填到github和coding上（有coding平台的话） #验证是否成功 $ ssh -T git@github.com $ ssh -T git@git.coding.net #(有coding平台的话) 4.安装nodejs12sudo apt-get install nodejssudo apt-get install npm 5.安装hexo1sudo npm install hexo-cli -g 但是已经不需要初始化了， 直接在任意文件夹下，打开git bash操作如下命令： 1$ git clone git@……………… 然后进入克隆到的文件夹： 123$ cd xxx.github.io$ npm install$ npm install hexo-deployer-git --save 生成，部署： 12$ hexo g$ hexo d 然后就可以开始写你的新博客了 1$ hexo new newpage Tips: 不要忘了，每次写完最好都把源文件上传一下 123$ git add .$ git commit –m &quot;xxxx&quot;$ git push 如果是在已经编辑过的电脑上，已经有clone文件夹了，那么，每次只要和远端同步一下就行了 1$ git pull","tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://clarkhedi.github.io/tags/Hexo/"}]},{"title":"损失函数的解释","date":"2020-10-27T15:53:18.000Z","path":"2020/10/27/sun-shi-han-shu-de-jie-shi/","text":"在任何深度学习项目中，配置损失函数都是确保模型以预期方式工作的最重要步骤之一。 损失函数可以为神经网络提供很多实用的灵活性，它将定义网络输出与网络其余部分的连接方式。 神经网络可以执行多种任务，从预测连续值（如每月支出）到对离散类别（如猫和狗）进行分类。 每个不同的任务将需要不同的损失类型，因为输出格式将不同。 具体任务将定义不同的损失函数。 从非常简化的角度来看，损失函数（J）可以定义为具有两个参数的函数： 预测输出； 实际输出。 通过将模型的预测值与应该输出的实际值进行比较，该函数将实质上计算出模型的执行效果。 如果Y_pred与Y相差很远，那么Loss值将非常高。 但是，如果两个值几乎相似，则“损失”值将非常低。 因此，我们需要保持一个损失函数，该函数在对数据集进行训练时可以有效地惩罚模型。 如果损失非常大，那么这个巨大的价值将在训练过程中通过网络传播，权重的变化将比平常多一点。 如果损失小，则权重不会发生太大变化，因为网络已经做得很好了。 这种情况有点类似于学习考试。 如果一个人在考试中表现不佳，我们可以说损失非常高，那么这个人将不得不改变自己，以便下次获得更好的成绩。 但是，如果考试进行顺利，那么为下一次考试他们将不必改变太多现在的做法。 现在，让我们将分类视为一项任务，并了解在这种情况下损失函数的工作方式。 分类损失当神经网络试图预测离散值时，我们可以将其视为分类模型。 这可能是网络试图预测图像中存在哪种动物，或者电子邮件是否为垃圾邮件。 首先，让我们看看分类神经网络的输出表示方式。 输出层的节点数将取决于数据中存在的类数。 每个节点将代表一个类。 每个输出节点的值本质上表示该类别为正确类别的概率。 1Pr(Class 1) &#x3D; Probability of Class 1 being the correct class 一旦获得所有不同类别的概率，我们就将具有最高概率的类别视为该实例的预测类别。 首先，让我们探讨如何进行二进制分类。 二进制分类在二进制分类中，即使我们将在两个类之间进行预测，在输出层中也将只有一个节点。 为了获得概率格式的输出，我们需要应用一个激活函数。 由于概率要求取0到1之间的值，因此我们将使用S型函数，该函数可以将任何实际值压缩为0到1之间的值。 随着Sigmoid的输入变大并趋向于无穷大，Sigmoid的输出趋向于1。随着Sigmoid的输入变小而趋向于负无穷大，输出将趋于0。现在我们保证总会得到 一个介于0到1之间的值，这正是我们需要的值，因为我们需要概率。 如果输出高于0.5（概率为50％），我们将认为它属于正类别；如果输出低于0.5，则我们将认为它属于负类别。 例如，如果我们正在训练一个在猫和狗之间进行分类的网络，则可以为狗分配正类，并且在狗的数据集中的输出值将为1，类似地，将为猫分配负类，而对猫的输出值将为 为0。 我们用于二进制分类的损失函数称为二进制交叉熵（BCE）。 该功能有效地惩罚了用于二进制分类任务的神经网络。 让我们看一下此功能的图像。 如您所见，有两个单独的函数，每个Y值一个。当我们需要预测正类（Y = 1）时，我们将使用 1Loss &#x3D; -log(Y_pred) 当我们需要预测负类（Y = 0）时，我们将使用 1Loss &#x3D; -log(1-Y_pred) 如您在图表中所见。 对于第一个函数，当Y_pred等于1时，损失等于0，这是有道理的，因为Y_pred与Y完全相同。随着Y_pred值变得更接近0，我们可以观察到Loss值以非常高的速度增加 速率，当Y_pred变为0时，趋于无穷大。 这是因为从分类的角度来看，0和1必须相反，因为它们各自代表完全不同的类。 因此，当Y_pred为0且Y为1时，为了使网络更有效地了解错误，损失将非常大。 我们可以在数学上将整个损失函数表示为一个方程式，如下所示： 此损失函数也称为对数损失。 这就是为二进制分类神经网络设计损失函数的方式。 现在，让我们继续来看如何为多类别分类网络定义损失。 多类别分类当我们需要我们的模型每次预测一个可能的类输出时，多类分类是合适的。 现在，由于我们仍在处理概率，因此仅将sigmoid应用于所有输出节点可能有意义，以便我们为所有输出获得介于0–1之间的值，但这是有问题的。 在考虑多个类别的概率时，我们需要确保所有单个概率的总和等于1，因为这是定义概率的方式。 应用S形不能确保总和始终等于1，因此我们需要使用另一个激活函数。 我们在这种情况下使用的激活函数是softmax。 此功能确保所有输出节点的值都在0–1之间，并且所有输出节点值的总和始终等于1。 softmax的公式如下： 让我们用图像示例： 如您所见，我们只是将所有值传递给指数函数。 之后，要确保它们都在0–1的范围内，并确保所有输出值的总和等于1，我们只需将每个指数除以所有指数的总和即可。 那么，为什么在归一化每个值之前必须将它们传递给指数呢？ 为什么我们不能仅将值本身标准化？ 这是因为softmax的目标是确保一个值非常高（接近1），而所有其他值都非常低（接近0）。 Softmax使用指数来确保发生这种情况。 然后我们在归一化，因为我们需要概率。 现在我们的输出格式正确，让我们继续研究如何为此配置损失函数。 好消息是损失函数与二进制分类的函数基本相同。 我们将只针对每个输出节点将其对数损失应用到各自的目标值，然后我们将在所有输出节点上求和。 这种损失称为分类交叉熵。 现在，让我们进入一种称为多标签分类的特殊分类情况。 多标签分类当模型需要预测多个类别作为输出时，便完成了多标签分类。 例如，假设您正在训练神经网络，以预测某些食物图片中的成分。 我们需要预测多种成分，因此Y中会有多个1。 为此，我们不能使用softmax，因为softmax始终只会迫使一个类别变为1，而其他类别变为0。因此，由于我们试图预测每个类别的个体概率，因此可以简单地在所有输出节点值上保持sigmoid。 至于损失，我们可以直接在每个节点上使用对数损失进行求和，类似于在多类分类中所做的。 深度学习多分类任务的损失函数详解 既然我们已经介绍了分类，现在让我们介绍回归损失函数。 回归损失在回归中，我们的模型正在尝试预测连续值。 回归模型的一些示例是： 房价预测 年龄预测 在回归模型中，我们的神经网络将为每个我们试图预测的连续值提供一个输出节点。 通过在输出值和真实值之间进行直接比较来计算回归损失。 我们用于回归模型的最流行的损失函数是均方误差损失函数。 在此，我们仅计算Y和Y_pred之差的平方，并对所有数据求平均值。 假设有n个数据点： 在这里，Y_i和Y_pred_i指的是数据集中第i个Y值，以及来自神经网络的相同数据的相应Y_pred。 到此结束本文。 希望现在您对如何为深度学习中的各种任务配置损失函数有更深入的了解。 感谢您的阅读！ 参考：https://medium.com/deep-learning-demystified/loss-functions-explained-3098e8ff2b27","tags":[{"name":"损失函数","slug":"损失函数","permalink":"http://clarkhedi.github.io/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"}]},{"title":"CLBP学习(下)","date":"2020-10-04T11:11:24.000Z","path":"2020/10/04/clbp-xue-xi-xia/","text":"阐述一下CLBP实现纹理分类，与传统LBP不同，CLBP具有3个描述子。分别是CLBP-C、CLBP-S、CLBP-M。 1.确定中心像素的邻域坐标 上图内有P个采样点，每个采样点的值可以通过下式计算： p的范围:0~P-1;其中(xc,yc)为邻域中心点，(xp,yp)为某个采样点。通过上式可以计算任意个采样点的坐标，但是计算得到的坐标未必完全是整数，所以可以通过双线性插值来得到该采样点的像素值，双线性插值算法是通过临近四个坐标点的像素值进行线性加权求和，在x,y方向上都进行线性加权求和。公式如下： f(i+u,j+v)=(1-u)*(1-v)*f(i,j)+(1-u)*v*f(i,j+1)+u*(1-v)*f(i+1,j)+u*v*f(i+1,j+1) 其中i,j 为浮点坐标的整数部分； u,v为浮点坐标的小数部分。 此插值算法有利弊，即： 优点：缩放后图像质量高 缺点： 计算量大，双线性插值具有低通滤波器的性质，使高频分量受损，图像轮廓在一定程度上变模糊。 2.CLBP的整体计算流程 上图为CLBP的整体框架图，可以看到首先将原始图像表示为其中心灰度（C）和局部差异dp。其中还加入了旋转不变等价模式的LBP算子的描述，见CLBP学习(上) 局部差异dp的求解公式及其分解如下： 本文中的符号分量CLBP_S实际上就是传统LBP，两者编码方式也是相同的（这里的-1相当于传统LBP中的0），如下图。作者分析并验证了，符号分量所包含的纹理特征远高于幅度分量。 由于局部差异dp并不能直接作为描述子，因为其对于光照，旋转，噪声等都很敏感。作者把邻域像素和中心像素的差值分成符号分量和幅度分量，且由二者相乘得到，分别记做CLBP_S和CLBP_M。如下图中的（a）为3x3的采样块，其差值可由（b）表示，并且可以分解成（c）*（d），（c）为符号分量，（d）为幅度分量。 由上图可发现CLBP_M是连续的值，为了与CLBP_S统一编码，需要将其也转换成二进制编码。受CLBP_S启发，作者提出以下编码方式对其进行编码，其中c是自适应阈值，这里c的值取整幅图像中mp的均值。 中心像素代表局部灰度级，也包含了局部灰度判别信息，为了让其有效和LBP_M和LBP_S结合，我们进行如下编码： 这里的gc表示中心像素灰度值，ci表示整幅图像灰度的平均值。即通过比较中心像素与全图平均像素值的大小来进行二进制编码。 至此三个描述子CLBP_SCLBP_M,CLBP_C全部产生，可通过串联、并联或串并联其直方图的形式将其进行融合。 3.不相似度的计算及拓展最后，运用到纹理识别分类中，用卡方距离来测量两个直方图的不相似度： 其中 X是直方图bin的总数，Tx和Lx别分表示样本和模板在第x个bin上的值。 拓展：图像相似度计算 每个图像都可以使用一个LBP特征向量来表示，图像的相似度就可以使用向量的相似度来计算。 向量的相似度计算方法有很多，比如余弦、距离等。这种基于直方图向量的相似度计算方法有多种形式，如下图所示给出三种： 上图中公式只是针对一个直方图的，使用中还会将图像分为多个区域分别计算直方图。所以在实际使用中，还可对不同区域进行加权。","tags":[{"name":"CLBP","slug":"CLBP","permalink":"http://clarkhedi.github.io/tags/CLBP/"}]},{"title":"CLBP学习(上)","date":"2020-10-03T10:23:21.000Z","path":"2020/10/03/clbp-xue-xi-shang/","text":"纹理分类是一个很老的topic，但是一些纹理分类的方法为以后的图片分类奠定了基础。首先定义一下纹理图片，他是一个随一下变量变化的函数：纹理表面材质，反射率，光照，照相机和他的角度。现在纹理分类比较流行的有两种方法：一个是全局特征，如lbp，gabor，另一种是基于局部特征的，如：harris-laplace，基于局部特征的方法主要基于texton的框架，也就是现在图片分类的bag-of-words框架。今天我们先介绍一下基于全局的特征，全局特征当属LBP最牛最简单有效，下面我们来介绍一下lbp及其变种。 转载：来自我导师的一篇文章 1.LBP以R为半径的P点邻域，gc为中心，gp为邻域点 ;区分邻域比中心亮度大还是小。 注意：改变P,R 形成多尺度LBP。 2.uniform LBP P*(P-1)+2个二值编码中0-1/1-0转换次数小于或等于2的编码； U&lt;=2: P=8，7*8+2=58个编码值，其余的U&gt;2的归为一个bin；即总共58+1=59个bin. 3. 旋转不变的LBP ： 36个由于编码的起始点是一定的，每一种二值编码模式经旋转（循环位移）后会产生不同的编码结果。为了形成旋转不变的编码模式，我们让有同一编码模式经旋转后产生的编码结果编码为同一值，即这些旋转结果中的最小值: 36个旋转不变的LBP编码模式： 4.旋转不变的uniform LBP P+1个P=8时，即在uniform LBP中，开始7行的每一行为旋转不变，被编为一个编码值，对应上图中第一行的1-7个模式。再加上 全1和全0两种，共9个；其余的归为一个bin；即总共9+1=10个bin. ——————————————以上就是经典的LBP了，下面介绍一些变种—————————————————- 一． 增加幅值信息，增加对噪声鲁棒性1.LTP对二值化设定阈值 三值编码：使相对中心值变化在t范围内的邻域量化为0；比ic大于tpan &gt;的量化为1；比ic小于t的量化为-1 最后把三值编码转化为正的和负的两部分，2个8bit编码作为特征向量； 2.CLBP像素值差分为符号和幅值两项考虑 ，对符号的编码CLBP_S和LBP一样 （ 8位） 对差异值dp的幅值Mp编码（8位）： C为全图像的所有mp的均值 对中心象数值gc编码（2位）：Ci为全图像像素灰度均值 最后构建3D联合直方图CLBP_S/M/C ，列化作为特征向量。 二． 加入局部方差信息（局部对比度）1.VAR 在训练集上得到局部方差的量化阈值，对局部方差进行量化，与旋转不变的uniform LBP描述子计算联合直方图，得： 缺点：由于训练和测试图片成像条件不同，训练的量化阈值可能在测试图片上不适合. 2.LBP-V将每个点的方差作为编码值的权重，进行直方图累加（类比sift中按方向累计梯度幅值）。原理：方差大，对应区域变化大，为高频区域，对区分性贡献大，所以对应该处编码权重大. 三． 增加局部梯度信息（类比SIFT）1.CS-LBP对中心对称点的亮度差编码，即编码四方向的梯度符号，缩短编码长度. 2.TP-LBP编码某中心像数点的相邻patch的相似度 提取patch-based的信息，是对pixels-based的信息的补充中心patch和邻域patch大小为w*w；邻域半径r，邻域patch个数S，提取相似度信息的邻域间隔a，d(a,b)为a，b patch的相似度，编码局部patch的变化程度 3.POEM编码局部区域个方向patch内的梯度变化信息 （1） 计算梯度：方向和大小，对方向离散化m个 （2） 对每点，按离散方向，累积半径为r邻域内的梯度幅值（高斯加权），形成m个累积梯度幅值图像 （3） 对每个图像，计算半径R，邻域P的LBP，形成m个LBP 4.LDP编码每点的各方向边缘响应强度的变化 （1） 计算8方向边缘响应 （2） 取第K主方向值Mk（即第k大的边缘响应幅值）作为阈值，进行二值化形成编码。有C_8_k种编码值 四． 对U-LBP的改进1.H-LBP层叠的多多尺度LBP ULBP将U&gt;2的编码都对归入到一个bin中，丢失了其中的区分信息。 半径越大非uniform编码出现频率越高，而大半径中为非uniform的编码在小半径时可能为uniform形式，此时把其编码换为小半径中uniform形式，直至半径缩小为指定大小 关于LBP的变形还有很多种，这里就不一一赘述了！","tags":[{"name":"CLBP","slug":"CLBP","permalink":"http://clarkhedi.github.io/tags/CLBP/"}]},{"title":"局部二值模式(LBP)","date":"2020-09-28T10:01:00.000Z","path":"2020/09/28/ju-bu-er-zhi-mo-shi-lbp/","text":"局部二值模式（英文：Local binary patterns，缩写：LBP）是机器视觉领域中用于分类的一种特征，于1994年被提出。局部二值模式在纹理分类问题上是一个非常强大的特征；局部二值模式是一个简单但非常有效的纹理运算符。它将各个像素与其附近的像素进行比较，并把结果保存为二进制数。由于其辨别力强大和计算简单，局部二值模式纹理算子已经在不同的场景下得到应用。LBP最重要的属性是对诸如光照变化等造成的灰度变化的强健性。它的另外一个重要特性是它的计算简单，这使得它可以对图像进行实时分析。 参考：局部二值模式(Local Binary Patterns)进行纹理分类;局部二值模式–维基百科 一、概念在最简简化的情况下，局部二值模式特征向量可以通过如下方式计算： 将检测窗口切分为区块（cells，例如，每个区块16x16像素）。 对区块中的每个像素，与它的八个邻域像素进行比较（左上、左中、左下、右上等）。可以按照顺时针或者逆时针的顺序进行比较。 对于中心像素大于某个邻域的，设置为0；否则，设置为1。这就获得了一个8位的二进制数（通常情况下会转换为十进制数字），作为该位置的特征。 对每一个区块计算直方图。 此时，可以选择将直方图归一化； 串联所有区块的直方图，这就得到了当前检测窗口的特征向量。 此特征向量可以通过诸如支持向量机(SVM)等机器学习算法来产生一个分类器。 一个有效的扩展被称为“等价模式”，可用于对特征向量降维，以及实现简单的旋转不变算子。其主要根据是一些模式比另一些模式更加常见。当某个LBP只包含从0到1或从1到0的最多两次跳变时，该LBP被定义为一个等价模式。例如，00010000（2次跳变）是一个等价模式，01010100（6次跳变）不是。在计算LBP的直方图时，对于每一个等价模式都各有一个组（bin），而所有非等价模式都被归类到一个单独的组中。使用等价模式，一个区块的特征长度能从256降到59。 二、特性和纹理分类方法对于二维的纹理分析，具有很多潜在的应用。例如，工业表层检查，远程监控，生物制药图像分析等等领域。但是在实际应用时，会存在很多问题。主要的问题在于现实世界中的纹理并不像实验中的那么规整，存在着很多变化，例如： 由于非均匀光源导致的光照变化； 实际的情况下，物体方向是随机的； 空间尺度不一致。 而且，很多纹理分类的方法计算复杂度过高，难以实用化。为了解决这些问题，可以采用改进型的局部二值模式进行纹理分类。改进型的**局部二值模式(Local Binary Patterns)**具有以下优点： 具有灰度不变性； 具有旋转不变性； 能够多分辨率分析； 并且，由于局部二值模式计算复杂度较低，因此，是一种很实用的图像处理方法。这里，我用简单的语言简述一下LBP的各种特性和纹理分类方法。 局部二值模式 首先，我们考虑一幅图像上的一个像素点，以及该像素点的八邻域。如下图(左)所示，我们考虑九宫格内的中心像素点，假设为“6”。周围像素点的数值如图所示。这时，我们将八邻域中，数值大于等于中心像素点的记为“1”，数值小于中心像素点的记为“0”。这时，我们得到下图(右)。这就是基本的局部二值模式(Local Binary Patterns)。之所以叫作“二值”，是因为LBP之后的模式只有0和1两个数值(同理，可以定义三值模式)。 细心的人可能会发现，其实LBP操作相当于：以中心点灰度值做参考，进行局部二值化处理。 这时，我们定义左边中心像素为起始点，逆时针方向为正方向，然后按顺序数LBP的输出值，便会得到一个LBP编码。这样，我们就称中心像素点的LBP值为11110001。同样，我们对一幅图像的所有像素点进行LBP处理，每个像素点都有一个LBP值，这个值在十进制下介于0到255之间。这样得到的图像称为LBP特征图。 1.灰度不变性通常，同样的物体具有同样的纹理特征，但不同时间段对物体的照相会因为光照的不同，导致亮度差异很大。但LBP具有灰度不变性的特征，可以抵抗光照变换所带来的影响。 如下图所示，第一幅图像经过LBP变换后得到LBP值为11110001。而第二幅图像的每个像素在第一幅图像的基础上都增加了50，进行LBP变换后，得到的LBP值仍然是11110001。因为LBP特征反应了局部亮度的相对变化，所以整体增加或减少一个值对LBP特征并没有大的影响，因此得到结论：差分分布对平均光强不敏感。 不过值得注意的是，该灰度不变性仅仅适用于灰度值的单调变化，也就是说，光照的变换要是线性的。 2.圆形局部二值模式为了更加准确的反映纹理的特性，会采用“圆形”的局部二值模式(下面均是如此)。如下图所示，所谓的“圆形”，只是采样点的选择不同于八邻域。它以中心像素点为圆心，R(pixel)为半径画圆，在圆上均匀地选取P个点作为采样点。而后面的处理方法与前面的八邻域LBP方法一致。下图是R=1(pixel)，P=8时的情况。 我们可以发现，R的大小决定了圆的大小，反映了二维空间的尺度；而P的大小决定了采样点数，反映了角度空间的分辨率。同样的，我们还可以改变R和P的值，实现不同的尺度和角度分辨率(如下图)。这也是后面“多分辨率分析”的理论基础。 这里值得注意的是：由于采样点在圆上，所以不一定会准确的落在像素点中。因此可能需要对采样点位置进行插值获得采样点的像素估计值。 3.旋转不变性对于下图的两个模式，其实只有方向不同，在实际中是同一个模式的不同状态。为了克服旋转带来的变化，引入了“旋转不变性”方法。 处理方法如下：两种模式各有一个LBP值，将这个LBP值不断的循环右移，并找到一个右移过程中最小的结果，作为新的LBP值。可见，这两种模式得到的新LBP值相同，属于同一种模式，从此解决了方向变化的问题。其中，”循环右移”的实质是对模式图案不断的旋转。”最小化”过程的实质是寻找能量最低的位置。 对于P=8的LBP，一共有8个采样点，每个采样点可能输出0或1，所以一共有256种局部二值模式。但其中有一些仅仅是方向不同，通过旋转之后可以重合。通过以上旋转不变性处理之后，256种LBP变为了具有“旋转不变性”的36种模式。如下图所示：(特点是任意两种模式经过任意旋转之后不会重合) 4.增强型旋转不变性在实际应用中，我们经过统计会发现， 上图中第一行的9种模式最为常见，而后面的27种模式并不常见。如果将后面的27种模式每种单独分类，会因为它们出现概率太小，而具有一定的随机性，因此分类结果反而不稳定。因此，我们要对这种方法进行改进。 我们对每个LBP上的数值按顺序读一圈，将0-&gt;1和1-&gt;0变化的总次数记为U。对于上图可以发现，第一行模式的U值均小于等于2(反映了平坦或边缘区域)，后面27种模式的U值均大于等于4(变化剧烈，不常见)。如下图。 这样，对于一般LBP进行处理时，我们将U值小于等于2的LBP每个单独分为一类，而对于U值大于等于4的LBP全部归为一类，这样一共有P+2类。 对于P=8的情况下，原先分好的36个LBP就变成了10类。 5.非参数化分类原理对于一幅图像，每个像素点均可以根据上述方法计算出一个LBP值，从而将这个像素归为(P+2)类中的一类。这样我们可以得到一个特征图，图中每点的数值代表像素点的类别，范围为：**0~(P+1)**。最终的纹理特征即为：LBP类别特征图的输出直方图。 如果，样本图像记为S，待匹配的模型记为M。b代表类别，取值为b=1,2…B，其中B=P+2。 则样本S和模型M的匹配程度，使用**最大对数似然(log-likelihood)**统计方法表示： 而这个表达式，是如下式子(log-likelihood ratio)的一个简化版本： 6.多分辨率分析在前面的第2节，我们提到了多分辨率分析的基础是改变不同的R值和P值，实现不同的二维尺度分辨率和不同的角度空间分辨率。在第5节中交代了非参数分类的原则表达式。多分辨率分析，及改变不同的R值和P值，重复以上操作，最终将总的最大似然统计作为分类准则。如下公式所见，一共完成了N种不同的分辨率测度，最终的似然函数为： 如有任何疑问，欢迎一起讨论。","tags":[{"name":"LBP","slug":"LBP","permalink":"http://clarkhedi.github.io/tags/LBP/"}]},{"title":"SVM多分类的两种方式","date":"2020-07-07T14:36:14.000Z","path":"2020/07/07/svm-duo-fen-lei-de-liang-chong-fang-shi/","text":"SVM本身是一个二值分类器，SVM算法最初是为二值分类问题设计的，当处理多类问题时，就需要构造合适的多类分类器。 目前，构造SVM多类分类器的方法主要有两类，直接法、间接法。 来源：CSDN博主「xfChen2」的原创（https://blog.csdn.net/xfChen2/article/details/79621396） 以下内容参考：https://www.cnblogs.com/CheeseZH/p/5265959.html ​ http://blog.csdn.net/rainylove1/article/details/32101113 ​ 王正海《基于决策树多分类支持向量机岩性波谱分类》 一、直接法直接在目标函数上进行修改，将多个分类面的参数求解合并到一个最优化问题中，通过求解该最优化问题“一次性”实现多类分类。这种方法看似简单，但其计算复杂度比较高，实现起来比较困难，只适合用于小型问题中； 二、间接法主要是通过组合多个二分类器来实现多分类器的构造，常见的方法有one-against-one和one-against-all两种。 （1）一对多法（one-versus-rest,简称OVR SVMs）训练时依次把某个类别的样本归为一类,其他剩余的样本归为另一类，这样k个类别的样本就构造出了k个SVM。分类时将未知样本分类为具有最大分类函数值的那类。 假如我有四类要划分（也就是4个Label），他们是A、B、C、D。 于是我在抽取训练集的时候，分别抽取 （1）A所对应的向量作为正集，B，C，D所对应的向量作为负集； （2）B所对应的向量作为正集，A，C，D所对应的向量作为负集； （3）C所对应的向量作为正集，A，B，D所对应的向量作为负集； （4）D所对应的向量作为正集，A，B，C所对应的向量作为负集； 使用这四个训练集分别进行训练，然后的得到四个训练结果文件。 在测试的时候，把对应的测试向量分别利用这四个训练结果文件进行测试。 最后每个测试都有一个结果f1(x),f2(x),f3(x),f4(x)。 于是最终的结果便是这四个值中最大的一个作为分类结果。 评价 优点：训练k个分类器，个数较少，其分类速度相对较快。 缺点： ①每个分类器的训练都是将全部的样本作为训练样本，这样在求解二次规划问题时，训练速度会随着训练样本的数量的增加而急剧减慢； ②同时由于负类样本的数据要远远大于正类样本的数据，从而出现了样本不对称的情况，且这种情况随着训练数据的增加而趋向严重。解决不对称的问题可以引入不同的惩罚因子，对样本点来说较少的正类采用较大的惩罚因子C； ③还有就是当有新的类别加进来时，需要对所有的模型进行重新训练。 从“一对多”的方法又衍生出基于决策树的分类： 首先将所有类别分为两个类别，再将子类进一步划分为两个次级子类，如此循环下去，直到所有的节点都只包含一个单独的类别为止，此节点也是二叉树树种的叶子。该分类将原有的分类问题同样分解成了一系列的两类分类问题，其中两个子类间的分类函数采用SVM。下图引用出自于王正海《基于决策树多分类支持向量机岩性波谱分类》 （2）一对一法（one-versus-one,简称OVO SVMs或者pairwise）其做法是在任意两类样本之间设计一个SVM，因此k个类别的样本就需要设计k(k-1)/2个SVM。 当对一个未知样本进行分类时，最后得票最多的类别即为该未知样本的类别。 Libsvm中的多类分类就是根据这个方法实现的。 假设有四类A,B,C,D四类。在训练的时候我选择A,B; A,C; A,D; B,C; B,D;C,D所对应的向量作为训练集，然后得到六个训练结果，在测试的时候，把对应的向量分别对六个结果进行测试，然后采取投票形式，最后得到一组结果。 投票是这样的： A=B=C=D=0; (A,B)-classifier 如果是A win,则A=A+1;otherwise,B=B+1; (A,C)-classifier 如果是A win,则A=A+1;otherwise, C=C+1; … (C,D)-classifier 如果是A win,则C=C+1;otherwise,D=D+1; The decision is the Max(A,B,C,D) 评价：这种方法虽然好,但是当类别很多的时候,model的个数是n*(n-1)/2,代价还是相当大的。 评价： 优点：不需要重新训练所有的SVM，只需要重新训练和增加语音样本相关的分类器。在训练单个模型时，相对速度较快。 缺点：所需构造和测试的二值分类器的数量关于k成二次函数增长，总训练时间和测试时间相对较慢。 从“一对一”的方式出发，出现了有向无环图（DirectedAcyclic Graph）的分类方法。 三、总结直接方法尽管看起来简洁，但是在最优化问题求解过程中的变量远远多于第一类方法，训练速度不及间接方法，而且在分类精度上也不占优。当训练样本数非常大时，这一问题更加突出。正因如此，间接方法更为常用。","tags":[{"name":"SVM","slug":"SVM","permalink":"http://clarkhedi.github.io/tags/SVM/"}]},{"title":"SVM入门（十）将SVM用于多类分类","date":"2020-07-06T23:42:43.000Z","path":"2020/07/06/svm-ru-men-shi-jiang-svm-yong-yu-duo-lei-fen-lei/","text":"从 SVM的那几张图可以看出来，SVM是一种典型的两类分类器，即它只回答属于正类还是负类的问题。而现实中要解决的问题，往往是多类的问题（少部分例外，例如垃圾邮件过滤，就只需要确定“是”还是“不是”垃圾邮件），比如文本分类，比如数字识别。如何由两类分类器得到多类分类器，就是一个值得研究的问题。 还以文本分类为例，现成的方法有很多，其中一种一劳永逸的方法，就是真的一次性考虑所有样本，并求解一个多目标函数的优化问题，一次性得到多个分类面，就像下图这样： 多个超平面把空间划分为多个区域，每个区域对应一个类别，给一篇文章，看它落在哪个区域就知道了它的分类。 看起来很美对不对？只可惜这种算法还基本停留在纸面上，因为一次性求解的方法计算量实在太大，大到无法实用的地步。 稍稍退一步，我们就会想到所谓“一类对其余”的方法，就是每次仍然解一个两类分类的问题。比如我们有5个类别，第一次就把类别1的样本定为正样本，其余2，3，4，5的样本合起来定为负样本，这样得到一个两类分类器，它能够指出一篇文章是还是不是第1类的；第二次我们把类别2 的样本定为正样本，把1，3，4，5的样本合起来定为负样本，得到一个分类器，如此下去，我们可以得到5个这样的两类分类器（总是和类别的数目一致）。到了有文章需要分类的时候，我们就拿着这篇文章挨个分类器的问：是属于你的么？是属于你的么？哪个分类器点头说是了，文章的类别就确定了。这种方法的好处是每个优化问题的规模比较小，而且分类的时候速度很快（只需要调用5个分类器就知道了结果）。但有时也会出现两种很尴尬的情况，例如拿一篇文章问了一圈，每一个分类器都说它是属于它那一类的，或者每一个分类器都说它不是它那一类的，前者叫分类重叠现象，后者叫不可分类现象。分类重叠倒还好办，随便选一个结果都不至于太离谱，或者看看这篇文章到各个超平面的距离，哪个远就判给哪个。不可分类现象就着实难办了，只能把它分给第6个类别了……更要命的是，本来各个类别的样本数目是差不多的，但“其余”的那一类样本数总是要数倍于正类（因为它是除正类以外其他类别的样本之和嘛），这就人为的造成了上一节所说的“数据集偏斜”问题。 因此我们还得再退一步，还是解两类分类问题，还是每次选一个类的样本作正类样本，而负类样本则变成只选一个类（称为“一对一单挑”的方法，哦，不对，没有单挑，就是“一对一”的方法，呵呵），这就避免了偏斜。因此过程就是算出这样一些分类器，第一个只回答“是第1类还是第2类”，第二个只回答“是第1类还是第3类”，第三个只回答“是第1类还是第4类”，如此下去，你也可以马上得出，这样的分类器应该有5 X 4/2=10个（通式是，如果有k个类别，则总的两类分类器数目为k(k-1)/2）。虽然分类器的数目多了，但是在训练阶段（也就是算出这些分类器的分类平面时）所用的总时间却比“一类对其余”方法少很多，在真正用来分类的时候，把一篇文章扔给所有分类器，第一个分类器会投票说它是“1”或者“2”，第二个会说它是“1”或者“3”，让每一个都投上自己的一票，最后统计票数，如果类别“1”得票最多，就判这篇文章属于第1类。这种方法显然也会有分类重叠的现象，但不会有不可分类现象，因为总不可能所有类别的票数都是0。看起来够好么？其实不然，想想分类一篇文章，我们调用了多少个分类器？10个，这还是类别数为5的时候，类别数如果是1000，要调用的分类器数目会上升至约500,000个（类别数的平方量级）。这如何是好？ 看来我们必须再退一步，在分类的时候下功夫，我们还是像一对一方法那样来训练，只是在对一篇文章进行分类之前，我们先按照下面图的样子来组织分类器（如你所见，这是一个有向无环图，因此这种方法也叫做DAG SVM） 这样在分类时,我们就可以先问分类器“1对5”（意思是它能够回答“是第1类还是第5类”），如果它回答5，我们就往左走，再问“2对5”这个分类器，如果它还说是“5”，我们就继续往左走，这样一直问下去，就可以得到分类结果。好处在哪？我们其实只调用了4个分类器（如果类别数是k，则只调用k-1个），分类速度飞快，且没有分类重叠和不可分类现象！缺点在哪？假如最一开始的分类器回答错误（明明是类别1的文章，它说成了5），那么后面的分类器是无论如何也无法纠正它的错误的（因为后面的分类器压根没有出现“1”这个类别标签），其实对下面每一层的分类器都存在这种错误向下累积的现象。。 不过不要被DAG方法的错误累积吓倒，错误累积在一对其余和一对一方法中也都存在，DAG方法好于它们的地方就在于，累积的上限，不管是大是小，总是有定论的，有理论证明。而一对其余和一对一方法中，尽管每一个两类分类器的泛化误差限是知道的，但是合起来做多类分类的时候，误差上界是多少，没人知道，这意味着准确率低到0也是有可能的，这多让人郁闷。 而且现在DAG方法根节点的选取（也就是如何选第一个参与分类的分类器），也有一些方法可以改善整体效果，我们总希望根节点少犯错误为好，因此参与第一次分类的两个类别，最好是差别特别特别大，大到以至于不太可能把他们分错；或者我们就总取在两类分类中正确率最高的那个分类器作根节点，或者我们让两类分类器在分类的时候，不光输出类别的标签，还输出一个类似“置信度”的东东，当它对自己的结果不太自信的时候，我们就不光按照它的输出走，把它旁边的那条路也走一走，等等。 大Tips：SVM的计算复杂度 使用SVM进行分类的时候，实际上是训练和分类两个完全不同的过程，因而讨论复杂度就不能一概而论，我们这里所说的主要是训练阶段的复杂度，即解那个二次规划问题的复杂度。对这个问题的解，基本上要划分为两大块，解析解和数值解。 解析解就是理论上的解，它的形式是表达式，因此它是精确的，一个问题只要有解（无解的问题还跟着掺和什么呀，哈哈），那它的解析解是一定存在的。当然存在是一回事，能够解出来，或者可以在可以承受的时间范围内解出来，就是另一回事了。对SVM来说，求得解析解的时间复杂度最坏可以达到O(Nsv3)，其中Nsv是支持向量的个数，而虽然没有固定的比例，但支持向量的个数多少也和训练集的大小有关。 数值解就是可以使用的解，是一个一个的数，往往都是近似解。求数值解的过程非常像穷举法，从一个数开始，试一试它当解效果怎样，不满足一定条件（叫做停机条件，就是满足这个以后就认为解足够精确了，不需要继续算下去了）就试下一个，当然下一个数不是乱选的，也有一定章法可循。有的算法，每次只尝试一个数，有的就尝试多个，而且找下一个数字（或下一组数）的方法也各不相同，停机条件也各不相同，最终得到的解精度也各不相同，可见对求数值解的复杂度的讨论不能脱开具体的算法。 一个具体的算法，Bunch-Kaufman训练算法，典型的时间复杂度在O(Nsv3+LNsv2+dLNsv)和O(dL2)之间，其中Nsv是支持向量的个数，L是训练集样本的个数，d是每个样本的维数（原始的维数，没有经过向高维空间映射之前的维数）。复杂度会有变化，是因为它不光跟输入问题的规模有关（不光和样本的数量，维数有关），也和问题最终的解有关（即支持向量有关），如果支持向量比较少，过程会快很多，如果支持向量很多，接近于样本的数量，就会产生O(dL2)这个十分糟糕的结果（给10，000个样本，每个样本1000维，基本就不用算了，算不出来，呵呵，而这种输入规模对文本分类来说太正常了）。 这样再回头看就会明白为什么一对一方法尽管要训练的两类分类器数量多，但总时间实际上比一对其余方法要少了，因为一对其余方法每次训练都考虑了所有样本（只是每次把不同的部分划分为正类或者负类而已），自然慢上很多。","tags":[{"name":"SVM","slug":"SVM","permalink":"http://clarkhedi.github.io/tags/SVM/"}]},{"title":"SVM入门（九）松弛变量（续）","date":"2020-07-06T23:12:23.000Z","path":"2020/07/06/svm-ru-men-jiu-song-chi-bian-liang-xu/","text":"接下来要说的东西其实不是松弛变量本身，但由于是为了使用松弛变量才引入的，因此放在这里也算合适，那就是惩罚因子C。回头看一眼引入了松弛变量以后的优化问题： 注意其中C的位置，也可以回想一下C所起的作用（表征你有多么重视离群点，C越大越重视，越不想丢掉它们）。这个式子是以前做SVM的人写的，大家也就这么用，但没有任何规定说必须对所有的松弛变量都使用同一个惩罚因子，我们完全可以给每一个离群点都使用不同的C，这时就意味着你对每个样本的重视程度都不一样，有些样本丢了也就丢了，错了也就错了，这些就给一个比较小的C；而有些样本很重要，决不能分类错误（比如中央下达的文件啥的，笑），就给一个很大的C。 当然实际使用的时候并没有这么极端，但一种很常用的变形可以用来解决分类问题中样本的“偏斜”问题。 先来说说样本的偏斜问题，也叫数据集偏斜（unbalanced），它指的是参与分类的两个类别（也可以指多个类别）样本数量差异很大。比如说正类有10，000个样本，而负类只给了100个，这会引起的问题显而易见，可以看看下面的图： 方形的点是负类。H，H1，H2是根据给的样本算出来的分类面，由于负类的样本很少很少，所以有一些本来是负类的样本点没有提供，比如图中两个灰色的方形点，如果这两个点有提供的话，那算出来的分类面应该是H’，H2’和H1，他们显然和之前的结果有出入，实际上负类给的样本点越多，就越容易出现在灰色点附近的点，我们算出的结果也就越接近于真实的分类面。但现在由于偏斜的现象存在，使得数量多的正类可以把分类面向负类的方向“推”，因而影响了结果的准确性。 对付数据集偏斜问题的方法之一就是在惩罚因子上作文章，想必大家也猜到了，那就是给样本数量少的负类更大的惩罚因子，表示我们重视这部分样本（本来数量就少，再抛弃一些，那人家负类还活不活了），因此我们的目标函数中因松弛变量而损失的部分就变成了： 其中i=1…p都是正样本，j=p+1…p+q都是负样本。libSVM这个算法包在解决偏斜问题的时候用的就是这种方法。 那C+和C-怎么确定呢？它们的大小是试出来的（参数调优），但是他们的比例可以有些方法来确定。咱们先假定说C+是5这么大，那确定C-的一个很直观的方法就是使用两类样本数的比来算，对应到刚才举的例子，C-就可以定为500这么大（因为10，000：100=100：1嘛）。 但是这样并不够好，回看刚才的图，你会发现正类之所以可以“欺负”负类，其实并不是因为负类样本少，真实的原因是负类的样本分布的不够广（没扩充到负类本应该有的区域）。说一个具体点的例子，现在想给政治类和体育类的文章做分类，政治类文章很多，而体育类只提供了几篇关于篮球的文章，这时分类会明显偏向于政治类，如果要给体育类文章增加样本，但增加的样本仍然全都是关于篮球的（也就是说，没有足球，排球，赛车，游泳等等），那结果会怎样呢？虽然体育类文章在数量上可以达到与政治类一样多，但过于集中了，结果仍会偏向于政治类！所以给C+和C-确定比例更好的方法应该是衡量他们分布的程度。比如可以算算他们在空间中占据了多大的体积，例如给负类找一个超球——就是高维空间里的球啦——它可以包含所有负类的样本，再给正类找一个，比比两个球的半径，就可以大致确定分布的情况。显然半径大的分布就比较广，就给小一点的惩罚因子。 但是这样还不够好，因为有的类别样本确实很集中，这不是提供的样本数量多少的问题，这是类别本身的特征（就是某些话题涉及的面很窄，例如计算机类的文章就明显不如文化类的文章那么“天马行空”），这个时候即便超球的半径差异很大，也不应该赋予两个类别不同的惩罚因子。 看到这里读者一定疯了，因为说来说去，这岂不成了一个解决不了的问题？然而事实如此，完全的方法是没有的，根据需要，选择实现简单又合用的就好（例如libSVM就直接使用样本数量的比）。","tags":[{"name":"SVM","slug":"SVM","permalink":"http://clarkhedi.github.io/tags/SVM/"}]},{"title":"SVM入门（八）松弛变量","date":"2020-07-06T22:45:15.000Z","path":"2020/07/06/svm-ru-men-ba-song-chi-bian-liang/","text":"现在我们已经把一个本来线性不可分的文本分类问题，通过映射到高维空间而变成了线性可分的。就像下图这样： 圆形和方形的点各有成千上万个（毕竟，这就是我们训练集中文档的数量嘛，当然很大了）。现在想象我们有另一个训练集，只比原先这个训练集多了一篇文章，映射到高维空间以后（当然，也使用了相同的核函数），也就多了一个样本点，但是这个样本的位置是这样的： 就是图中黄色那个点，它是方形的，因而它是负类的一个样本，这单独的一个样本，使得原本线性可分的问题变成了线性不可分的。这样类似的问题（仅有少数点线性不可分）叫做“近似线性可分”的问题。 以我们人类的常识来判断，说有一万个点都符合某种规律（因而线性可分），有一个点不符合，那这一个点是否就代表了分类规则中我们没有考虑到的方面呢（因而规则应该为它而做出修改）？ 其实我们会觉得，更有可能的是，这个样本点压根就是错误，是噪声，是提供训练集的同学人工分类时一打瞌睡错放进去的。所以我们会简单的忽略这个样本点，仍然使用原来的分类器，其效果丝毫不受影响。 但这种对噪声的容错性是人的思维带来的，我们的程序可没有。由于我们原本的优化问题的表达式中，确实要考虑所有的样本点（不能忽略某一个，因为程序它怎么知道该忽略哪一个呢？），在此基础上寻找正负类之间的最大几何间隔，而几何间隔本身代表的是距离，是非负的，像上面这种有噪声的情况会使得整个问题无解。这种解法其实也叫做“硬间隔”分类法，因为他硬性的要求所有样本点都满足和分类平面间的距离必须大于某个值。 因此由上面的例子中也可以看出，硬间隔的分类法其结果容易受少数点的控制，这是很危险的（尽管有句话说真理总是掌握在少数人手中，但那不过是那一小撮人聊以自慰的词句罢了，咱还是得民主）。 但解决方法也很明显，就是仿照人的思路，允许一些点到分类平面的距离不满足原先的要求。由于不同的训练集各点的间距尺度不太一样，因此用间隔（而不是几何间隔）来衡量有利于我们表达形式的简洁。我们原先对样本点的要求是： 意思是说离分类面最近的样本点函数间隔也要比1大。如果要引入容错性，就给1这个硬性的阈值加一个松弛变量，即允许 因为松弛变量是非负的，因此最终的结果是要求间隔可以比1小。但是当某些点出现这种间隔比1小的情况时（这些点也叫离群点），意味着我们放弃了对这些点的精确分类，而这对我们的分类器来说是种损失。但是放弃这些点也带来了好处，那就是使分类面不必向这些点的方向移动，因而可以得到更大的几何间隔（在低维空间看来，分类边界也更平滑）。显然我们必须权衡这种损失和好处。好处很明显，我们得到的分类间隔越大，好处就越多。回顾我们原始的硬间隔分类对应的优化问题： ||w||2就是我们的目标函数（当然系数可有可无），希望它越小越好，因而损失就必然是一个能使之变大的量（能使它变小就不叫损失了，我们本来就希望目标函数值越小越好）。那如何来衡量损失，有两种常用的方式，有人喜欢用 而有人喜欢用 其中l都是样本的数目。两种方法没有大的区别。如果选择了第一种，得到的方法的就叫做二阶软间隔分类器，第二种就叫做一阶软间隔分类器。把损失加入到目标函数里的时候，就需要一个惩罚因子（cost，也就是libSVM的诸多参数中的C），原来的优化问题就变成了下面这样： 这个式子有这么几点要注意： 一是并非所有的样本点都有一个松弛变量与其对应。实际上只有“离群点”才有，或者也可以这么看，所有没离群的点松弛变量都等于0（对负类来说，离群点就是在前面图中，跑到H2右侧的那些负样本点，对正类来说，就是跑到H1左侧的那些正样本点）。 二是松弛变量的值实际上标示出了对应的点到底离群有多远，值越大，点就越远。 三是惩罚因子C决定了你有多重视离群点带来的损失，显然当所有离群点的松弛变量的和一定时，你定的C越大，对目标函数的损失也越大，此时就暗示着你非常不愿意放弃这些离群点，最极端的情况是你把C定为无限大，这样只要稍有一个点离群，目标函数的值马上变成无限大，马上让问题变成无解，这就退化成了硬间隔问题。 四是惩罚因子C不是一个变量，整个优化问题在解的时候，C是一个你必须事先指定的值，指定这个值以后，解一下，得到一个分类器，然后用测试数据看看结果怎么样，如果不够好，换一个C的值，再解一次优化问题，得到另一个分类器，再看看效果，如此就是一个参数寻优的过程，但这和优化问题本身决不是一回事，优化问题在解的过程中，C一直是定值，要记住。 五是尽管加了松弛变量这么一说，但这个优化问题仍然是一个优化问题（汗，这不废话么），解它的过程比起原始的硬间隔问题来说，没有任何更加特殊的地方。 从大的方面说优化问题解的过程，就是先试着确定一下w，也就是确定了前面图中的三条直线，这时看看间隔有多大，又有多少点离群，把目标函数的值算一算，再换一组三条直线（你可以看到，分类的直线位置如果移动了，有些原来离群的点会变得不再离群，而有的本来不离群的点会变成离群点），再把目标函数的值算一算，如此往复（迭代），直到最终找到目标函数最小时的w。 啰嗦了这么多，读者一定可以马上自己总结出来，松弛变量也就是个解决线性不可分问题的方法罢了，但是回想一下，核函数的引入不也是为了解决线性不可分的问题么？为什么要为了一个问题使用两种方法呢？ 其实两者还有微妙的不同。一般的过程应该是这样，还以文本分类为例。在原始的低维空间中，样本相当的不可分，无论你怎么找分类平面，总会有大量的离群点，此时用核函数向高维空间映射一下，虽然结果仍然是不可分的，但比原始空间里的要更加接近线性可分的状态（就是达到了近似线性可分的状态），此时再用松弛变量处理那些少数“冥顽不化”的离群点，就简单有效得多啦。 本节中的（式1）也确实是支持向量机最最常用的形式。至此一个比较完整的支持向量机框架就有了，简单说来，支持向量机就是使用了核函数的软间隔线性分类法。 下一节会说说松弛变量剩下的一点点东西，顺便搞个读者调查，看看大家还想侃侃SVM的哪些方面。","tags":[{"name":"SVM","slug":"SVM","permalink":"http://clarkhedi.github.io/tags/SVM/"}]},{"title":"SVM入门（七）为何需要核函数","date":"2020-07-06T22:20:39.000Z","path":"2020/07/06/svm-ru-men-qi-wei-he-xu-yao-he-han-shu/","text":"生存？还是毁灭？——哈姆雷特 可分？还是不可分？——支持向量机 之前一直在讨论的线性分类器,器如其名（汗，这是什么说法啊），只能对线性可分的样本做处理。如果提供的样本线性不可分，结果很简单，线性分类器的求解程序会无限循环，永远也解不出来。这必然使得它的适用范围大大缩小，而它的很多优点我们实在不原意放弃，怎么办呢？是否有某种方法，让线性不可分的数据变得线性可分呢？ 有！其思想说来也简单，来用一个二维平面中的分类问题作例子，你一看就会明白。事先声明，下面这个例子是网络早就有的，我一时找不到原作者的正确信息，在此借用，并加进了我自己的解说而已。例子是下面这张图： 我们把横轴上端点a和b之间红色部分里的所有点定为正类，两边的黑色部分里的点定为负类。试问能找到一个线性函数把两类正确分开么？不能，因为二维空间里的线性函数就是指直线，显然找不到符合条件的直线。 但我们可以找到一条曲线，例如下面这一条： 显然通过点在这条曲线的上方还是下方就可以判断点所属的类别（你在横轴上随便找一点，算算这一点的函数值，会发现负类的点函数值一定比0大，而正类的一定比0小）。这条曲线就是我们熟知的二次曲线，它的函数表达式可以写为： 问题只是它不是一个线性函数，但是，下面要注意看了，新建一个向量y和a： 这样g(x)就可以转化为f(y)=&lt;a,y&gt;，你可以把y和a分别回带一下，看看等不等于原来的g(x)。用内积的形式写你可能看不太清楚，实际上f(y)的形式就是： ​ g(x)=f(y)=ay 在任意维度的空间中，这种形式的函数都是一个线性函数（只不过其中的a和y都是多维向量罢了），因为自变量y的次数不大于1。 看出妙在哪了么？原来在二维空间中一个线性不可分的问题，映射到四维空间后，变成了线性可分的！因此这也形成了我们最初想解决线性不可分问题的基本思路——向高维空间转化，使其变得线性可分。 而转化最关键的部分就在于找到x到y的映射方法。遗憾的是，如何找到这个映射，没有系统性的方法（也就是说，纯靠猜和凑）。具体到我们的文本分类问题，文本被表示为上千维的向量，即使维数已经如此之高，也常常是线性不可分的，还要向更高的空间转化。其中的难度可想而知。 小Tips：为什么说f(y)=ay是四维空间里的函数? 12345678910大家可能一时没看明白。回想一下我们二维空间里的函数定义 g(x)&#x3D;ax+b变量x是一维的，为什么说它是二维空间里的函数呢？因为还有一个变量我们没写出来，它的完整形式其实是 y&#x3D;g(x)&#x3D;ax+b即 y&#x3D;ax+b看看，有几个变量？两个。那是几维空间的函数？（作者五岁的弟弟答：五维的。作者：……）再看看f(y)&#x3D;ay里面的y是三维的变量，那f(y)是几维空间里的函数？（作者五岁的弟弟答：还是五维的。作者：……） 用一个具体文本分类的例子来看看这种向高维空间映射从而分类的方法如何运作，想象一下，我们文本分类问题的原始空间是1000维的（即每个要被分类的文档被表示为一个1000维的向量），在这个维度上问题是线性不可分的。现在我们有一个2000维空间里的线性函数： ​ f(x’)=&lt;w’,x’&gt;+b 注意向量的右上角有个 ’哦。它能够将原问题变得可分。式中的 w’和x’都是2000维的向量，只不过w’是定值，而x’是变量（好吧,严格说来这个函数是2001维的,哈哈），现在我们的输入呢，是一个1000维的向量x，分类的过程是先把x变换为2000维的向量x’，然后求这个变换后的向量x’与向量w’的内积，再把这个内积的值和b相加，就得到了结果，看结果大于阈值还是小于阈值就得到了分类结果。 你发现了什么？我们其实只关心那个高维空间里内积的值，那个值算出来了，分类结果就算出来了。而从理论上说， x’是经由x变换来的，因此广义上可以把它叫做x的函数（有一个x，就确定了一个x’，对吧，确定不出第二个），而w’是常量，它是一个低维空间里的常量w经过变换得到的，所以给了一个w 和x的值，就有一个确定的f(x’)值与其对应。这让我们幻想，是否能有这样一种函数K(w,x),他接受低维空间的输入值，却能算出高维空间的内积值&lt;w’,x’&gt;？ 如果有这样的函数，那么当给了一个低维空间的输入x以后， ​ g(x)=K(w,x)+b ​ f(x’)=&lt;w’,x’&gt;+b 这两个函数的计算结果就完全一样，我们也就用不着费力找那个映射关系，直接拿低维的输入往g(x)里面代就可以了（再次提醒，这回的g(x)就不是线性函数啦，因为你不能保证K(w,x)这个表达式里的x次数不高于1哦）。 万幸的是，这样的K(w,x)确实存在（发现凡是我们人类能解决的问题，大都是巧得不能再巧，特殊得不能再特殊的问题，总是恰好有些能投机取巧的地方才能解决，由此感到人类的渺小），它被称作核函数（核，kernel），而且还不止一个，事实上，只要是满足了Mercer条件的函数，都可以作为核函数。核函数的基本作用就是接受两个低维空间里的向量，能够计算出经过某个变换后在高维空间里的向量内积值。几个比较常用的核函数，俄，教课书里都列过，我就不敲了（懒！）。 回想我们上节说的求一个线性分类器，它的形式应该是： 现在这个就是高维空间里的线性函数（为了区别低维和高维空间里的函数和向量，我改了函数的名字，并且给w和x都加上了 ’），我们就可以用一个低维空间里的函数（再一次的，这个低维空间里的函数就不再是线性的啦）来代替。 又发现什么了？f(x’) 和g(x)里的α，y，b全都是一样一样的！这就是说，尽管给的问题是线性不可分的，但是我们就硬当它是线性问题来求解，只不过求解过程中，凡是要求内积的时候就用你选定的核函数来算。这样求出来的α再和你选定的核函数一组合，就得到分类器啦！ 明白了以上这些，会自然的问接下来两个问题： 1． 既然有很多的核函数，针对具体问题该怎么选择？ 2． 如果使用核函数向高维空间映射后，问题仍然是线性不可分的，那怎么办？ 第一个问题现在就可以回答你：对核函数的选择，现在还缺乏指导原则！各种实验的观察结果（不光是文本分类）的确表明，某些问题用某些核函数效果很好，用另一些就很差，但是一般来讲，径向基核函数是不会出太大偏差的一种，首选。（我做文本分类系统的时候，使用径向基核函数，没有参数调优的情况下，绝大部分类别的准确和召回都在85%以上，可见。虽然libSVM的作者林智仁认为文本分类用线性核函数效果更佳，待考证） 对第二个问题的解决则引出了我们下一节的主题：松弛变量。","tags":[{"name":"SVM","slug":"SVM","permalink":"http://clarkhedi.github.io/tags/SVM/"}]},{"title":"SVM入门（六）线性分类器的求解——问题的转化，直观角度","date":"2020-07-06T21:58:20.000Z","path":"2020/07/06/svm-ru-men-liu-xian-xing-fen-lei-qi-de-qiu-jie-wen-ti-de-zhuan-hua-zhi-guan-jiao-du/","text":"让我再一次比较完整的重复一下我们要解决的问题：我们有属于两个类别的样本点（并不限定这些点在二维空间中）若干，如下图。 圆形的样本点定为正样本（连带着，我们可以把正样本所属的类叫做正类），方形的点定为负例。我们想求得这样一个线性函数（在n维空间中的线性函数）： g(x)=wx+b 使得所有属于正类的点x+代入以后有g(x+)≥1，而所有属于负类的点x-代入后有g(x-)≤-1（之所以总跟1比较，无论正一还是负一，都是因为我们固定了间隔为1，注意间隔和几何间隔的区别）。代入g(x)后的值如果在1和-1之间，我们就拒绝判断。 求这样的g(x)的过程就是求w（一个n维向量）和b（一个实数）两个参数的过程（但实际上只需要求w，求得以后找某些样本点代入就可以求得b）。因此在求g(x)的时候，w才是变量。 你肯定能看出来，一旦求出了w（也就求出了b），那么中间的直线H就知道了（因为它就是wx+b=0嘛，哈哈），那么H1和H2也就知道了（因为三者是平行的，而且相隔的距离还是||w||决定的）。那么w是谁决定的？显然是你给的样本决定的，一旦你在空间中给出了那些个样本点，三条直线的位置实际上就唯一确定了（因为我们求的是最优的那三条，当然是唯一的），我们解优化问题的过程也只不过是把这个确定了的东西算出来而已。 样本确定了w，用数学的语言描述，就是w可以表示为样本的某种组合： w=α1x1+α2x2+…+αnxn 式子中的αi是一个一个的数（在严格的证明过程中，这些α被称为拉格朗日乘子），而xi是样本点，因而是向量，n就是总样本点的个数。为了方便描述，以下开始严格区别数字与向量的乘积和向量间的乘积，我会用α1x1表示数字和向量的乘积，而用&lt;x1,x2&gt;表示向量x1,x2的内积（也叫点积，注意与向量叉积的区别）。因此g(x)的表达式严格的形式应该是： g(x)=&lt;w,x&gt;+b 但是上面的式子还不够好，你回头看看图中正样本和负样本的位置，想像一下，我不动所有点的位置，而只是把其中一个正样本点定为负样本点（也就是把一个点的形状从圆形变为方形），结果怎么样？三条直线都必须移动（因为对这三条直线的要求是必须把方形和圆形的点正确分开）！这说明w不仅跟样本点的位置有关，还跟样本的类别有关（也就是和样本的“标签”有关）。因此用下面这个式子表示才算完整： w=α1y1x1+α2y2x2+…+αnynxn （式1） 其中的yi就是第i个样本的标签，它等于1或者-1。其实以上式子的那一堆拉格朗日乘子中，只有很少的一部分不等于0（不等于0才对w起决定作用），这部分不等于0的拉格朗日乘子后面所乘的样本点，其实都落在H1和H2上，也正是这部分样本（而不需要全部样本）唯一的确定了分类函数，当然，更严格的说，这些样本的一部分就可以确定，因为例如确定一条直线，只需要两个点就可以，即便有三五个都落在上面，我们也不是全都需要。这部分我们真正需要的样本点，就叫做支持（撑）向量！（名字还挺形象吧，他们“撑”起了分界线） 式子也可以用求和符号简写一下： 因此原来的g(x)表达式可以写为： 注意式子中x才是变量，也就是你要分类哪篇文档，就把该文档的向量表示代入到 x的位置，而所有的xi统统都是已知的样本。还注意到式子中只有xi和x是向量，因此一部分可以从内积符号中拿出来，得到g(x)的式子为： 发现了什么？w不见啦！从求w变成了求α。 但肯定有人会说，这并没有把原问题简化呀。嘿嘿，其实简化了，只不过在你看不见的地方，以这样的形式描述问题以后，我们的优化问题少了很大一部分不等式约束（记得这是我们解不了极值问题的万恶之源）。但是接下来先跳过线性分类器求解的部分，来看看 SVM在线性分类器上所做的重大改进——核函数。","tags":[{"name":"SVM","slug":"SVM","permalink":"http://clarkhedi.github.io/tags/SVM/"}]},{"title":"SVM入门（五）线性分类器的求解——问题的描述Part2","date":"2020-07-06T21:36:36.000Z","path":"2020/07/06/svm-ru-men-wu-xian-xing-fen-lei-qi-de-qiu-jie-wen-ti-de-miao-shu-part2/","text":"从最一般的定义上说，一个求最小值的问题就是一个优化问题（也叫寻优问题，更文绉绉的叫法是规划——Programming），它同样由两部分组成，目标函数和约束条件，可以用下面的式1表示： 约束条件用函数c来表示，就是constrain的意思啦。你可以看出一共有p+q个约束条件，其中p个是不等式约束，q个等式约束。 关于这个式子可以这样来理解：式中的x是自变量，但不限定它的维数必须为1（视乎你解决的问题空间维数，对我们的文本分类来说，那可是成千上万啊）。要求f(x)在哪一点上取得最小值（反倒不太关心这个最小值到底是多少，关键是哪一点），但不是在整个空间里找，而是在约束条件所划定的一个有限的空间里找，这个有限的空间就是优化理论里所说的可行域。注意可行域中的每一个点都要求满足所有p+q个条件，而不是满足其中一条或几条就可以（切记，要满足每个约束），同时可行域边界上的点有一个额外好的特性，它们可以使不等式约束取得等号！而边界内的点不行。 关于可行域还有个概念不得不提，那就是凸集，凸集是指有这么一个点的集合，其中任取两个点连一条直线，这条线上的点仍然在这个集合内部，因此说“凸”是很形象的（一个反例是，二维平面上，一个月牙形的区域就不是凸集，你随便就可以找到两个点违反了刚才的规定）。 回头再来看我们线性分类器问题的描述，可以看出更多的东西，式2如下所示： 在这个问题中，自变量就是w，而目标函数是w的二次函数，所有的约束条件都是w的线性函数（哎，千万不要把xi当成变量，它代表样本，是已知的），这种规划问题有个很有名气的称呼——二次规划（Quadratic Programming，QP），而且可以更进一步的说，由于它的可行域是一个凸集，因此它是一个凸二次规划。 一下子提了这么多术语，实在不是为了让大家以后能向别人炫耀学识的渊博，这其实是我们继续下去的一个重要前提，因为在动手求一个问题的解之前（好吧，我承认，是动计算机求……），我们必须先问自己：这个问题是不是有解？如果有解，是否能找到？ 对于一般意义上的规划问题，两个问题的答案都是不一定，但凸二次规划让人喜欢的地方就在于，它有解（教科书里面为了严谨，常常加限定成分，说它有全局最优解，由于我们想找的本来就是全局最优的解，所以不加也罢），而且可以找到！（当然，依据你使用的算法不同，找到这个解的速度，行话叫收敛速度，会有所不同） 对比（式2）和（式1）还可以发现，我们的线性分类器问题只有不等式约束，因此形式上看似乎比一般意义上的规划问题要简单，但解起来却并非如此。 因为我们实际上并不知道该怎么解一个带约束的优化问题。如果你仔细回忆一下高等数学的知识，会记得我们可以轻松的解一个不带任何约束的优化问题（实际上就是当年背得烂熟的函数求极值嘛，求导再找0点呗，谁不会啊？笑），我们甚至还会解一个只带等式约束的优化问题，也是背得烂熟的，求条件极值，记得么，通过添加拉格朗日乘子，构造拉格朗日函数，来把这个问题转化为无约束的优化问题云云（如果你一时没想通，我提醒一下，构造出的拉格朗日函数就是转化之后的问题形式，它显然没有带任何条件）。 读者问：如果只带等式约束的问题可以转化为无约束的问题而得以求解，那么可不可以把带不等式约束的问题向只带等式约束的问题转化一下而得以求解呢？ 聪明，可以，实际上我们也正是这么做的。下一节就来说说如何做这个转化，一旦转化完成，求解对任何学过高等数学的人来说，都是小菜一碟啦。","tags":[{"name":"SVM","slug":"SVM","permalink":"http://clarkhedi.github.io/tags/SVM/"}]},{"title":"SVM入门（四）线性分类器的求解——问题的描述Part1","date":"2020-07-06T21:18:45.000Z","path":"2020/07/06/svm-ru-men-si-xian-xing-fen-lei-qi-de-qiu-jie-wen-ti-de-miao-shu-part1/","text":"上节说到我们有了一个线性分类函数，也有了判断解优劣的标准——即有了优化的目标，这个目标就是最大化几何间隔，但是看过一些关于SVM的论文的人一定记得什么优化的目标是要最小化||w||这样的说法，这是怎么回事呢？回头再看看我们对间隔和几何间隔的定义： 间隔：δ=y(wx+b)=|g(x)| 几何间隔： 可以看出δ=||w||*δ几何。注意到几何间隔与||w||是成反比的，因此最大化几何间隔与最小化||w||完全是一回事。而我们常用的方法并不是固定||w||的大小而寻求最大几何间隔，而是固定间隔（例如固定为1），寻找最小的||w||。 而凡是求一个函数的最小值（或最大值）的问题都可以称为寻优问题（也叫作一个规划问题），又由于找最大值的问题总可以通过加一个负号变为找最小值的问题，因此我们下面讨论的时候都针对找最小值的过程来进行。一个寻优问题最重要的部分是目标函数，顾名思义，就是指寻优的目标。例如我们想寻找最小的||w||这件事，就可以用下面的式子表示： 但实际上对于这个目标，我们常常使用另一个完全等价的目标函数来代替，如下式1所示： 不难看出当||w||2达到最小时，||w||也达到最小，反之亦然（前提当然是||w||描述的是向量的长度，因而是非负的）。之所以采用这种形式，是因为后面的求解过程会对目标函数作一系列变换，而式（1）的形式会使变换后的形式更为简洁（正如聪明的读者所料，添加的系数二分之一和平方，皆是为求导数所需）。 接下来我们自然会问的就是，这个式子是否就描述了我们的问题呢？（回想一下，我们的问题是有一堆点，可以被分成两类，我们要找出最好的分类面） 如果直接来解这个求最小值问题，很容易看出当||w||=0的时候就得到了目标函数的最小值。但是你也会发现，无论你给什么样的数据，都是这个解！反映在图中，就是H1与H2两条直线间的距离无限大，这个时候，所有的样本点（无论正样本还是负样本）都跑到了H1和H2中间，而我们原本的意图是，H1右侧的被分为正类，H2 左侧的被分为负类，位于两类中间的样本则拒绝分类（拒绝分类的另一种理解是分给哪一类都有道理，因而分给哪一类也都没有道理）。这下可好，所有样本点都进入了无法分类的灰色地带。 造成这种结果的原因是在描述问题的时候只考虑了目标，而没有加入约束条件，约束条件就是在求解过程中必须满足的条件，体现在我们的问题中就是样本点必须在H1或H2的某一侧（或者至少在H1和H2上），而不能跑到两者中间。我们前文提到过把间隔固定为1，这是指把所有样本点中间隔最小的那一点的间隔定为1（这也是集合的间隔的定义，有点绕嘴），也就意味着集合中的其他点间隔都不会小于1，按照间隔的定义，满足这些条件就相当于让下面的式子总是成立： yi[(w·xi)+b]≥1 (i=1,2,…,l) （l是总的样本数） 但我们常常习惯让式子的值和0比较，因而经常用变换过的形式： yi[(w·xi)+b]-1≥0 (i=1,2,…,l) （l是总的样本数） 因此我们的两类分类问题也被我们转化成了它的数学形式，一个带约束的最小值的问题： 下一节我们从最一般的意义上看看一个求最小值的问题有何特征，以及如何来解。","tags":[{"name":"SVM","slug":"SVM","permalink":"http://clarkhedi.github.io/tags/SVM/"}]},{"title":"SVM入门（三）线性分类器Part 2","date":"2020-07-06T21:05:13.000Z","path":"2020/07/06/svm-ru-men-san-xian-xing-fen-lei-qi-part-2/","text":"上回说到对于文本分类这样的不适定问题（有一个以上解的问题称为不适定问题），需要有一个指标来衡量解决方案（即我们通过训练建立的分类模型）的好坏，而分类间隔是一个比较好的指标。 在进行文本分类的时候，我们可以让计算机这样来看待我们提供给它的训练样本，每一个样本由一个向量（就是那些文本特征所组成的向量）和一个标记（标示出这个样本属于哪个类别）组成。如下： ​ Di=(xi,yi) xi就是文本向量（维数很高），yi就是分类标记。 在二元的线性分类中，这个表示分类的标记只有两个值，1和-1（用来表示属于还是不属于这个类）。有了这种表示法，我们就可以定义一个样本点到某个超平面的间隔： ​ δi=yi(wxi+b) 这个公式乍一看没什么神秘的，也说不出什么道理，只是个定义而已，但我们做做变换，就能看出一些有意思的东西。 首先注意到如果某个样本属于该类别的话，那么wxi+b&gt;0（记得么？这是因为我们所选的g(x)=wx+b就通过大于0还是小于0来判断分类），而yi也大于0；若不属于该类别的话，那么wxi+b&lt;0，而yi也小于0，这意味着yi(wxi+b)总是大于0的，而且它的值就等于|wxi+b|！（也就是|g(xi)|） 现在把w和b进行一下归一化，即用w/||w||和b/||w||分别代替原来的w和b，那么间隔就可以写成 这个公式是不是看上去有点眼熟？没错，这不就是解析几何中点xi到直线g(x)=0的距离公式嘛！（推广一下，是到超平面g(x)=0的距离， g(x)=0就是上节中提到的分类超平面） 小Tips：||w||是什么符号？||w||叫做向量w的范数，范数是对向量长度的一种度量。我们常说的向量长度其实指的是它的2-范数，范数最一般的表示形式为p-范数，可以写成如下表达式 向量w=(w1, w2, w3,…… wn) 它的p-范数为 看看把p换成2的时候，不就是传统的向量长度么？当我们不指明p的时候，就像||w||这样使用时，就意味着我们不关心p的值，用几范数都可以；或者上文已经提到了p的值，为了叙述方便不再重复指明。 当用归一化的w和b代替原值之后的间隔有一个专门的名称，叫做几何间隔，几何间隔所表示的正是点到超平面的欧氏距离，我们下面就简称几何间隔为“距离”。以上是单个点到某个超平面的距离（就是间隔，后面不再区别这两个词）定义，同样可以定义一个点的集合（就是一组样本）到某个超平面的距离为此集合中离超平面最近的点的距离。下面这张图更加直观的展示出了几何间隔的现实含义： H是分类面，而H1和H2是平行于H，且过离H最近的两类样本的直线，H1与H，H2与H之间的距离就是几何间隔。 之所以如此关心几何间隔这个东西，是因为几何间隔与样本的误分次数间存在关系： 其中的δ是样本集合到分类面的间隔，R=max ||xi|| i=1,…,n，即R是所有样本中（xi是以向量表示的第i个样本）向量长度最长的值（也就是说代表样本的分布有多么广）。先不必追究误分次数的具体定义和推导过程，只要记得这个误分次数一定程度上代表分类器的误差。而从上式可以看出，误分次数的上界由几何间隔决定！（当然，是样本已知的时候） 至此我们就明白为何要选择几何间隔来作为评价一个解优劣的指标了，原来几何间隔越大的解，它的误差上界越小。因此最大化几何间隔成了我们训练阶段的目标，而且，与二把刀作者所写的不同，最大化分类间隔并不是SVM的专利，而是早在线性分类时期就已有的思想。","tags":[{"name":"SVM","slug":"SVM","permalink":"http://clarkhedi.github.io/tags/SVM/"}]},{"title":"SVM入门（二）线性分类器Part 1","date":"2020-07-06T20:45:28.000Z","path":"2020/07/06/svm-ru-men-er-xian-xing-fen-lei-qi-part-1/","text":"线性分类器(一定意义上,也可以叫做感知机) 是最简单也很有效的分类器形式.在一个线性分类器中,可以看到SVM形成的思路,并接触很多SVM的核心概念. 用一个二维空间里仅有两类样本的分类问题来举个小例子。如图所示 C1和C2是要区分的两个类别，在二维平面中它们的样本如上图所示。中间的直线就是一个分类函数，它可以将两类样本完全分开。一般的，如果一个线性函数能够将样本完全正确的分开，就称这些数据是线性可分的，否则称为非线性可分的。 什么叫线性函数呢？在一维空间里就是一个点，在二维空间里就是一条直线，三维空间里就是一个平面，可以如此想象下去，如果不关注空间的维数，这种线性函数还有一个统一的名称——超平面（Hyper Plane）！ 实际上，一个线性函数是一个实值函数（即函数的值是连续的实数），而我们的分类问题（例如这里的二元分类问题——回答一个样本属于还是不属于一个类别的问题）需要离散的输出值，例如用1表示某个样本属于类别C1，而用0表示不属于（不属于C1也就意味着属于C2），这时候只需要简单的在实值函数的基础上附加一个阈值即可，通过分类函数执行时得到的值大于还是小于这个阈值来确定类别归属。 例如我们有一个线性函数： ​ g(x)=wx+b 我们可以取阈值为0，这样当有一个样本xi需要判别的时候，我们就看g(xi)的值。若g(xi)&gt;0，就判别为类别C1，若g(xi)&lt;0，则判别为类别C2（等于的时候我们就拒绝判断，呵呵）。此时也等价于给函数g(x)附加一个符号函数sgn()，即f(x)=sgn [g(x)]是我们真正的判别函数。 关于g(x)=wx+b这个表达式要注意三点：一，式中的x不是二维坐标系中的横轴，而是样本的向量表示，例如一个样本点的坐标是(3,8)，则xT=(3,8) ，而不是x=3（一般说向量都是说列向量，因此以行向量形式来表示时，就加上转置）。二，这个形式并不局限于二维的情况，在n维空间中仍然可以使用这个表达式，只是式中的w成为了n维向量（在二维的这个例子中，w是二维向量，为了表示起来方便简洁，以下均不区别列向量和它的转置，聪明的读者一看便知）；三，g(x)不是中间那条直线的表达式，中间那条直线的表达式是g(x)=0，即wx+b=0，我们也把这个函数叫做分类面。 实际上很容易看出来，中间那条分界线并不是唯一的，我们把它稍微旋转一下，只要不把两类数据分错，仍然可以达到上面说的效果，稍微平移一下，也可以。此时就牵涉到一个问题，对同一个问题存在多个分类函数的时候，哪一个函数更好呢？显然必须要先找一个指标来量化“好”的程度，通常使用的都是叫做“分类间隔”的指标。下一节我们就仔细说说分类间隔，也补一补相关的数学知识。","tags":[{"name":"SVM","slug":"SVM","permalink":"http://clarkhedi.github.io/tags/SVM/"}]},{"title":"SVM入门（一）八股简介","date":"2020-07-06T20:23:25.000Z","path":"2020/07/06/svm-ru-men-yi-ba-gu-jian-jie/","text":"（一）SVM的八股简介 来源：http://www.blogjava.net/zhenandaci/archive/2008/06/20/209446.html 支持向量机(Support Vector Machine)是Cortes和Vapnik于1995年首先提出的，它在解决小样本、非线性及高维模式识别中表现出许多特有的优势，并能够推广应用到函数拟合等其他机器学习问题中[10]。支持向量机方法是建立在统计学习理论的VC 维理论和结构风险最小原理基础上的，根据有限的样本信息在模型的复杂性（即对特定训练样本的学习精度，Accuracy）和学习能力（即无错误地识别任意样本的能力）之间寻求最佳折衷，以期获得最好的推广能力[14]（或称泛化能力）。 以上是经常被有关SVM 的学术文献引用的介绍，有点八股，我来逐一分解并解释一下。 Vapnik是统计机器学习的大牛，这想必都不用说，他出版的《Statistical Learning Theory》是一本完整阐述统计机器学习思想的名著。在该书中详细的论证了统计机器学习之所以区别于传统机器学习的本质，就在于统计机器学习能够精确的给出学习效果，能够解答需要的样本数等等一系列问题。与统计机器学习的精密思维相比，传统的机器学习基本上属于摸着石头过河，用传统的机器学习方法构造分类系统完全成了一种技巧，一个人做的结果可能很好，另一个人差不多的方法做出来却很差，缺乏指导和原则。 所谓VC维是对函数类的一种度量，可以简单的理解为问题的复杂程度，VC维越高，一个问题就越复杂。正是因为SVM关注的是VC维，后面我们可以看到，SVM解决问题的时候，和样本的维数是无关的（甚至样本是上万维的都可以，这使得SVM很适合用来解决文本分类的问题，当然，有这样的能力也因为引入了核函数）。 结构风险最小听上去文绉绉，其实说的也无非是下面这回事。 机器学习本质上就是一种对问题真实模型的逼近（我们选择一个我们认为比较好的近似模型，这个近似模型就叫做一个假设），但毫无疑问，真实模型一定是不知道的（如果知道了，我们干吗还要机器学习？直接用真实模型解决问题不就可以了？对吧，哈哈）既然真实模型不知道，那么我们选择的假设与问题真实解之间究竟有多大差距，我们就没法得知。比如说我们认为宇宙诞生于150亿年前的一场大爆炸，这个假设能够描述很多我们观察到的现象，但它与真实的宇宙模型之间还相差多少？谁也说不清，因为我们压根就不知道真实的宇宙模型到底是什么。 这个与问题真实解之间的误差，就叫做风险（更严格的说，误差的累积叫做风险）。我们选择了一个假设之后（更直观点说，我们得到了一个分类器以后），真实误差无从得知，但我们可以用某些可以掌握的量来逼近它。最直观的想法就是使用分类器在样本数据上的分类的结果与真实结果（因为样本是已经标注过的数据，是准确的数据）之间的差值来表示。这个差值叫做经验风险Remp(w)。以前的机器学习方法都把经验风险最小化作为努力的目标，但后来发现很多分类函数能够在样本集上轻易达到100%的正确率，在真实分类时却一塌糊涂（即所谓的推广能力差，或泛化能力差）。此时的情况便是选择了一个足够复杂的分类函数（它的VC维很高），能够精确的记住每一个样本，但对样本之外的数据一律分类错误。回头看看经验风险最小化原则我们就会发现，此原则适用的大前提是经验风险要确实能够逼近真实风险才行（行话叫一致），但实际上能逼近么？答案是不能，因为样本数相对于现实世界要分类的文本数来说简直九牛一毛，经验风险最小化原则只在这占很小比例的样本上做到没有误差，当然不能保证在更大比例的真实文本上也没有误差。 统计学习因此而引入了泛化误差界的概念，就是指真实风险应该由两部分内容刻画，一是经验风险，代表了分类器在给定样本上的误差；二是置信风险，代表了我们在多大程度上可以信任分类器在未知文本上分类的结果。很显然，第二部分是没有办法精确计算的，因此只能给出一个估计的区间，也使得整个误差只能计算上界，而无法计算准确的值（所以叫做泛化误差界，而不叫泛化误差）。 置信风险与两个量有关，一是样本数量，显然给定的样本数量越大，我们的学习结果越有可能正确，此时置信风险越小；二是分类函数的VC维，显然VC维越大，推广能力越差，置信风险会变大。 泛化误差界的公式为： ​ R(w)≤Remp(w)+Ф(n/h) 公式中R(w)就是真实风险，Remp(w)就是经验风险，Ф(n/h)就是置信风险。统计学习的目标从经验风险最小化变为了寻求经验风险与置信风险的和最小，即结构风险最小。 SVM正是这样一种努力最小化结构风险的算法。 SVM其他的特点就比较容易理解了。 小样本，并不是说样本的绝对数量少（实际上，对任何算法来说，更多的样本几乎总是能带来更好的效果），而是说与问题的复杂度比起来，SVM算法要求的样本数是相对比较少的。 非线性，是指SVM擅长应付样本数据线性不可分的情况，主要通过松弛变量（也有人叫惩罚变量）和核函数技术来实现，这一部分是SVM的精髓，以后会详细讨论。多说一句，关于文本分类这个问题究竟是不是线性可分的，尚没有定论，因此不能简单的认为它是线性可分的而作简化处理，在水落石出之前，只好先当它是线性不可分的（反正线性可分也不过是线性不可分的一种特例而已，我们向来不怕方法过于通用）。 高维模式识别是指样本维数很高，例如文本的向量表示，如果没有经过另一系列文章（《文本分类入门》）中提到过的降维处理，出现几万维的情况很正常，其他算法基本就没有能力应付了，SVM却可以，主要是因为SVM 产生的分类器很简洁，用到的样本信息很少（仅仅用到那些称之为“支持向量”的样本，此为后话），使得即使样本维数很高，也不会给存储和计算带来大麻烦（相对照而言，kNN算法在分类时就要用到所有样本，样本数巨大，每个样本维数再一高，这日子就没法过了……）。 下一节开始正式讨论SVM。别嫌我说得太详细哦。","tags":[{"name":"SVM","slug":"SVM","permalink":"http://clarkhedi.github.io/tags/SVM/"}]},{"title":"将自己的简历模板部署到GitHub Pages","date":"2020-05-02T19:16:40.000Z","path":"2020/05/02/jiang-zi-ji-de-jian-li-mo-ban-bu-shu-dao-github-pages/","text":"实验楼的学习分享 我的Resume 什么是 Github Pages？ Github Pages 是 Github 的静态页面托管服务。它设计的初衷是为了用户能够直接通过 Github 仓库来托管用户个人、组织或是项目的专属页面。 Github Pages参考 可以说相当于一个可直接用 git 管理内容的静态服务器，有许多人会用它来托管自己的个人博客（利用 Jekyll、Pelican 这一类静态页面生成工具）或是在这上面发布自己的 HTML5 小游戏。当然这么好的东西也是有限制的。 Github Pages 的限制： 仓库存储的所有文件不能超过 1 GB 页面的带宽限制是低于每月 100 GB 或是每月 100,000 次请求 每小时最多只能部署 10 个静态网站 如果真的不小心超了，Github 那边不会采取什么强制措施，而是会发一份邮件提醒你应该找一个更适合你的托管对象的服务。 接下来进入正题：环境： Windows10. 1. 创建一个文件夹这个文件夹用作本地仓库，如： 2. 初始化 git 库进入文件夹右击鼠标，点击 git bash ( 前提是安装了 git )，然后输入 git init 命令，文件夹中会多出一个 .git 文件. 3. 用户配置（可选） 12git config --global user.name &quot;你的用户名&quot;git config --global user.email &quot;你的邮箱地址&quot; 这一步不做也没关系，用户名和邮箱是你提交commit时的签名，在 Github 的仓库页面上会显示这次提交的用户，如果不做设置就会默认为该仓库的拥有者，做了则根据邮箱来匹配用户。 4. 编辑简历文件Windows中git bash完全可以替代原生的cmd，但是对于git bash会有一些Linux下广泛使用的命令的缺失，比如wget命令。 在此，以安装wget命令为例，其他命令可以采用相同的方式解决： 下载wget二进制安装包，wget下载地址 下载解压包的解压安装包，将wget.exe 拷贝到自己安装的Git目录下面,如：D:\\Git\\mingw64\\bin（或者解压之后将解压文件中wget.exe的路径添加到环境变量中） 如果有简历的话直接放到此文件夹中，没有的话可以先下载简历模板文件，解压，命令如下：（你还可以下载其他模板） 12345671.下载：wget http://labfile.oss.aliyuncs.com/courses/624/cv-template.zip2.在当前目录下解压：unzip cv-template3.将cv-template中的所有文件都移到当前文件夹下：mv cv-template/* . (说明：* 代表所有文件， . 代表当前目录； .DS_Store 可忽略)4.删除__MACOSX和cv-template(包括其压缩包)所有文件rm -rf cv-template* __MACOSX* 用浏览器打开index.html就可以看见模板的样子了,可以直接在浏览器上在线编辑，根据自己的需求来修改模板的样式。 注意:简历的内容不要超出背景的高度。 编辑完自己的简历以后，Google Chrome按F12查看修改的代码，可以把修改后的代码复制下来，替换掉原index.html里的代码。 不喜欢发布后的简历页面仍是可编辑的，可以修改static/js下的script.js文件，操作非常简单，删除该文件下的所有内容，然后加上下面这一句。 123$(document).ready(function($)&#123; $(&quot;*&quot;).removeAttr(&#x27;contenteditable&#x27;); &#125;) 这一句是为了去掉页面上所有元素的可编辑属性。 最后可以在 CSS 文件内再改改样式。 5. 部署简历文件到GitHub上这里可以参考我之前发的文章： 手把手教如何将本地项目上传到GitHub 这里对于Github Pages操作，首先新建一个仓库，名字取 resume，之后先别跟着它给的步骤做。 Github Pages 支持托管的页面分两类，个人/组织页面 与 项目页面，其主要区别就是托管位置的区别。如下表所示（这里略去组织，它跟个人是差不多的）： 类型 页面域名 &amp; 托管位置 页面源文件所在的分支 个人主页 username.github.io master 项目主页 username.github.io/projectname master、gh-pages 、或是在master的doc目录下 如果想使用个人主页，那么就创建一个名为 username.github.io （username需要替换为你的用户名）的库，在主分支master上托管你的页面代码。 如果是使用项目主页，那么可以选择将代码托管在master、gh-pages、或者master的doc目录下，其中gh-pages是默认的页面托管分支，如果想使用master，可在项目页面的设置栏中进行切换。 （由于现在仓库还是空的，上面的选项还无法选） 无论使用哪一种页面操作都是差不多的，这里就用项目页面来做演示了，由于我们所有的代码就只有页面代码而已，那么就直接在master分支上进行托管吧。 先在本地仓库做一次代码提交： 1234git add .git commit -m &#x27;commit my cv&#x27;git remote add origin 你的远程仓库地址git push -u origin master 代码提交到远程仓库后，在项目页面设置 Github Pages 使用的托管源。 现在你可以访问https://你的用户名.github.io/resume/这个地址了，恭喜，简历页面已成功部署在了 Github Pages 上。 6. 将简历下载 保存为 pdfGoogle Chrome 下：打开https://你的用户名.github.io/resume/地址：右击 打印 选择另存为PDF。 7. 总结主要是给没有接触过 Github Pages 的同学演示一遍它的基本使用，关于其它主题如自定义域名，自定义 404 页面等可在 Customizing GitHub Pages 中找到参考。 这里还需要再三提醒一句，千万不要在发布的简历中加上个人身份敏感信息呀！ 最后再给看到这里的同学一个福利","tags":[{"name":"GitHub","slug":"GitHub","permalink":"http://clarkhedi.github.io/tags/GitHub/"},{"name":"Resume","slug":"Resume","permalink":"http://clarkhedi.github.io/tags/Resume/"}]},{"title":"深度学习常用Python库介绍","date":"2020-04-27T23:39:39.000Z","path":"2020/04/27/shen-du-xue-xi-chang-yong-python-ku-jie-shao/","text":"总体介绍Python 被大量应用在数据挖掘和深度学习领域，其中使用极其广泛的是 Numpy、pandas、Matplotlib、PIL 等库。 numpy是 Python 科学计算库的基础。包含了强大的 N 维数组对象和向量运算。 pandas是建立在 numpy 基础上的高效数据分析处理库，是 Python 的重要数据分析库。 Matplotlib是一个主要用于绘制二维图形的 Python 库。用途：绘图、可视化 PIL库是一个具有强大图像处理能力的第三方库。用途：图像处理 Numpy 库NumPy 是使用 Python 进行科学计算的基础软件包。 更多学习，可参考numpy 中文网：https://www.numpy.org.cn/ 1. 数组创建可以使用 array 函数从常规 Python列表或元组中创建数组。得到的数组的类型是从 Python 列表中元素的类型推导出来的。 创建数组最简单的办法就是使用 array 函数。它接受一切序列型的对象（包括其他数组），然后产生一个新的含有传入数据的 numpy 数组。其中，嵌套序列（比如由一组等长列表组成的列表）将会被转换为一个多维数组 123456import numpy as np#将列表转换为数组array = np.array([[1,2,3], [4,5,6]])print(array) [[1 2 3] [4 5 6]] 123456import numpy as np#将元组转换为数组array = np.array(((1,2,3), (4,5,6)))print(array) [[1 2 3] [4 5 6]] 下面这样可以吗？ 1a = np.array(1,2,3,4) #不行的 通常，数组的元素最初是未知的，但它的大小是已知的。因此，NumPy 提供了几个函数来创建具有初始占位符内容的数组。 zeros():可以创建指定长度或者形状的全 0 数组 ones():可以创建指定长度或者形状的全 1 数组 empty():创建一个数组，其初始内容是随机的,取决于内存的状态 12zeroarray = np.zeros((2,3))print(zeroarray) [[0. 0. 0.] [0. 0. 0.]] 12onearray = np.ones((3,4),dtype=&#x27;int64&#x27;)print(onearray) [[1 1 1 1] [1 1 1 1] [1 1 1 1]] 12emptyarray = np.empty((3,4))print(emptyarray) [[6.95060666e-310 4.66535240e-310 0.00000000e+000 0.00000000e+000] [0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000] [0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000]] 为了创建数字组成的数组，NumPy 提供了一个类似于 range 的函数，该函数返回数组而不是列表。 12array = np.arange( 10, 31, 5 )print(array) [10 15 20 25 30] 输出数组的一些信息，如维度、形状、元素个数、元素类型等 12345678910array = np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])print(array)#数组维度print(array.ndim)#数组形状print(array.shape)#数组元素个数print(array.size)#数组元素类型print(array.dtype) [[ 1 2 3] [ 4 5 6] [ 7 8 9] [10 11 12]] 2 (4, 3) 12 int64 重新定义数字的形状 1234567array1 = np.arange(6).reshape([2,3])print(array1)array2 = np.array([[1,2,3],[4,5,6]],dtype=np.int64).reshape([3,2])print(array2) [[0 1 2] [3 4 5]] [[1 2] [3 4] [5 6]] 2. 数组的计算数组很重要，因为它可以使我们不用编写循环即可对数据执行批量运算。这通常叫做矢量化（vectorization）。 大小相等的数组之间的任何算术运算都会将运算应用到元素级。同样，数组与标量的算术运算也会将那个标量值传播到各个元素. 矩阵的基础运算： 123456789arr1 = np.array([[1,2,3],[4,5,6]])arr2 = np.ones([2,3],dtype=np.int64)print(arr1 + arr2)print(arr1 - arr2)print(arr1 * arr2)print(arr1 / arr2)print(arr1 ** 2) [[2 3 4] [5 6 7]] [[0 1 2] [3 4 5]] [[1 2 3] [4 5 6]] [[1. 2. 3.] [4. 5. 6.]] [[ 1 4 9] [16 25 36]] 矩阵乘法： 123456#矩阵乘法arr3 = np.array([[1,2,3],[4,5,6]])arr4 = np.ones([3,2],dtype=np.int64)print(arr3)print(arr4)print(np.dot(arr3,arr4)) [[1 2 3] [4 5 6]] [[1 1] [1 1] [1 1]] [[ 6 6] [15 15]] 矩阵的其他计算： 1234567print(arr3)print(np.sum(arr3,axis=1)) #axis=1,每一行求和 axie=0,每一列求和print(np.max(arr3))print(np.min(arr3))print(np.mean(arr3))print(np.argmax(arr3)) #取出arr3中元素最大值所对应的索引print(np.argmin(arr3)) [[1 2 3] [4 5 6]] [ 6 15] 6 1 3.5 5 0 1234arr3_tran = arr3.transpose()#T转置print(arr3_tran)print(arr3.flatten())#扁平化 [[1 4] [2 5] [3 6]] [1 2 3 4 5 6] 3. 数组的索引与切片12345678arr5 = np.arange(0,6).reshape([2,3])print(arr5)print(arr5[1])print(arr5[1][2])print(arr5[1,2])print(arr5[1,:])print(arr5[:,1])print(arr5[1,0:2]) [[0 1 2] [3 4 5]] [3 4 5] 5 5 [3 4 5] [1 4] [3 4] padas 库pandas 是 python 第三方库，提供高性能易用数据类型和分析工具。 pandas 基于 numpy 实现，常与 numpy 和 matplotlib 一同使用 更多学习，请参考pandas 中文网：https://www.pypandas.cn/ Padas 核心数据结构： 维 数 名 称 描 述 1 Series 带标签的一维同构数组 2 DataFrame 带标签的，大小可变的，二维异构表格 1. Series Series 是一种类似于一维数组的对象，它由一维数组（各种 numpy 数据类型）以及一组与之相关的数据标签（即索引）组成. 可理解为带标签的一维数组，可存储整数、浮点数、字符串、Python 对象等类型的数据。 123456import pandas as pdimport numpy as nps = pd.Series([&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;d&#x27;,&#x27;e&#x27;])print(s) 0 a 1 b 2 c 3 d 4 e dtype: object Seris 中可以使用 index 设置索引列表。 与字典不同的是，Seris 允许索引重复 1234#与字典不同的是：Series允许索引重复s = pd.Series([&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;,&#x27;d&#x27;,&#x27;e&#x27;],index=[100,200,100,400,500])print(s) 100 a 200 b 100 c 400 d 500 e dtype: object Series 可以用字典实例化 12d = &#123;&#x27;b&#x27;: 1, &#x27;a&#x27;: 0, &#x27;c&#x27;: 2&#125;pd.Series(d) b 1 a 0 c 2 dtype: int64 可以通过 Series 的 values 和 index 属性获取其数组表示形式和索引对象 123print(s.values)print(s.index) [&#39;a&#39; &#39;b&#39; &#39;c&#39; &#39;d&#39; &#39;e&#39;] Int64Index([100, 200, 100, 400, 500], dtype=&#39;int64&#39;) 1234#与普通numpy数组相比，可以通过索引的方式选取Series中的单个或一组值print(s[100])print(s[[400, 500]]) 100 a 100 c dtype: object 400 d 500 e dtype: object 12345678s = pd.Series(np.array([1,2,3,4,5]), index=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;])print(s)#对应元素求和print(s+s)#对应元素乘print(s*3) a 1 b 2 c 3 d 4 e 5 dtype: int64 a 2 b 4 c 6 d 8 e 10 dtype: int64 a 3 b 6 c 9 d 12 e 15 dtype: int64 Series 中最重要的一个功能是：它会在算术运算中自动对齐不同索引的数据 Series 和多维数组的主要区别在于， Series 之间的操作会自动基于标签对齐数据。因此，不用顾及执行计算操作的 Series 是否有相同的标签。 1234obj1 = pd.Series(&#123;&quot;Ohio&quot;: 35000, &quot;Oregon&quot;: 16000, &quot;Texas&quot;: 71000, &quot;Utah&quot;: 5000&#125;)obj2 = pd.Series(&#123;&quot;California&quot;: np.nan, &quot;Ohio&quot;: 35000, &quot;Oregon&quot;: 16000, &quot;Texas&quot;: 71000&#125;)print(obj1 + obj2) California NaN Ohio 70000.0 Oregon 32000.0 Texas 142000.0 Utah NaN dtype: float64 1234567s = pd.Series(np.array([1,2,3,4,5]), index=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;])print(s[1:])print(s[:-1])print(s[1:] + s[:-1]) b 2 c 3 d 4 e 5 dtype: int64 a 1 b 2 c 3 d 4 dtype: int64 a NaN b 4.0 c 6.0 d 8.0 e NaN dtype: float64 2. DataFrame DataFrame 是一个表格型的数据结构，类似于 Excel 或 sql 表 它含有一组有序的列，每列可以是不同的值类型（数值、字符串、布尔值等） DataFrame 既有行索引也有列索引，它可以被看做由 Series 组成的字典（共用同一个索引） 用多维数组字典、列表字典生成 DataFrame 1234data = &#123;&#x27;state&#x27;: [&#x27;Ohio&#x27;, &#x27;Ohio&#x27;, &#x27;Ohio&#x27;, &#x27;Nevada&#x27;, &#x27;Nevada&#x27;], &#x27;year&#x27;: [2000, 2001, 2002, 2001, 2002], &#x27;pop&#x27;: [1.5, 1.7, 3.6, 2.4, 2.9]&#125;frame = pd.DataFrame(data)print(frame) state year pop 0 Ohio 2000 1.5 1 Ohio 2001 1.7 2 Ohio 2002 3.6 3 Nevada 2001 2.4 4 Nevada 2002 2.9 1234#如果指定了列顺序，则DataFrame的列就会按照指定顺序进行排列frame1 = pd.DataFrame(data, columns=[&#x27;year&#x27;, &#x27;state&#x27;, &#x27;pop&#x27;])print(frame1) year state pop 0 2000 Ohio 1.5 1 2001 Ohio 1.7 2 2002 Ohio 3.6 3 2001 Nevada 2.4 4 2002 Nevada 2.9 跟原 Series 一样，如果传入的列在数据中找不到，就会产生 NAN 值 12frame2 = pd.DataFrame(data, columns=[&#x27;year&#x27;, &#x27;state&#x27;, &#x27;pop&#x27;, &#x27;debt&#x27;], index=[&#x27;one&#x27;, &#x27;two&#x27;, &#x27;three&#x27;, &#x27;four&#x27;, &#x27;five&#x27;])print(frame2) year state pop debt one 2000 Ohio 1.5 NaN two 2001 Ohio 1.7 NaN three 2002 Ohio 3.6 NaN four 2001 Nevada 2.4 NaN five 2002 Nevada 2.9 NaN 用 Series 字典或字典生成 DataFrame 123d = &#123;&#x27;one&#x27;: pd.Series([1., 2., 3.], index=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;]), &#x27;two&#x27;: pd.Series([1., 2., 3., 4.], index=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;])&#125;print(pd.DataFrame(d)) one two a 1.0 1.0 b 2.0 2.0 c 3.0 3.0 d NaN 4.0 123#通过类似字典标记的方式或属性的方式，可以将DataFrame的列获取为一个Series,返回的Series拥有原DataFrame相同的索引print(frame2[&#x27;state&#x27;]) one Ohio two Ohio three Ohio four Nevada five Nevada Name: state, dtype: object 列可以通过赋值的方式进行修改,例如，给那个空的“delt”列赋上一个标量值或一组值 123frame2[&#x27;debt&#x27;] = 16.5print(frame2) year state pop debt one 2000 Ohio 1.5 16.5 two 2001 Ohio 1.7 16.5 three 2002 Ohio 3.6 16.5 four 2001 Nevada 2.4 16.5 five 2002 Nevada 2.9 16.5 123print(frame2)frame2[&#x27;new&#x27;] = frame2[&#x27;debt&#x27; ]* frame2[&#x27;pop&#x27;]print(frame2) year state pop debt one 2000 Ohio 1.5 16.5 two 2001 Ohio 1.7 16.5 three 2002 Ohio 3.6 16.5 four 2001 Nevada 2.4 16.5 five 2002 Nevada 2.9 16.5 year state pop debt new one 2000 Ohio 1.5 16.5 24.75 two 2001 Ohio 1.7 16.5 28.05 three 2002 Ohio 3.6 16.5 59.40 four 2001 Nevada 2.4 16.5 39.60 five 2002 Nevada 2.9 16.5 47.85 12frame2[&#x27;debt&#x27;] = np.arange(5.)print(frame2) year state pop debt new one 2000 Ohio 1.5 0.0 24.75 two 2001 Ohio 1.7 1.0 28.05 three 2002 Ohio 3.6 2.0 59.40 four 2001 Nevada 2.4 3.0 39.60 five 2002 Nevada 2.9 4.0 47.85 PIL 库PIL 库是一个具有强大图像处理能力的第三方库。 图像的组成：由 RGB 三原色组成,RGB 图像中，一种彩色由 R、G、B 三原色按照比例混合而成。0-255 区分不同亮度的颜色。 图像的数组表示：图像是一个由像素组成的矩阵，每个元素是一个 RGB 值 Image 是 PIL 库中代表一个图像的类（对象） 12#安装pillow#!pip install pillow 1. 展示图片，并获取图像的模式，长宽，1234567891011121314151617181920from PIL import Imageimport matplotlib.pyplot as plt#显示matplotlib生成的图形%matplotlib inline#读取图片img = Image.open(&#x27;/home/aistudio/work/lena.png&#x27;)#显示图片#img.show() #自动调用计算机上显示图片的工具plt.imshow(img)plt.show(img)#获得图像的模式img_mode = img.modeprint(img_mode)width,height = img.sizeprint(width,height) RGB 512 512 2. 图片旋转12345678910111213141516from PIL import Imageimport matplotlib.pyplot as plt#显示matplotlib生成的图形%matplotlib inline#读取图片img = Image.open(&#x27;/home/aistudio/work/lena.png&#x27;)#显示图片plt.imshow(img)plt.show(img)#将图片旋转45度img_rotate = img.rotate(45)#显示旋转后的图片plt.imshow(img_rotate)plt.show(img_rotate) 3. 图片剪切1234567891011121314from PIL import Image#打开图片img1 = Image.open(&#x27;/home/aistudio/work/lena.png&#x27;)#剪切 crop()四个参数分别是：(左上角点的x坐标，左上角点的y坐标，右下角点的x坐标，右下角点的y坐标)img1_crop_result = img1.crop((126,50,381,400))#保存图片img1_crop_result.save(&#x27;/home/aistudio/work/lena_crop_result.jpg&#x27;)#展示图片plt.imshow(img1_crop_result)plt.show(img1_crop_result) 4. 图片缩放123456789101112131415161718from PIL import Image#打开图片img2 = Image.open(&#x27;/home/aistudio/work/lena.png&#x27;)width,height = img2.size#缩放img2_resize_result = img2.resize((int(width*0.6),int(height*0.6)),Image.ANTIALIAS)print(img2_resize_result.size)#保存图片img2_resize_result.save(&#x27;/home/aistudio/work/lena_resize_result.jpg&#x27;)#展示图片plt.imshow(img2_resize_result)plt.show(img2_resize_result) (307, 307) 5. 镜像效果：左右旋转、上下旋转123456789101112131415161718from PIL import Image#打开图片img3 = Image.open(&#x27;/home/aistudio/work/lena.png&#x27;)#左右镜像img3_lr = img3.transpose(Image.FLIP_LEFT_RIGHT)#展示左右镜像图片plt.imshow(img3_lr)plt.show(img3_lr)#上下镜像img3_bt = img3.transpose(Image.FLIP_TOP_BOTTOM)#展示上下镜像图片plt.imshow(img3_bt)plt.show(img3_bt) Matplotlib 库Matplotlib 库由各种可视化类构成，内部结构复杂。 matplotlib.pylot 是绘制各类可视化图形的命令字库 更多学习，可参考Matplotlib 中文网：https://www.matplotlib.org.cn 1#!pip install matplotlib 123456789101112131415161718192021222324import matplotlib.pyplot as pltimport numpy as np#显示matplotlib生成的图形%matplotlib inline&#x27;&#x27;&#x27;语法：numpy.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None, axis=0)参数含义： start:返回样本数据开始点 stop:返回样本数据结束点 num:生成的样本数据量，默认为50 endpoint：True则包含stop；False则不包含stop retstep：If True, return (samples, step), where step is the spacing between samples.(即如果为True则结果会给出数据间隔) dtype：输出数组类型 axis：0(默认)或-1&#x27;&#x27;&#x27;x = np.linspace(-1,1,50) #等差数列y = 2*x + 1#传入x,y,通过plot()绘制出折线图plt.plot(x,y)#显示图形plt.show() 1234567891011121314import matplotlib.pyplot as pltimport numpy as npx = np.linspace(-1,1,50) #等差数列y1 = 2*x + 1y2 = x**2plt.figure()plt.plot(x,y1)plt.figure(figsize=(8,5))plt.plot(x,y2)plt.show() 123456789import matplotlib.pyplot as pltimport numpy as npplt.figure(figsize=(7,5))plt.plot(x,y1,color=&#x27;red&#x27;,linewidth=1)plt.plot(x,y2,color=&#x27;blue&#x27;,linewidth=5)plt.xlabel(&#x27;x&#x27;,fontsize=20)plt.ylabel(&#x27;y&#x27;,fontsize=20)plt.show() 123456789101112import matplotlib.pyplot as pltimport numpy as npplt.figure(figsize=(7,5))l1, = plt.plot(x,y1,color=&#x27;red&#x27;,linewidth=1)l2, = plt.plot(x,y2,color=&#x27;blue&#x27;,linewidth=5)plt.legend(handles=[l1,l2],labels=[&#x27;aa&#x27;,&#x27;bb&#x27;],loc=&#x27;best&#x27;) #图例plt.xlabel(&#x27;x&#x27;)plt.ylabel(&#x27;y&#x27;)# plt.xlim((0,1)) #x轴只截取一段进行显示# plt.ylim((0,1)) #y轴只截取一段进行显示plt.show() 1234567# dots1 = np.array([2,3,4,5,6])# dots2 = np.array([2,3,4,5,6])dots1 =np.random.rand(50)dots2 =np.random.rand(50)plt.scatter(dots1,dots2,c=&#x27;red&#x27;,alpha=0.5) #散点图，c表示颜色，alpha表示透明度plt.show() 1234x = np.arange(10)y = 2**x+10plt.bar(x,y,facecolor=&#x27;blue&#x27;,edgecolor=&#x27;white&#x27;) #直方图plt.show() 12345678910111213141516&#x27;&#x27;&#x27;zip 语法：zip([iterable, ...]) 参数说明：iterabl -- 一个或多个迭代器; 返回值: 返回zip对象,可用list转元组列表。&#x27;&#x27;&#x27;#examplel = [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;,&#x27;f&#x27;]print (l)print(zip(l[:-1],l[1:]))#打印列表print(list(zip(l[:-1],l[1:])))nums = [&#x27;flower&#x27;,&#x27;flow&#x27;,&#x27;flight&#x27;]for i in zip(*nums): print(i) # 元素个数与最短的元素一致 [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;] &lt;zip object at 0x7ff2d4680050&gt; [(&#39;a&#39;, &#39;b&#39;), (&#39;b&#39;, &#39;c&#39;), (&#39;c&#39;, &#39;d&#39;), (&#39;d&#39;, &#39;e&#39;), (&#39;e&#39;, &#39;f&#39;)] (&#39;f&#39;, &#39;f&#39;, &#39;f&#39;) (&#39;l&#39;, &#39;l&#39;, &#39;l&#39;) (&#39;o&#39;, &#39;o&#39;, &#39;i&#39;) (&#39;w&#39;, &#39;w&#39;, &#39;g&#39;) 12345678910111213141516x = np.arange(10)y = 2**x+10print(x,y,sep=&#x27;\\n&#x27;)plt.bar(x,y,facecolor=&#x27;blue&#x27;,edgecolor=&#x27;white&#x27;)for ax,ay in zip(x,y): plt.text(ax,ay,&#x27;%.1f&#x27; % ay,va=&#x27;bottom&#x27;,ha=&#x27;center&#x27;) #用于设置文字说明&#x27;&#x27;&#x27;简要语法：plt.text(x,y,string,fontsize=15,verticalalignment=&quot;top&quot;,horizontalalignment=&quot;right&quot;)参数说明： x,y:表示坐标值上的值 string:表示说明文字 fontsize:表示字体大小 verticalalignment(va)：垂直对齐方式 ，参数：[ ‘center’ | ‘top’ | ‘bottom’ | ‘baseline’ ] horizontalalignment(ha)：水平对齐方式 ，参数：[ ‘center’ | ‘right’ | ‘left’ ]&#x27;&#x27;&#x27;plt.show() [0 1 2 3 4 5 6 7 8 9] [ 11 12 14 18 26 42 74 138 266 522]","tags":[{"name":"Python","slug":"Python","permalink":"http://clarkhedi.github.io/tags/Python/"}]},{"title":"Jupyter 常用魔法命令","date":"2020-04-19T20:02:39.000Z","path":"2020/04/19/jupyter-chang-yong-mo-fa-ming-ling/","text":"Jupyter Lab简介Jupyter Lab 是功能强大的Python交互IDE，深受数据分析师和算法工程师的热爱。 Jupyter Lab自带的一些常用Command 可以让它变得更加得心应手。 一、Command介绍Jupyter Lab 有两种键盘输入模式: 命令模式 (按键 Esc 开启) 编辑模式(按键 Enter 切换) 编辑模式截图： 按Esc开启命令模式截图： 按Enter键切换成编辑模式截图： 命令模式下(按键 Esc 开启)：Y : 单元转入代码状态 R : 单元转入raw状态 M :单元转入markdown状态 即在markdown状态下： 1 : 设定 1 级标题 2 : 设定 2 级标题 3 : 设定 3 级标题 4 : 设定 4 级标题 5 : 设定 5 级标题 6 : 设定 6 级标题 Up/K : 选中上方单元 Down/J : 选中下方单元 Shift+K : 一直按会扩大选中上方单元与自身单元 Shift+J : 一直按会扩大选中下方单元与自身单元 A : 在上方插入新单元 B : 在下方插入新单元 X : 剪切选中的单元 C : 复制选中的单元 V : 粘贴到下方单元 Z : 恢复删除的最后一个单元(撤销) D,D : 删除选中的单元 Shift+M : 合并选中的单元 Ctrl+S/S : 文件存盘 L : 转换行号 O : 转换输出 Shift+O : 转换输出滚动 Esc/Q : 关闭页面 H : 显示快捷键帮助 Shift : 忽略 Shift+Space : 向上滚动 Space : 向下滚动 编辑模式下(按键 Enter 切换)：Tab : 代码补全或缩进 Shift+Tab : 提示 Shift+Enter : 运行本单元，选中下一单元 Alt+Enter : 运行本单元，在下面插入一单元 Ctrl+Enter : 运行本单元 Ctrl+] : 缩进 Ctrl+[ : 解除缩进 Ctrl+A : 全选 Ctrl+Z : 复原 Ctrl+Shift+Z/Ctrl+Y : 再做 Ctrl+Up/Ctrl+Home : 跳到单元开头 Ctrl+Down/Ctrl+End : 跳到单元末尾 Ctrl+Left : 跳到左边一个字首 Ctrl+Right : 跳到右边一个字首 Ctrl+Shift+- : 分割单元 Ctrl+S : 文件存盘 Up : 光标上移或转入上一单元 Down :光标下移或转入下一单元 使用Tab键补全代码功能截图如下： 使用shift+tab键显示函数使用提示如下： 二、NoteBook 常用魔法命令1、查看当前工作目录 2、更改工作目录 3、查看目录文件列表 4、写入文件 5、执行脚本文件 6、复制文档内容 没执行该语句前： 执行语句后： 7、查看当前变量 8、清除变量 清除全部变量： 清除某个变量： 9、测算运行时间 使用magic command测算： 使用python代码测算：","tags":[{"name":"Python","slug":"Python","permalink":"http://clarkhedi.github.io/tags/Python/"}]},{"title":"如何系统的学习Python","date":"2020-04-14T15:11:15.000Z","path":"2020/04/14/ru-he-xi-tong-de-xue-xi-python/","text":"总体介绍：来说一下怎么更有效地学习Python。学习Python需要掌握如下基础知识以及相关技能，这些都是入门基础，基本概念必须清楚！ Python基础知识（变量、语句、数据类型、数值类型、字符串、布尔类型、列表、字典、元组、条件语句、循环语句、函数、装饰器、面向对象、网络socket、爬虫） Python基础库（模块、包、系统模块、三方模块） python文件处理（读、写、执行、） python字符统计 python数据排序 一、学习方法： 万虐终成神！敲代码，解决BUG才是学习，无数次的看视频不是学习，至少不会学好。 只记Python基础语法，却没什么鸟用。就像幼儿园，老师在黑板上写的‘肉’字，记住这个字咋写，一笔一划的记住，只需要半天，但是把这个词和你平时吃的东西绑定，以至于后面你想到这个字，就流口水，需要日常的重复训练。 同理：无方向的看书，看视频也没什么用，其实可以通过直接实战来上手，比如：文件操作字符排序网络编程 错误的学习方法：很多人在学习Python的时候常常会犯下面一种情况：买一本厚厚的编程指南，逼自己看完，记住每个语法，闭门看书三个月，吃透一本书，最后一行代码也写不出来。 正确的学习方法：编程就像骑自行车，买一本&lt;&lt;骑自行车大全&gt;&gt;是没有什么用的。正确姿势：掌握最基础的姿势，就可以骑上车出发了，实际联系几天，摔几跤，基本就学会了。 二、自我进行测评： 基础门槛，不过需要找原因并解决。 很多朋友反馈：Python基础语法都学会了，但不知如何写项目进阶？ 1.List，Dict特性倒背如流，就是无法写出实际的项目。 2.各种书籍也看，写不出东西。 3.各种视频也看，写不出东西。 4.各种大会也去，名词高大上，但是没学到具体的技能。 对自我进行检测： 1.给你一个字符串“come baby,python rocks!” 如何统计里面字母o出现的次数！思路：遍历字符串，定义一个变量，每次o出现，都+1. 2.给你一个字符串“come baby,python rocks!” 如何统计这里面所有字母出现的次数！（普通变量肯定无法完成。）思路：需要使用字典这类复杂的数据结构处理，字母当key，出现的次数当value，每个key出现，对应的value+1. 3.给你一个字符串“come baby,python rocks!” 如何统计这里面字母出现次数的前三名！思路：排序，取出前三. 后续扩展练习： 1.一个nginx日志文件，怎么统计IP出现次数前三的url。 2.一个nginx日志文件，统计IP出现前三后，如何存入MySQL数据库。 3.存入MySQL中的日志文件，如何输出给浏览器端显示。 4.如何美化前端表格等等。 三、重要学习部分： python库怎么学 1.模块: 将多个代码块（按功能）定义到同一个文件中。别的文件中使用时则先导入模块，在调用模块内变量或函数。 模块命名要符合python变量的命名规范: 建议全小写英文字母和数字 避免与常用模块或第三方模块名称冲突 控制模块内代码在使用python mod.py时执行，在导入时不执行: 通过Global内变量__name__进行判断 当以python mod.py运行脚本时__name__变量为__main__字符串 当以模块导入时__name__为模块名称字符串 2.包:将不同模块文件放在不同文件夹内，包文件夹下面需要有init.py文件用以声明该文件为Python包。使用时需要从包内导入模块后调用模块中变量和函数。 常用系统模块： os,sys,time,datetime,urllib,xml,json,email,csv,collections,math,zipfile,trafile,hashlib 常用三方模块： requests,pyquery,django,flask,mysqlclient,paramiko,redis,lxml,dateutils,ipaddr,netaddr 模块学习方法： 1.先知道有没有 2.用的时候在查 内置工具：dir、help 搜索引擎：google、百度 四、再说一个python目前一个热点： python Web应用（python全栈） 1.Python基础入门（入门、数据类型、条件表达、循环语句） 2.Python基础进阶（文件操作、函数、装饰器、模块、面向对象、网络编程） 3.Python前端知识（Html、Css、Js、Jquery、Bootstrap、） 4.Python高级用法（Django、Flask、数据库操作、MVC、ORM、Admin、template） 5.Python项目实战（电商项目、爬虫项目、常用组件、运维项目、代码调优） 6.Python高级进阶（数据算法、代码规范、面试技巧） 重要：多抄、多写、多想、多问、多看、多听、多说 1.学习编程就是为了解决实际的问题，把自己在工作或学习中的重复工作程序化 2.谷歌和度娘 3.加入开源社区（多看、多分享、多交流） 4.参加培训辅导（仔细听课、跟上课堂学习，有问题做记录，课后查阅资料或请求他人） 5.善于记录笔记，不断总结，查漏补缺。 五、python前景之一： 大数据分析 1.python基础入门（入门、数据类型、条件表达、循环语句） 2.python基础进阶（文件操作、函数、装饰器、模块、面向对象、网络编程） 3.python数据采集：（外部数据源导入分析&amp;爬虫自己采集数据源分析） 4.数据分析：（各种库，如Pandas库，Numpy库必备数据库） 5.数据可视化：（matplotlib库） 重要：实用即可，最具价值，切莫花哨不适用 六、python前景之二： 机器学习—-看起来是个云端的概念** 直接看应用吧： 1.计算机视觉 典型的应用包括：人脸识别、车牌识别、扫描文字识别、图片内容识别、图片搜索等等。 2.自然语言处理 典型的应用包括：搜索引擎智能匹配、文本内容理解、文本情绪判断，语音识别、输入法、机器翻译等等。 3.社会网络分析 典型的应用包括：用户画像、网络关联分析、欺诈作弊发现、热点发现等等。 4.推荐 典型的应用包括：虾米音乐的“歌曲推荐”，某宝的“猜你喜欢”等等。 学习路线： 1.数学基础：微积分、线性代数、概率与统计、典型算法 2.编程语言、工具和环境: python python有着全品类的数据科学工具，从数据获取、数据清洗到整合各种算法都做得非常全面。 网页爬虫: scrapy 数据挖掘: pandas：模拟R，进行数据浏览与预处理。 numpy：数组运算。 scipy：高效的科学计算。 matplotlib：非常方便的数据可视化工具。 机器学习: scikit-learn：远近闻名的机器学习package。未必是最高效的，但是接口真心封装得好，几乎所有的机器学习算法输入输出部分格式都一致。而它的支持文档甚至可以直接当做教程来学习，非常用心。对于不是非常高纬度、高量级的数据，scikit-learn胜任得非常好(有兴趣可以看看sklearn的源码，也很有意思)。 libsvm：高效率的svm模型实现(了解一下很有好处，libsvm的系数数据输入格式，在各处都非常常见) keras/TensorFlow：对深度学习感兴趣的同学，也能很方便地搭建自己的神经网络了。 自然语言处理: nltk：自然语言处理的相关功能做得非常全面，有典型语料库，而且上手也非常容易。 交互式环境： ipython notebook：能直接打通数据到结果的通道，方便至极。强力推荐。 3.编程语言、工具和环境: R R最大的优势是开源社区，聚集了非常多功能强大可直接使用的包，绝大多数的机器学习算法在R中都有完善的包可直接使用，同时文档也非常齐全。常见的package包括：RGtk2, pmml, colorspace, ada, amap, arules, biclust, cba, descr, doBy, e1071, ellipse等等。另外，值得一提的是R的可视化效果做得非常不错，而这对于机器学习是非常有帮助的。 4.其他语言 相应资深程序员小哥哥的要求，再补充一下Java和C++相关机器学习package。 Java系列 WEKA Machine Learning Workbench 相当于java中的scikit-learn 其他的工具如 Massive Online Analysis（MOA）、MEKA 、 Mallet等也非常有名。 C++系列 mlpack，高效同时可扩充性非常好的机器学习库。 Shark：文档齐全的老牌C++机器学习库。 七、相关学习文档资料： 目前比较好的中文文档。 分享给大家的python资料包pan.baidu.com，自己去下载。","tags":[{"name":"Python","slug":"Python","permalink":"http://clarkhedi.github.io/tags/Python/"}]},{"title":"手把手教如何将本地项目上传到GitHub","date":"2020-04-14T14:39:06.000Z","path":"2020/04/14/shou-ba-shou-jiao-ru-he-jiang-ben-di-xiang-mu-shang-chuan-dao-github/","text":"总体介绍使用git上传文件到GitHub需要git客户端以及注册GitHub账号。命令简单上传通道 git官网:去git官网 github官网:去github官网 git的安装以及GitHub的注册这里就不说了。还不知道的，没安装的看这里：我要去看git安装教程 下边就直接从上传开始。 第一步：创建文件夹我们需要先创建一个本地的版本库（其实也就是一个文件夹）。 你可以直接在桌面右击新建文件夹，也可以右击打开Git bash命令行窗口通过命令来创建。 还可以通过命令行在桌面新建一个文件夹（你也可以在其他任何地方创建这个文件夹），并且进入这个文件夹 比如说：我用之前创建好的Learn Python文件夹，右击进入Git bash 第二步：git init在命令行中输入git init把这个文件夹变成Git可管理的仓库 这时你会发现Learn Python里面多了个.git文件夹，它是Git用来跟踪和管理版本库的，因为它默认是隐藏文件，要是看不到就设置下文件夹和搜索选项。 之后把需要上传到GitHub的文件全部复制到这Learn Python这个目录下。 然后通过git add .(注意这个”.”，是有空格的，”.”代表Learn Python这个文件夹下的目录全部都提交。你也可以通过git add 文件名 提交指定的文件)把文件添加到缓存区。 然后可以通过git status命令，查看下现在的状态，也可以不看，随你。 看到所有文件夹的内容都提交上去了。 然后，在使用命令git commit -m &quot;这里面写你的注释&quot; 把文件提交的本地仓库。 第三步：连接Github下面就到了连接远程仓库。 ​ 由于本地Git仓库和Github仓库之间的传输是通过SSH加密的，所以连接时需要设置一下： ​ 创建SSH KEY。先看一下你C盘用户目录下有没有.ssh目录，有的话看下里面有没有id_rsa和id_rsa.pub这两个文件，有就跳到下一步，没有就通过下面命令创建:ssh-keygen -t rsa -C &quot;youremail@example.com&quot;然后一路回车。这时你就会在用户下的.ssh目录里找到id_rsa和id_rsa.pub这两个文件，id_rsa是私钥，不能告诉别人；id_rsa.pub是公钥。 第四步：登录Github找到右上角的图标，打开点进里面的Settings，再选中里面的SSH and GPG KEYS，点击右上角的New SSH key，然后Title里面随便填，再把刚才id_rsa.pub里面的内容复制到Title下面的Key内容框里面，最后点击Add SSH key，这样就完成了SSH Key的加密。具体步骤也可看下面： 第五步：在Github上创建一个Git仓库。你可以直接点New repository来创建，比如我创建了一个Python-Basic-Introduction的仓库。 上面我没有默认勾选Initialize this repository with a README，勾选的话会在远程仓库（也就是Github）上创建README.md文件。 第六步：进行关联在Github上创建好Git仓库之后我们就可以和本地仓库进行关联了，根据创建好的Git仓库页面的提示，可以在本地Learn Python仓库的命令行输入：git remote add origin https://github.com/clarkhedi/Python-Basic-Introduction.git 第七步：推送到远程仓库关联好之后我们就可以把本地库的所有内容推送到远程仓库（也就是Github）上了，通过： git push -u origin master（由于新建的远程仓库是空的，所以要加上-u这个参数）。会弹出以下界面即输入你的GitHub的username和password： 然后进去GitHub的Python-Basic-Introduction这个仓库刷新下就会有已经上传的文件夹了。 注意：如果新建远程仓库不是空的，例如你勾选了 Initialize this repository with a README。那么你通过命令 $ git push -u origin master是会报错的这是由于你新创建的那个仓库里面的README文件不在本地仓库目录中，这时我们可以通过以下命令先将内容合并以下：git pull --rebase origin master再输入git push origin master。 至此就完成了将本地项目上传到Github的整个过程。 更新文件到github其实也差不多的步骤 输入指令：git add 文件名称或者 git add. 输入指令：git commit -m “这是注释内容” 这一步从本地仓库或本地分支获取并集成(整合)，输入指令：git pull origin master 如果过程中出现‘please enter a commit message…’,首先按下esc退出键然后输入 :wq即可 输入指令：git push origin master 按照这些更新步骤走完之后刷新你的github主页就能看到文件已经推送到仓库，从仓库中的文件推送时间就可以知道。 如果你发现文件的推送并不是你此次更新的时间而是上次推送时间，证明你并没有更新成功，请仔细检查再重新敲一遍更新流程即可。","tags":[{"name":"GitHub","slug":"GitHub","permalink":"http://clarkhedi.github.io/tags/GitHub/"}]},{"title":"Python基础入门学习","date":"2020-04-14T14:31:59.000Z","path":"2020/04/14/python-ji-chu-ru-men-xue-xi/","text":"总体介绍本文使用的实验编程环境是：jupyter lab、python3.7.6。 推荐大家自己手敲过一遍。项目已上传到GitHub。 一、算术运算11+(100-20)/4+5*2 #四则运算 输出：31.0 12**10 #乘方运算 输出：1024 17%5 #求模运算 输出：2 17//5 #地板除法(整除) 输出：1 1abs(-1) #绝对值运算(适用于float、int和复数类型。返回是float和int类型) 输出：1 1import math 1math.fabs(-5) #绝对值运算(只适用于float、int类型。返回是float类型) 输出：5.0 1math.sin(math.pi/2) #三角函数运算 输出：1.0 1math.log(math.e) #对数运算(log默认以e为底) 输出：1.0 1math.factorial(5) # 阶乘运算 输出：120 1(1 + 2j) + (3 - 1j) #复数运算 输出：(4+1j) 1complex(2,1)/(2+1j) #复数运算 输出：(1+0j) 1#math.factorial(1000) + 2**100 #强大的计算器 二、输入输出输入：input 输出：print 123#input 输入的都是字符串weight = input(&#x27;please input your weight:&#x27;)weight 123输出：please input your weight: 60&#39;60&#39; 123#利用float函数将字符串转换成浮点数weight = float(input(&#x27;please input your weight:&#x27;))weight 123输出：please input your weight: 6060.0 123#利用eval函数将输入的字符串作为表达式进行计算age = eval(input(&#x27;please input your age:&#x27;))age #算年龄 123输出：please input your age: 2020-199822 12#输出用print,print()里变量用逗号(,)隔开即有：默认的 sep=&#x27; &#x27;分隔符，end=&#x27;\\n&#x27;结尾符print(f&#x27;your weight is:&#123;weight&#125;kg&#x27;) 输出：’your weight is:60kg’ 12#或者直接使用f-string(python3.6及以上版本)f&#x27;your age is:&#123;age&#125;&#x27; 输出：’your age is:22’ 三、导入模块import … 或 from … import …或 import … as … 1234### 以普通方式导入import datetimedatetime.datetime.today() #获取当前时间 输出：datetime.date(2020, 4, 12) 1234### 导入模块中某个对象from datetime import datetimedatetime.today() 输出：datetime.datetime(2020, 4, 12, 1, 16, 44, 79453) 12345### 导入模块中全部对象from datetime import *print(datetime.today())date.today() #获取当前日期 123输出：2020-04-12 01:54:03.982064datetime.date(2020, 4, 12) 1234### 以简写方式导入模块import datetime as dtdt.datetime.today() 输出：datetime.datetime(2020, 4, 12, 1, 20, 44, 994886) 四、语法规则1、标识符 标识符由字母、数字、下划线组成，区分大小写，不能以数字开头。以下划线开头的标识符有特殊含义。以单下划线开头的(_foo)代表不能直接访问类属性，以双下划线开头的(foo)代表类的私有成员；以双下划线开头和结尾的(__foo)代表Python里特殊方法专用的标识，如init()代表类的构造函数。 12import numpy as npnp.__version__ 输出：’1.18.2’ 2、缩进 Python的代码块不使用大括号或者其他来控制类、函数、以及其他逻辑判断，而是使用缩进来实现代码分组。通常用四个空格来进行缩进。 123456a, b = 1, 2if a &gt; b: x = aelse: x = bprint(x) 输出：2 3、注释 Python中单行注释采用 # 开头。多行注释在代码块首尾分别使用三个单引号(‘’’)或三个双引号(“””)。 12345678910&quot;&quot;&quot;author: HDdate: 2020-4-12&quot;&quot;&quot;def my_abs(x): #自定义绝对值函数 if x &gt; 0: return x else: return -xmy_abs(-5) 输出：5 4、一条语句粉多行显示 Python语句中一般以新行作为语句的结束符。但是我们可以使用反斜杠()将一行的语句分为多行显示。如果有{},[],()跨行则可以不使用\\。 12345print(1+2+3+4+5+6+\\+7+8+9+10)a = [1,2,3,4, 5,6,7,8]a 123输出：55[1, 2, 3, 4, 5, 6, 7, 8] 5、同一行显示多条语句 Python可以在同一行中使用多条语句，语句之间使用分号分割。 12a = 1; b = a + 5print(a,b) 输出：1 6 五、Python数据结构概述Python内建的数据结构有列表，元组，字符串，集合，字典等。 此外常用的还有numpy中的array，以及pandas中的dataframe和series。 1、有序数据结构： list(列表)，是有序集合，没有固定大小，可以通过对偏移量以及其他方法修改列表大小。基本形式如：[1,2,3,4] tuple(元组)，是有序集合、不可变的，可以进行组合和赋值运算后会生成一个新的元组。基本形式如：(1,3,5,7) str(字符串)，是有序集合，基本形式如：’hello’ 12345#有序数据结构可通过下标访问数据l = [1,2,3,4]print(l[0]) l[0] = 9l 123输出：1[9, 2, 3, 4] 2、无序数据结构 set(集合)，是一个无序不重复元素的集合。基本功能包括关系运算和消除重复元素。基本形式如：{‘apple’,’orange’,’banana’} dict(字典)，是无序的键值对的集合。**键必须是互不相同的(在同一个字典之内)**，可通过键访问其值。基本形式如：{‘ICBC’:95588,’BOC’:95566} 12d = &#123;&#x27;ICBC&#x27;:95588,&#x27;BOC&#x27;:95566&#125;d[&#x27;BOC&#x27;] 输出：95566 3、小知识：浅拷贝和深拷贝 浅拷贝(不可变类型tuple利用赋值):只是原来对象的一个别名即做更改拷贝后的对象会改变原来的对象 深拷贝(可变类型利用copy()函数):会开辟新的内存空间即做更改拷贝后的对象不会改变原来的对象 列表list1234567### 1、建立列表fruits = [&#x27;apple&#x27;,&#x27;orange&#x27;,&#x27;banana&#x27;] #直接建立a = list(range(1,11,2)) #利用list建立b = [2**i for i in range(5)] #利用列表推导式(for循环内的语句写在前面)建立c = [[i+j for i in range(3)] for j in range(2)] #利用列表推导式建立二维列表print(fruits,a,b,c,sep=&#x27;\\n&#x27;) 输出： [&#39;apple&#39;, &#39;orange&#39;, &#39;banana&#39;] [1, 3, 5, 7, 9] [1, 2, 4, 8, 16] [[0, 1, 2], [1, 2, 3]] 1234567891011### 2、访问列表# 列表支持下标访问和切片访问---具体有顺序(从左往右)和逆序(从右往左)# 比如：顺序从0开始，逆序从-1开始l = [1,2,3,4,5]print(l[0],l[-1],sep=&#x27;,&#x27;) #下标访问#切片访问，中间用冒号隔开，前两位取值遵循左闭右开原则，第三位2表示步长print(l[0:3:2],l[-5:-2:2],sep=&#x27;\\n&#x27;) print(l[:])print(l[:-1])print(l[::2]) 输出： 1,5 [1, 3] [1, 3] [1, 2, 3, 4, 5] [1, 2, 3, 4] [1, 3, 5] 1234567891011### 3、修改列表l = [1,2,3,4,5]l[0] = 0print(l)l.remove(2) #或者用del(l[1])删除元素值2print(l)l = l * 3 # *号有复制拷贝多份效果print(l)l = l + [6,7,8,9] # +号对序列有拼接作用print(l) 输出： [0, 2, 3, 4, 5] [0, 3, 4, 5] [0, 3, 4, 5, 0, 3, 4, 5, 0, 3, 4, 5] [0, 3, 4, 5, 0, 3, 4, 5, 0, 3, 4, 5, 6, 7, 8, 9] 12345678910### 4、列表常用函数print(len(l)) #列表长度print(max(l)) #列表中最大值print(min(l)) #列表中最小值print(sorted(l)) #列表中元素排序，默认从小到大print(sorted(l,reverse=True)) #改为逆序(从大到小) 输出： 16 9 0 [0, 0, 0, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 7, 8, 9] [9, 8, 7, 6, 5, 5, 5, 4, 4, 4, 3, 3, 3, 0, 0, 0] 12345678### 5、列表常用方法lt = [7,8,9]lt.extend([10,11])lt.append(12)print(lt)lt.insert(0,1)print(lt) 输出： [7, 8, 9, 10, 11, 12] [1, 7, 8, 9, 10, 11, 12] 字典dict字典在插入元素和查找元素方面很多时候比列表更加高效。 1234567### 1、创建字典d = &#123;1:3,2:4,3:6&#125; #一般创建a = dict([(&#x27;a&#x27;,1),[&#x27;b&#x27;,2]]) #利用dict创建b = dict(x=1,y=2)D = &#123;i:i**2 for i in range(5)&#125; #利用字典推导式创建print(d,a,b,D,sep=&#x27;\\n&#x27;) 输出： &#123;1: 3, 2: 4, 3: 6&#125; &#123;&#39;a&#39;: 1, &#39;b&#39;: 2&#125; &#123;&#39;x&#39;: 1, &#39;y&#39;: 2&#125; &#123;0: 0, 1: 1, 2: 4, 3: 9, 4: 16&#125; 1234567### 2、字典常用操作a[&#x27;a&#x27;] = 3 #通过键来改变和添加对应的值a[&#x27;c&#x27;] = 5print(a)a.update(&#123;&#x27;b&#x27;:4,&#x27;d&#x27;:8&#125;) #通过update函数更新对应的键值print(a) 输出： &#123;&#39;a&#39;: 3, &#39;b&#39;: 2, &#39;c&#39;: 5&#125; &#123;&#39;a&#39;: 3, &#39;b&#39;: 4, &#39;c&#39;: 5, &#39;d&#39;: 8&#125; 1a.keys() 输出：dict_keys([‘a’, ‘b’, ‘c’]) 1a.values() 输出：dict_values([3, 2, 5]) 1a.items() 输出：dict_items([(‘a’, 3), (‘b’, 2), (‘c’, 5)]) 123456d = &#123;&#x27;a&#x27;:3,&#x27;b&#x27;:4,&#x27;c&#x27;:5,&#x27;d&#x27;:8&#125;print(d.get(&#x27;b&#x27;)) #获取键对应的值d.get(&#x27;e&#x27;,0) #给没有的键设置默认值，没有添加进去print(d)d.setdefault(&#x27;e&#x27;,4) #给没有的键设置默认值并添加进去print(d) 输出： 4 &#123;&#39;a&#39;: 3, &#39;b&#39;: 4, &#39;c&#39;: 5, &#39;d&#39;: 8&#125; &#123;&#39;a&#39;: 3, &#39;b&#39;: 4, &#39;c&#39;: 5, &#39;d&#39;: 8, &#39;e&#39;: 4&#125; 字符串str12345### 1、创建字符串print(str(12345))s1 = &#x27;I\\&#x27;m Clark.\\nI just use Python to say:&quot;hello world&quot;!&#x27; #\\为转义字符print(s1) 输出： 12345 I&#39;m Clark. I just use Python to say:&quot;hello world&quot;! 12s2 = &quot;I&#x27;m Clark.\\nI just use Python to say:\\&quot;hello world\\&quot;!&quot;print(s2) 输出： I&#39;m Clark. I just use Python to say:&quot;hello world&quot;! 1234s3 = &#x27;&#x27;&#x27;I&#x27;m Clark.I just use Python to say:&quot;hello world&quot;!&#x27;&#x27;&#x27;print(s3) 输出： I&#39;m Clark. I just use Python to say:&quot;hello world&quot;! 123456### 2、字符串拼接(+,join)s1 = &quot;I&#x27;m Clark.&quot;s2 = &quot;I love Python.&quot;s3 = &#x27;I just use Python to say:&quot;hello world&quot;!&#x27;print(s1+&#x27;\\n&#x27;+s2+&#x27;\\n&#x27;+s3) # +号拼接 输出： I&#39;m Clark. I love Python. I just use Python to say:&quot;hello world&quot;! 1print(&#x27;\\n&#x27;.join([s1,s2,s3])) #join拼接 输出： I&#39;m Clark. I love Python. I just use Python to say:&quot;hello world&quot;! 1&#x27;abc&#x27; * 5 #乘法有复制效果 输出：’abcabcabcabcabc’ 12345### 3、字符串的常用方法#split()中第一个参数：分隔符--默认为所有的空字符，包括空格、换行(\\n)、制表符(\\t)等；第二个参数：分割次数--默认为 -1, 即分隔所有print(&quot;Clark\\t22\\tmale&quot;.split())&quot;Clark\\t22\\tmale&quot;.split(&#x27;\\t&#x27;,1) #分割完后的字符串个数=分割次数+1 123输出：[&#39;Clark&#39;, &#39;22&#39;, &#39;male&#39;][&#39;Clark&#39;, &#39;22\\tmale&#39;] 1&quot;\\n123abc\\t&quot;.strip() #strip()方法用于移除字符串头尾指定的字符（默认为空格或换行符）或字符序列 输出：’123abc’ 1&quot;$$$$abcdef$$$xyz&quot;.replace(&#x27;$&#x27;,&#x27;&#x27;) #用空字符串代替$ 输出：’abcdefxyz’ 12345### 4、格式化字符串(%或format或f-string)age = 22weight = 60.5hobby = &#x27;travelling&#x27; 12fs = &quot;I&#x27;m %d years old. My weight is %.2f kg. I like %s.&quot; %(age,weight,hobby) # %格式化print(fs) 输出：I’m 22 years old. My weight is 60.50 kg. I like travelling. 12fs = &quot;I&#x27;m &#123;&#125; years old. My weight is &#123;:.2f&#125; kg. I like &#123;&#125;.&quot; .format(age,weight,hobby) # format格式化print(fs) 输出：I’m 22 years old. My weight is 60.50 kg. I like travelling. 12fs = f&quot;I&#x27;m &#123;age&#125; years old. My weight is &#123;weight:.2f&#125; kg. I like &#123;hobby&#125;.&quot; # f-string格式化(python3.6版本及以上可以使用)print(fs) 输出：I’m 22 years old. My weight is 60.50 kg. I like travelling. 元组tuple1234567### 1、创建元组t = (1,2,3)t0 = ()t1 = (1,)x = 1,2print(t,t0,t1,x,sep=&#x27;\\n&#x27;) 输出： (1, 2, 3) () (1,) (1, 2) 123y = tuple([1,2,3])z = tuple(&#x27;abc&#x27;)print(y,z,sep=&#x27;\\n&#x27;) 输出： (1, 2, 3) (&#39;a&#39;, &#39;b&#39;, &#39;c&#39;) 12345### 2、使用元组t = (1,2,2,1,1,3)print(t.count(1))print(t.index(3)) 输出： 3 5 1234#序列解包a,b = 1,2t1,t2,t3 = [1,2,3]print(a,b,t1,t2,t3,sep=&#x27;\\n&#x27;) 输出： 1 2 1 2 3 1234#元组可以作为字典的keyd =&#123;(1,2):4&#125;print(d) 输出：{(1, 2): 4} 集合set123456### 1、创建集合s = &#123;1,2,3&#125;s0 = set() #创建空集合，&#123;&#125;是创建一个空字典s1 = &#123;x**2 for x in range(5)&#125;print(s,s0,s1,sep=&#x27;\\n&#x27;) 输出： &#123;1, 2, 3&#125; set() &#123;0, 1, 4, 9, 16&#125; 12345### 2、使用集合# 去除重复对象，求交集、并集、补集等操作a = [1,2,3,6,4,5,5,2,6,3,1]set(a) #去重 输出：{1, 2, 3, 4, 5, 6} 12345s1 = &#123;1,2,3,5,6&#125;s2 = &#123;2,5,6,7,8&#125;print(s1 &amp; s2) #交集print(s1 | s2) #并集print(s1.difference(s2)) #补集 输出： &#123;2, 5, 6&#125; &#123;1, 2, 3, 5, 6, 7, 8&#125; &#123;1, 3&#125; 六、条件语句 if1234567891011121314### 1、if语句a,b = 3,2if a&gt;b: x = aelse: x = bprint(x)#if...elif...elif...else...#单行实现if语句y = a if a&gt;b else bprint(y) 输出： 3 3 12345678### 2、逻辑运算符2&gt;3 1+2&lt;1003 == 4-12 != 3not 2 == 3 输出：True 12345678### 3、and和or2&gt;3 and 4&lt;52&gt;3 or 4&lt;5# 短路计算[] and [1,2] and &#123;&#125;[] or [1,2] or &#123;&#125; 输出：[1, 2] 12# 注意空字符串、空列表、空字典、空元组和空集合以及0的bool值为falsebool(&#x27;&#x27;),bool([]),bool(&#123;&#125;),bool(()),bool(set()),bool(0) 输出：(False, False, False, False, False, False) 七、循环语句 for,while12345### 1、for循环l = [1,2,3,4,5,6]for i in l: print(i,end=&#x27; &#x27;) 输出：1 2 3 4 5 6 123d = &#123;&#x27;a&#x27;:1,&#x27;b&#x27;:2,&#x27;c&#x27;:3&#125;for k,v in d.items(): print(k,&#x27;:&#x27;,v) 输出： a : 1 b : 2 c : 3 12345# for循环实现九九乘法表for i in range(1,10): for j in range(1,i+1): print(f&#x27;&#123;j&#125; x &#123;i&#125; = &#123;i*j:2d&#125;&#x27;,end=&#x27; &#x27;) print() 输出： 1 x 1 = 1 1 x 2 = 2 2 x 2 = 4 1 x 3 = 3 2 x 3 = 6 3 x 3 = 9 1 x 4 = 4 2 x 4 = 8 3 x 4 = 12 4 x 4 = 16 1 x 5 = 5 2 x 5 = 10 3 x 5 = 15 4 x 5 = 20 5 x 5 = 25 1 x 6 = 6 2 x 6 = 12 3 x 6 = 18 4 x 6 = 24 5 x 6 = 30 6 x 6 = 36 1 x 7 = 7 2 x 7 = 14 3 x 7 = 21 4 x 7 = 28 5 x 7 = 35 6 x 7 = 42 7 x 7 = 49 1 x 8 = 8 2 x 8 = 16 3 x 8 = 24 4 x 8 = 32 5 x 8 = 40 6 x 8 = 48 7 x 8 = 56 8 x 8 = 64 1 x 9 = 9 2 x 9 = 18 3 x 9 = 27 4 x 9 = 36 5 x 9 = 45 6 x 9 = 54 7 x 9 = 63 8 x 9 = 72 9 x 9 = 81 12345678### 2、while循环# 求1+2+3+...+100的和s,i = 0,1while i&lt;=100: s += i i += 1print(s,i) 输出：5050 101 12345# 打印斐波那契(Fibonacci)数列。这个数列前两项为 1，之后的每一个项都是前两项之和。a, b = 0, 1while b &lt; 100: print(b,end=&#x27; &#x27;) a, b = b, a + b 输出：1 1 2 3 5 8 13 21 34 55 89 123456789# while循环实现九九乘法表i = 1while i&lt;10: j = 1 while j&lt;i+1: print(f&#x27;&#123;j&#125; x &#123;i&#125; = &#123;i*j:2d&#125;&#x27;,end=&#x27; &#x27;) j +=1 print() i += 1 输出： 1 x 1 = 1 1 x 2 = 2 2 x 2 = 4 1 x 3 = 3 2 x 3 = 6 3 x 3 = 9 1 x 4 = 4 2 x 4 = 8 3 x 4 = 12 4 x 4 = 16 1 x 5 = 5 2 x 5 = 10 3 x 5 = 15 4 x 5 = 20 5 x 5 = 25 1 x 6 = 6 2 x 6 = 12 3 x 6 = 18 4 x 6 = 24 5 x 6 = 30 6 x 6 = 36 1 x 7 = 7 2 x 7 = 14 3 x 7 = 21 4 x 7 = 28 5 x 7 = 35 6 x 7 = 42 7 x 7 = 49 1 x 8 = 8 2 x 8 = 16 3 x 8 = 24 4 x 8 = 32 5 x 8 = 40 6 x 8 = 48 7 x 8 = 56 8 x 8 = 64 1 x 9 = 9 2 x 9 = 18 3 x 9 = 27 4 x 9 = 36 5 x 9 = 45 6 x 9 = 54 7 x 9 = 63 8 x 9 = 72 9 x 9 = 81 1234567891011121314151617### 3、循环控制 continue，breaks = &#x27;hello world&#x27;# break跳出本层循环for i in s: if i == &#x27; &#x27;: #遇到空格就终止 break print(i,end=&#x27;&#x27;)print() #换行# continue跳出本次循环for i in s: if i == &#x27; &#x27;: #不打印空格 continue print(i,end=&#x27;&#x27;) 输出： hello helloworld 1234567### 4、循环中的else# 循环后面使用可选的 else 语句。它将会在循环完毕后执行，一旦有break终止就不会执行else后面的语句。for i in range(0, 5): print(i,end=&#x27; &#x27;)else: print(&quot;Bye bye&quot;) 输出：0 1 2 3 4 Bye bye Python中循环的 else 子句给我们提供了检测循环是否顺利执行完毕的一种优雅方法 八、函数123456789### 1、函数参数：普通参数，默认参数，可变参数，关键字参数### 参数定义顺序：普通参数，默认参数，可变参数，关键字参数# 普通参数 x(位置参数)def my_abs(x): return x if x&gt;=0 else -xmy_abs(-5)my_abs(x = -5) 输出：5 12345678# 默认参数 n(参数缺失时赋默认参数且默认参数定义时必须写在普通参数后)def my_power(x,n=2): return x**nmy_power(5)my_power(5,3)my_power(x=5,n=3) 输出：125 123456789101112# 可变参数 *args(可以传入不定长度的参数序列---元组或列表)def my_sum(*args): s = 0 for i in args: s += i return smy_sum()my_sum(1,2,3)my_sum(*(1,2,3))my_sum(*[1,2,3]) 输出：6 12345678910# 关键字参数 **kv(可以传入字典)def student(name,age,**kv): d = &#123;&#x27;name&#x27;:name,&#x27;age&#x27;:age&#125; d.update(kv) #将传进的**kv参数更新到d中 return dstudent(&#x27;HD&#x27;,22,grade=&quot;一班&quot;,gender=&#x27;male&#x27;)Clark = &#123;&#x27;name&#x27;:&#x27;Clark&#x27;,&#x27;age&#x27;:22,&#x27;grade&#x27;:&quot;一班&quot;,&#x27;hometown&#x27;:&#x27;hunan&#x27;&#125;student(**Clark) 输出：{‘name’: ‘Clark’, ‘age’: 22, ‘grade’: ‘一班’, ‘hometown’: ‘hunan’} 1234567891011### 2、递归函数# 递归函数特点：调用自身# 斐波那契(Fibonacci)数列。这个数列前两项为 1，之后的每一个项都是前两项之和。def fib(n): if n in [1,2]: #前两项为 1 return 1 else: return fib(n-1) + fib(n-2)fib(11) 输出：89 1234567891011121314### 3、装饰器# 装饰器在不更改函数代码前提下赋予函数额外的功能# 通常把函数非核心逻辑如插入日志、权限校验、性能测试放在装饰器中import timedef decorater(func): def wrapper(*args,**kv): tic = time.time() ans = func(*args,**kv) toc = time.time() print(f&#x27;&#123;func.__name__&#125; is called. &#123;toc-tic&#125;s are used.&#x27;) return ans return wrapper 12345678@decoraterdef my_sum(*args): s = 0 for i in args: s += i return s# @decorater是一个语法糖# 相当于 my_sum = decorater(my_sum) 1my_sum(*range(100)) 输出： my_sum is called. 0.0s are used. 4950 1my_sum(1,2,3) #相当于 decorater(my_sum)(1,2,3) 输出： my_sum is called. 0.0s are used. 6 12345678@decoraterdef fib(n): if n in [1,2]: #前两项为 1 return 1 else: return fib(n-1) + fib(n-2)fib(4) 输出： fib is called. 0.0s are used. fib is called. 0.0s are used. fib is called. 0.0s are used. fib is called. 0.0s are used. fib is called. 0.0s are used. 3 九、lambda匿名函数lambda只是一个表达式，适合定义较为简单的函数,不可在里面写循环。 lambda函数的定义语法是： fun = lambda 参数序列:返回值表达式 一般来说通过使用lambda匿名函数可以节约程序开支并加快运行速度。 12my_abs = lambda x:x if x&gt;=0 else -xmy_abs(-5) 输出：5 12my_power = lambda x,n=2:x**nmy_power(-5) 输出：25 1(lambda x,n=2:x**n)(-5,3) 输出：-125 12my_sum = lambda *args:sum(args)my_sum(1,2,3) 输出：6 12student = lambda name,age,**kv:dict(name = name,age = age,**kv)student(&#x27;HD&#x27;,22,grade=&#x27;一班&#x27;,gender=&#x27;male&#x27;) 输出：{‘name’: ‘HD’, ‘age’: 22, ‘grade’: ‘一班’, ‘gender’: ‘male’} 12fib = lambda n:1 if n in [1,2] else fib(n-1) + fib(n-2)fib(11) 输出：89 十、高阶函数以函数为参数的函数称为高阶函数。常用的内置高阶函数有：map,reduce,filter。 高阶函数和匿名函数搭配使用，堪称绝配。 1234### 1、map将一个函数的方法作用到一个序列或者多个序列，且map返回的是map object# map原意为：映射list(map(lambda x:x**2,[1,2,3,4])) 输出：[1, 4, 9, 16] 1list(map(lambda x,y:x+y,&#x27;abc&#x27;,&#x27;123&#x27;)) #字符串中+号是拼接作用 输出：[‘a1’, ‘b2’, ‘c3’] 123456### 2、reduce将一个带有两个参数的函数的方法依次迭代作用到一个序列# reduce原意为：减少# reduce(f,[a,b,c,d]) 相当于 f(f(f(a,b),c),d)from functools import reducereduce(lambda x,y:x+y,[1,2,3,4]) 输出：10 1234### 3、filter根据一个函数(函数返回值最好是bool值)的规则过滤序列中的元素，且filter返回值返回的是filter object# filter原意为：过滤list(filter(lambda x:x&gt;0,[-1,1,-2,2])) 输出：[1, 2] 十一、Python推导式Python中的推导式是我最喜爱的一类语法规则，没有之一。 Python推导式可以生成列表、字典和集合。 Python推导式虽然简单，但表达能力很强，可以实现map，filter等功能，并且可以多重遍历。 淋漓尽致地体现了Python语言的simple，readable，powerful的特点。 12345678910111213141516171819202122### 1、列表推导式# 语法规范：# out_list = [out_express for out_express in input_list if out_express_condition]# 其中的 if 条件判断根据需要可有可无。# 生成平方数序列[x**2 for x in range(5)]# 求序列的绝对值l = [-1,-2,3,5,-6][x if x&gt;=0 else -x for x in l] # 函数在循环前list(map(lambda x:x if x&gt;=0 else -x,l))# 过滤序列中某些元素(条件在循环后)[x for x in l if x&gt;0]list(filter(lambda x:x&gt;0,l))# 多重遍历girls = [&#x27;Mary&#x27;,&#x27;Lily&#x27;]boys = [&#x27;Jim&#x27;,&#x27;John&#x27;][(b,g) for b in boys for g in girls] #out_express需用括号，顺序和不用推导式的原始for循环是一致的 输出：[(‘Jim’, ‘Mary’), (‘Jim’, ‘Lily’), (‘John’, ‘Mary’), (‘John’, ‘Lily’)] 1234### 2、字典推导式seasons = &#123;&#x27;Spring&#x27;,&#x27;Summer&#x27;,&#x27;Autumn&#x27;,&#x27;Winter&#x27;&#125;&#123;k:v for k,v in enumerate(seasons,start=1)&#125; 输出：{1: ‘Winter’, 2: ‘Summer’, 3: ‘Autumn’, 4: ‘Spring’} 1list(enumerate(seasons,start=1)) 输出：[(1, ‘Winter’), (2, ‘Summer’), (3, ‘Autumn’), (4, ‘Spring’)] 123keys = [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;]values = [1,2,3]&#123;k:v for k,v in zip(keys,values)&#125; 输出：{‘a’: 1, ‘b’: 2, ‘c’: 3} 1list(zip(keys,values)) 输出：[(‘a’, 1), (‘b’, 2), (‘c’, 3)] 1234567891011### 3、集合推导式# 生成绝对值序列&#123;abs(x) for x in [-1,2,-2,-3,1]&#125;# 求两个集合的交集a = &#123;1,2,3,4&#125;b = &#123;2,4,6,8&#125;a.intersection(b) #内置方法求交集&#123;x for x in a if x in b&#125; #集合推导式求交集 输出：{2, 4} 十二、类和对象1、面向对象基本概念 什么是面向过程编程和面向对象编程？ 面向过程编程(POP：Process Oriented Programming).程序被看成一系列命令的依次执行。基本封装形式为函数。设计函数的基本要点是IPO：输入input——&gt;处理Process——&gt;输出Output. 面向对象编程(OOP:Object Oriented Programming).程序被看成一系列对象的相互作用。基本的封装形式是类。设计类的基本要点是RPM：关系Relation，属性Property，方法Method. 面向对象基本术语？ 类：class，抽象数据结构，数据和算法的封装。如：定义一个类：dog。 对象：object，类的实例。如：dog类的一个实例：点点dot。 属性：properties，和对象关联的数据部分。如：weight体重，breed品种。 方法：methods，和对象关联的算法部分。如：run(),eat(),bark()。 面向对象编程的优点？ 容易使用：封装，奇妙的句点符号。 容易扩展：继承，多态。 2、创建类和对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# 创建一个Dog类class Dog(object): # 类的构造函数__init__ def __init__(self,name,weight,breed,age): self.name = name self.weight = weight self.breed = breed # __age为私有属性 self.__age = age def run(self): print(f&#x27;&#123;self.name&#125; is running...&#x27;) def bark(self): print(&#x27;Bowwow,Bowwow,Bowwow...&#x27;) def eat(self,food): print(f&#x27;&#123;self.name&#125; is eating &#123;food&#125;...&#x27;) def sleep(self): print(&#x27;Zzz...Zzz...Zzz...&#x27;) # __think为私有方法 def __think(self): print(&quot;I think I&#x27;m a hero and very handsome!&quot;) # speak公有方法可以调用私有方法 def speak(self,words=&#x27;&#x27;): self.__think() if words: print(words) # 实例化一个对象gu = Dog(&#x27;giao&#x27;,3,&#x27;Husky&#x27;,4) #调用类的构造函数__init__# 调用公有属性和公有方法print(gu.breed)gu.run()gu.bark()gu.eat(&#x27;meat&#x27;)gu.speak(&quot;HaHaHa!!!&quot;)gu.sleep()# 私有属性和私有方法不能够直接在类外部访问# gu.__age# gu.__think() 输出： Husky giao is running... Bowwow,Bowwow,Bowwow... giao is eating meat... I think I&#39;m a hero and very handsome! HaHaHa!!! Zzz...Zzz...Zzz... 3、获取对象信息 123456789# Python中万物皆对象。对象由类创建而来，所有的类都是object基类的子类。# type查看对象类别type(1),type(False),type(gu),type(len),type([1,2,3])# isinstance 测试某个对象是否属于某个类isinstance(&#123;1,2,3&#125;,set) #输出：Trueisinstance(max,object) #输出：Trueisinstance(123,(list,str,float,int)) 输出：True 十三、封装和继承1、封装 奇妙的句点符号：通过奇妙的句点符号可以召唤对象的属性和方法。私有属性和私有方法除外。 (1) 公有属性和公有方法 (2) 私有属性和私有方法：以双下划线开头 (3) 定制属性和定制方法：以双下划线开头和双下划线结尾 __init__ 构造函数，通过类名调用 __str__ 通过str函数调用 __len__ 通过len函数调用 …… (4) 类属性和类方法：在__init__外部定义的为类属性，第一个参数不是self参数的方法为类方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576class Animal(object): #类属性 home = &#x27;earth&#x27; #类方法 def dream(): print(&#x27;No deal,no hurt!&#x27;) #定制方法 def __str__(self): #从属于对象的，所以加self return f&#x27;An animal named &#123;self.name&#125;&#x27; #类的构造函数__init__ def __init__(self,name,weight,breed,age): self.name = name self.weight = weight self.breed = breed # __age为私有属性 self.__age = age def run(self): print(f&#x27;&#123;self.name&#125; is running...&#x27;) def eat(self,food): print(f&#x27;&#123;self.name&#125; is eating &#123;food&#125;...&#x27;) def sleep(self): print(&#x27;Zzz...Zzz...Zzz...&#x27;) # __think为私有方法 def __think(self): print(&quot;I think I&#x27;m a hero and very handsome!&quot;) # speak公有方法可以调用私有方法 def speak(self,words=&#x27;&#x27;): self.__think() if words: print(words)#类属性homegu = Animal(&#x27;giao&#x27;,3,&#x27;Husky&#x27;,4) #实例化一个对象gugu.home #输出为：&#x27;earth&#x27;Animal.home #输出为：&#x27;earth&#x27;Animal.home = &#x27;Jupyter&#x27; #修改类属性homegu.home #输出为：&#x27;Jupyter&#x27;#增加对象gu的一个公有属性home，通过对象能够访问，但通过对象不能够修改类属性homegu.home = &#x27;moon&#x27; gu.home #输出为：&#x27;moon&#x27;Animal.home #输出为：&#x27;Jupyter&#x27;del gu.home #删除对象gu的一个公有属性homegu.home #输出为：&#x27;Jupyter&#x27;#类方法只能通过类名访问，不能通过对象访问Animal.dream()#通过类名也可以访问对象方法Animal.run(gu) #参数self通过对象gu传递gu.run() #定制方法有特殊的功能，通过str调用str(gu) #参数self通过对象gu传递#奇妙的句点符号s = &#x27;abc#123@def&#x27;#面向过程必须记住非常多的函数名，如：replace,upper,find...#面向对象只需要输入奇妙的句点符号后按下tab键s.replace(&#x27;#&#x27;,&#x27;&#x27;).replace(&#x27;@&#x27;,&#x27;&#x27;) #输出为：&#x27;abc123def&#x27;len(s) #输出：11s.__len__() #调用其定制方法# dir(s) #查看全部可用属性和方法 输出： No deal,no hurt! giao is running... giao is running... 11 2、继承 123456789101112# 子类可以通过继承获得父类的属性和方法# 可以继承多个父类，且可以增加新的属性和方法class Cat(Animal): def call(self): print(&#x27;MiaoMiaoMiao...&#x27;) #实例化一个对象kittykitty = Cat(&#x27;kitty&#x27;,1,&#x27;Bose&#x27;,5)kitty.run()kitty.call()kitty.speak(&#x27;MiaoMiaoMiao...&#x27;) 输出： kitty is running... MiaoMiaoMiao... I think I&#39;m a hero and very handsome! MiaoMiaoMiao... 十四、模块和包一个.py文件就是一个模块。 一个包含有__init__.py文件的文件夹就是一个包。 1、模块示范 写入一个my_nodule的模块： 123456789101112131415161718192021222324252627282930%%writefile my_module.py #!/usr/bin/env python3#-*- coding:utf-8 -*-&#x27;a test module&#x27; #模块注释__author__ = &#x27;HD&#x27; #作者信息__version__ = &#x27;v2.0&#x27; #版本信息def __Email(): #模块私有函数 print(&#x27;hedi1117@126.com&#x27;) def __Wechat_Official_Account(): #模块私有函数 print(&#x27;学长说python&#x27;) def hello(person = &#x27;world&#x27;): #公有函数 print(&#x27;hello&#x27;,person) def test(): #测试代码 hello() hello(&#x27;China&#x27;) print(&#x27;Contact to me:&#x27;,end=&#x27; &#x27;) __Email() print(&#x27;Learn more with me:&#x27;,end=&#x27; &#x27;) __Wechat_Official_Account() #当直接运行该模块时，执行测试代码，而引入模块时不执行测试代码。if __name__ == &#x27;__main__&#x27;: test() 输出：Overwriting my_module.py 123#测试一下模块import my_module# help(my_module) #查看my_module.py 1my_module.__author__ 输出：’HD’ 1my_module.__doc__ #查看模块注释 输出：’a test module’ 1!python my_module.py #执行脚本 输出： hello world hello China Contact to me: hedi1117@126.com Learn more with me: 学长说python 2、包示范 建立一个Animal文件夹: 1!mkdir Animal 123456%%writefile Animal/__init__.py#!/usr/bin/env python3#-*- coding:utf-8 -*-&#x27;Animal module for fun！&#x27; #模块注释__author__ = &#x27;HD&#x27; #作者信息 输出：Writing Animal/__init__.py 1234%%writefile Animal/Animal.pyclass Animal(object): def __init__(self,name): self.name = name 输出：Writing Animal/Animal.py 12345%%writefile Animal/Cat.pyfrom Animal.Animal import Animalclass Cat(Animal): def call(self): print(&#x27;miaoao...miaoao...miaoao...&#x27;) 输出：Writing Animal/Cat.py 12345%%writefile Animal/Dog.pyfrom Animal.Animal import Animalclass Dog(Animal): def call(self): print(&#x27;Bowwow...Bowwow...Bowwow...&#x27;) 输出：Writing Animal/Dog.py 123#测试一下包import Animal#help(Animal) 123from Animal.Dog import Doggu = Dog(&#x27;giao&#x27;)gu.call() 输出：Bowwow…Bowwow…Bowwow… 123from Animal.Cat import Catkitty = Cat(&#x27;kitty&#x27;)kitty.call() 输出：miaoao…miaoao…miaoao… 十五、异常处理模块1、捕捉异常的关键字语句： try...except...finally... 123456789101112131415161718import mathfor i in range(10): try: #遇到异常跳出并执行except捕捉异常的语句 input_number = input(&#x27;please input a number:&#x27;) if input_number == &#x27;q&#x27;: break result = 1/math.log(float(input_number)) print(&#x27;current value is: &#x27;,result) except ValueError: #捕捉ValueError异常 print(&#x27;ValueError: input must &gt; 0&#x27;) except ZeroDivisionError: #捕捉ZeroDivisionError异常 print(&#x27;ZeroDivisionError: log(value) must != 0&#x27;) except Exception: #捕捉除上述俩个异常外的其他所有异常 break finally: #无论遇没遇到异常都会执行的语句 print(&#x27;Finally!&#x27;)# 输出结果自己动手操作查看。 2、抛出异常的关键字语句： raise... 12345678910#定义一个异常类class MyError(ValueError): #继承ValueError类 pass cur_list = [&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;]while True: cur_input = input() if cur_input not in cur_list: raise MyError(&#x27;Invalid input: %s&#x27; %cur_input) #抛出MyError异常# 输出结果自己动手操作查看。 十六、文件操作Python文件操作中的步骤： open-&gt;操作-&gt;close 123456789#创建并打开file.txt空文件，以&#x27;w&#x27;形式写入文件txt = open(&#x27;file.txt&#x27;,&#x27;w&#x27;) #&#x27;w&#x27;会覆盖原来文件，在文件后添加东西用&#x27;a&#x27;for i in range(5): txt.write(str(i) + &#x27;\\n&#x27;) #写操作txt.close() #必须进行关闭文件操作，否则后面读取不到文件txt2 = open(&#x27;file.txt&#x27;,&#x27;r&#x27;)#读操作print(txt2.read()) #全部读出来或#print(txt2.readlines()) #返回一个列表，可一行一行的读取 以上下文管理器 with 进行文件操作 123# with操作可自动关闭文件with open(&#x27;file1.txt&#x27;,&#x27;w&#x27;) as f: f.write(&#x27;Python is strength&#x27;) #写操作 十七、学习资料 Python中文文档 实验楼学习 在线手册","tags":[{"name":"Python","slug":"Python","permalink":"http://clarkhedi.github.io/tags/Python/"}]},{"title":"Numpy基础入门","date":"2020-04-09T12:46:49.000Z","path":"2020/04/09/numpy-ji-chu-ru-men/","text":"总体介绍NumPy（Numerical Python）是 Python 中的一个线性代数库。对每一个数据科学或机器学习 Python 包而言，这都是一个非常重要的库，SciPy（Scientific Python）、Mat-plotlib（plotting library）、Scikit-learn 等都在一定程度上依赖 NumPy。 对数组执行数学运算和逻辑运算时，NumPy 是非常有用的。在用 Python 对 n 维数组和矩阵进行运算时，NumPy 提供了大量有用特征。 1、什么是numpy？一言以蔽之，numpy是python中基于数组对象的科学计算库。 提炼关键字，可以得出numpy以下三大特点： 拥有n维数组对象; 拥有广播功能（后面讲到）； 拥有各种科学计算API，任你调用； 2、如何安装numpy？因为numpy是一个python库，所以使用python包管理工具pip或者conda都可以安装。 安装python后，打开cmd命令行，输入： 1pip install numpy 即可完成安装。 3、什么是n维数组对象？n维数组（ndarray）对象，是一系列同类数据的集合，可以进行索引、切片、迭代操作。 numpy中可以使用array函数创建数组: 123import numpy as npnp.array([1,2,3])# 输出：array([1, 2, 3]) 4、如何区分一维、二维、多维？判断一个数组是几维，主要是看它有几个轴（axis）。 一个轴表示一维数组，两个轴表示二维数组，以此类推。 每个轴都代表一个一维数组。 比如说，二维数组第一个轴里的每个元素都是一个一维数组，也就是第二个轴。 一维数组一个轴： 1[1,2,3] 二维数组两个轴： 12[[0, 1, 2], [3, 4, 5]] 三维数组三个轴： 12345[[[ 0, 1, 2], [ 3, 4, 5]], [[ 6, 7, 8], [ 9, 10, 11]]] 以此类推n维数组。 5、如何创建n维数组？numpy中常用array函数创建数组，传入列表或元组即可。 创建一维数组，并指定数组类型为int： 123import numpy as npnp.array([1,2,3],dtype=int)# 输出：array([1, 2, 3]) 创建二维数组： 12345678import numpy as npnp.array(((1,2),(3,4))) &#x27;&#x27;&#x27;输出：array([[1, 2], [3, 4]])&#x27;&#x27;&#x27; 还可以使用arange函数创建一维数字数组，用法类似python的range函数. 12345import numpy as npnp.arange(1,6)&#x27;&#x27;&#x27;输出：array([1, 2, 3, 4, 5])&#x27;&#x27;&#x27; 6、如何创建随机数组？numpy的random模块用来创建随机数组。 random.random(size=None)函数 1np.random.random((100, 50)) 以上代码表示生成100行 50列的随机浮点数，浮点数范围 : (0,1) 值得注意的是以下代码与上述效果一样 1np.random.random([100, 50]) random.rand函数，生成[0,1)均匀分布的随机数组 12345678import numpy as np# 创建2行2列取值范围为[0,1)的数组np.random.rand(2,2)&#x27;&#x27;&#x27;输出：array([[0.99449146, 0.92339551], [0.1837405 , 0.41719798]])&#x27;&#x27;&#x27; random.randn函数，生成数值成标准正态分布（平均值为0，标准差为1）的数组 123456789import numpy as np# 创建2行3列，取值范围为标准正态分布的数组np.random.randn(3,2)&#x27;&#x27;&#x27;输出：array([[-1.27481003, -1.5888111 ], [ 0.16985203, -2.91526479], [ 1.75992671, -2.81304831]])&#x27;&#x27;&#x27; random.randint函数，生成可以指定范围的随机整数数组 12345678import numpy as np# 创建2行2列,取值范围为[2,10)的随机整数数组np.random.randint(2,10,size=(2,2))&#x27;&#x27;&#x27;输出：array([[5, 4], [3, 7]])&#x27;&#x27;&#x27; random.normal函数，生成数值成正态分布（可指定平均值、标准差）的数组 12345678import numpy as np# 创建一维，数值成正态分布（均值为1，标准差为2）的数组# 参数loc代表均值，scale代表标准差np.random.normal(loc=1,scale=2,size=5)&#x27;&#x27;&#x27;输出：array([ 0.82962241, 0.41738042, 0.0470862 , 1.79446076, -1.47514478])&#x27;&#x27;&#x27; random模块还有其他函数，这里不多说。 7、如何查看数组的维度？前面说到，数组维度即代表轴的数量。 我们可以通过数组（ndarray）对象的ndim或shape属性，来查看轴的数量。 ndim属性直接返回维度值； shape属性返回一个元组，元组的长度即代表维度值，里面的数字从左往右分别代表每一轴的元素数量。 123456789101112131415161718import numpy as np# 创建一维数组x1 = np.array([1,2,3])# 返回维度值x1.ndim&#x27;&#x27;&#x27;输出：1&#x27;&#x27;&#x27;# 创建二维数组x2 = np.array([[1,2,3],[4,5,6]])# 返回形状x2.shape&#x27;&#x27;&#x27;输出：(2, 3)元素长度为2代表二维，元素2代表0轴有两个元素，元素3代表1轴有3个元素。&#x27;&#x27;&#x27; 8、如何查看数组有多少个元素？数组（ndarray）对象的size属性可以查看数组包含元素总数。 12345678import numpy as np# 创建二维数组x2 = np.array([[1,2,3],[4,5,6]])# 查看元素总数x2.size&#x27;&#x27;&#x27;输出：6&#x27;&#x27;&#x27; 还可以通过shape属性返回元素的乘积，来计算数组元素数量。 1234567891011import numpy as npfrom functools import reduce# 创建二维数组x2 = np.array([[1,2,3],[4,5,6]])# 查看元素总数reduce(lambda x,y:x*y , x2.shape)&#x27;&#x27;&#x27;输出：6shape形状：(2,3)&#x27;&#x27;&#x27; 9、Numpy数组支持哪些数据类型？Numpy支持的数据类型非常多，所以很适合做数值计算。下面给出常见的数据类型： 10、如何查看和转换数组的类型？数组（ndarrry）对象提供dtype属性和astype属性。dtype用来查看数组类型，astype用来转换数组的数据类型 1234567891011import numpy as np# 创建二维数组x2 = np.array([[1,2,3],[4,5,6]],dtype=int)# 返回类型x2.dtypex2.astype(&#x27;float&#x27;)x2.dtype&#x27;&#x27;&#x27;输出：dtype(&#x27;int32&#x27;)输出：dtype(&#x27;float64&#x27;)&#x27;&#x27;&#x27; dtype：一个用于说明数组数据类型的对象。返回的是该数组的数据类型。由于图中的数据都为整形，所以返回的都是int32。如果数组中有数据带有小数点，那么就会返回float64。 有疑问的是：整形数据不应该是int吗？浮点型数据不应该是float吗？ 解答：int32、float64是Numpy库自己的一套数据类型。 astype：转换数组的数据类型。 ​ int32 –&gt; float64 完全ojbk ​ float64 –&gt; int32 会将小数部分截断 ​ string_ –&gt; float64 如果字符串数组表示的全是数字，也可以用astype转化为数值类型 注意其中的float，它是python内置的类型，但是Numpy可以使用。Numpy会将Python类型映射到等价的dtype上。 11、如何改变数组的形状？前面说过，数组的shape属性返回一个元组，能够反映数组的形状，包括维度以及每个轴的元素数量。 那么如果给定一个数组，怎么改变其形状呢？ 常用的方式有两种： reshape方法，它返回一个新的数组，而不能改变原始数组。 resize方法，无返回值，它更改了原始数组。 比如说我要将一个二维数组转换为三维数组。 12345678910import numpy as np# 创建二维数组x2 = np.array([[1,2,3],[4,5,6]])# 将x2转换为三维数组，并且自定义每个轴的元素数量x2.reshape(1,2,3)&#x27;&#x27;&#x27;输出：array([[[1, 2, 3], [4, 5, 6]]])&#x27;&#x27;&#x27; reshape方法可以传入整数或者元组形式的参数。 传入的参数和shape属性返回的元组的含义是一样的。 例如， x2.reshape(1,2,3)是将二维数组转换成三维数组，参数个数代表要转换的维度，参数数字从左到右分别表示0轴、1轴、2轴的元素数量。 resize方法和reshape方法使用形式一样，区别是resize方法改变了原始数组形状。 1234567891011import numpy as np# 创建二维数组x2 = np.array([[1,2,3],[4,5,6]])# 将x2转换为三维数组，并且自定义每个轴的元素数量x2.resize((1,2,3))x2&#x27;&#x27;&#x27;输出：array([[[1, 2, 3], [4, 5, 6]]])&#x27;&#x27;&#x27; 12、如何对数组进行索引和切片操作？numpy一维数组的索引和切片操作类似python列表，这里不多讲。 比如说取一维数组前三个元素。 123456789import numpy as np# 创建一维数组x1 = np.array([1,2,3,4])# 切片，取前三个元素x1[:3]&#x27;&#x27;&#x27;输出：array([1, 2, 3])&#x27;&#x27;&#x27; 重点是对多维数组的索引和切片。 多维数组有多个轴，那么就需要对每个轴进行索引。 例如，三维数组形状为(x,y,z)，分别代表：0轴有x个元素、1轴有y个元素，2轴有z个元素。 对0、1、2轴进行索引，如果取o轴第2个元素、1轴第0个元素、2轴第3个元素，那么索引形式就为[2,0,3]。 12345678910111213141516171819import numpy as np# 创建三维数组x3 = np.arange(24).reshape(3,2,4)# 对该三维数组进行索引x3[2,0,3]&#x27;&#x27;&#x27;输出：19三维数组形式：array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7]], [[ 8, 9, 10, 11], [12, 13, 14, 15]], [[16, 17, 18, 19], [20, 21, 22, 23]]])&#x27;&#x27;&#x27; 切片也是同样道理。 如果取0轴前2个元素、1轴前1个元素、2轴后2个元素，那么切片形式就为[:2,:1,-2:]。 12345678910111213141516171819202122import numpy as np# 创建三维数组x3 = np.arange(24).reshape(3,2,4)# 对该三维数组进行切片x3[:2,:1,-2:]&#x27;&#x27;&#x27;输出：array([[[ 2, 3]], [[10, 11]]])三维数组形式：array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7]], [[ 8, 9, 10, 11], [12, 13, 14, 15]], [[16, 17, 18, 19], [20, 21, 22, 23]]])&#x27;&#x27;&#x27; 13、如何对数组里每个元素进行迭代？说到迭代，大家很容易想到直接对数组直接使用for循环操作，对于一维数组来说，当然是可以的。 12345678910111213import numpy as np# 创建一维数组x1 = np.array([1,2,3,4])# 迭代for i in x1: print(i)&#x27;&#x27;&#x27;输出：1234&#x27;&#x27;&#x27; 但对于多维数组，迭代是相对于0轴完成的，就是多维数组最外层的那一维。 你没有办法直接遍历数组里每一个元素，嵌套循环又太低效。 这个时候就需要用到flat方法，它可以将多维数组平铺为一维的迭代器。 123456789101112131415import numpy as np# 创建二维数组x2 = np.array([[1,2,3],[4,5,6]])# 先平铺，再迭代for i in x2.flat: print(i)&#x27;&#x27;&#x27;输出：123456&#x27;&#x27;&#x27; 14、如何将多维数组展开为一维数组？数组（ndarray）对象提供了ravel方法，用来将多维数组展开为一维数组。 123456789import numpy as np# 创建er维数组x3 = np.arange(12).reshape(3,4)# 对该三维数组进行索引x3.ravel()&#x27;&#x27;&#x27;输出：array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])&#x27;&#x27;&#x27; 15、什么广播机制？广播(Broadcast)是 numpy 对不同形状(shape)的数组进行数值计算的方式， 对多个数组的算术运算通常在相应的元素上进行。 较小的数组在较大的数组上“广播”，以便它们具有兼容的形状。 比如说一个一维数组乘以一个数字，相当于一维数组里每个元素都乘以这个数。 123456789import numpy as np# 创建一维数组x1 = np.array([1,2,3])# 广播x1 * 2&#x27;&#x27;&#x27;输出：array([2, 4, 6])&#x27;&#x27;&#x27; 如果相同维度的数组进行运算，其shape相同，那么广播就是两个数组相同位数的元素进行运算。 12345678910import numpy as np# 创建一维数组x1 = np.array([1,2,3])x2 = np.array([4,5,6])# 广播x1 + x2&#x27;&#x27;&#x27;输出：array([5, 7, 9])&#x27;&#x27;&#x27; 如果两个数组维度不同，进行运算，这里就触发了广播的两个规则。 让所有输入数组都向其中形状最长的数组看齐，形状中不足的部分都通过在前面加 1 补齐； 当输入数组的某个维度的长度为 1 时，沿着此维度运算时都用此维度上的第一组值。 这两个规则保证了不同维度数组进行运算时，其维度自动调整成一致。 1234567891011import numpy as np# 创建一维数组x1 = np.array([[1,2,3],[4,5,6]])x2 = np.array([2,3,4])# 广播x1 - x2&#x27;&#x27;&#x27;输出：array([[-1, -1, -1], [ 2, 2, 2]])&#x27;&#x27;&#x27; 16、numpy中如何进行数值舍入操作？ around函数，用于四舍五入，返回一个新数组 123456789import numpy as np# 创建一维数组x1 = np.array([1.45,2.78,3.12])# 四舍五入，到小数点后1位np.around(x1,1)&#x27;&#x27;&#x27;输出：array([1.4, 2.8, 3.1])&#x27;&#x27;&#x27; 注意：python3中四舍五入如果是像1.5、0.5、2.5这种中间型的，返回值为离它最近的偶数。 floor函数，用于向下取整，返回一个新数组 123456789import numpy as np# 创建一维数组x1 = np.array([1.45,2.78,3.12])# 向下取整np.floor(x1)&#x27;&#x27;&#x27;输出：array([1., 2., 3.])&#x27;&#x27;&#x27; ceil函数，用于向上取整，返回一个新数组 123456789import numpy as np# 创建一维数组x1 = np.array([1.45,2.78,3.12])# 向下取整np.ceil(x1)&#x27;&#x27;&#x27;输出：array([2., 3., 4.])&#x27;&#x27;&#x27; 17、如何对数组进行转置操作？numpy提供了transpose函数用以对数组进行维度的调换，也就是转置操作。 转置后返回一个新数组。 12345678910111213141516import numpy as np# 创建二维数组x1 = np.arange(12).reshape(3,4)# 转置np.transpose(x1)&#x27;&#x27;&#x27;输出：array([[ 0, 4, 8], [ 1, 5, 9], [ 2, 6, 10], [ 3, 7, 11]])原数组：array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]])&#x27;&#x27;&#x27; 当然，可以用更简单的方法。 数组对象提供了T方法，用于转置，同样会返回一个新数组。 12345678910111213141516import numpy as np# 创建二维数组x1 = np.arange(12).reshape(3,4)# 转置x1.T&#x27;&#x27;&#x27;输出：array([[ 0, 4, 8], [ 1, 5, 9], [ 2, 6, 10], [ 3, 7, 11]])原数组：array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]])&#x27;&#x27;&#x27; 18、如何连接两个相同维度的数组？numpy的concatenate 函数用于沿指定轴连接相同形状的两个或多个数组。 1234567891011121314151617181920212223import numpy as np# 创建两个二维数组x1 = np.array([[1,2,3],[4,5,6]])x2 = np.array([[7,8,9],[10,11,12]])# 连接,默认沿0轴连接np.concatenate((x1,x2))&#x27;&#x27;&#x27;输出：array([[ 1, 2, 3], [ 4, 5, 6], [ 7, 8, 9], [10, 11, 12]])&#x27;&#x27;&#x27;# 指定沿1轴连接np.concatenate((x1,x2),axis=1)&#x27;&#x27;&#x27;输出：array([[ 1, 2, 3, 7, 8, 9], [ 4, 5, 6, 10, 11, 12]])&#x27;&#x27;&#x27; 19、如何向数组添加值？ numpy的append 函数向数组末尾追加值，可以指定不同的轴。 1234567891011121314151617181920212223242526import numpy as np# 创建一个二维数组x1 = np.array([[1,2,3],[4,5,6]])# 直接向数组末尾添加元素，返回平铺的一维数组np.append(x1,[7,8,9])&#x27;&#x27;&#x27;输出：array([1, 2, 3, 4, 5, 6, 7, 8, 9])&#x27;&#x27;&#x27;# 沿轴 0 添加元素np.append(x1, [[7,8,9]],axis = 0)&#x27;&#x27;&#x27;输出：array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])&#x27;&#x27;&#x27;# 沿轴 1 添加元素np.append(x1, [[5,5,5],[7,8,9]],axis = 1)&#x27;&#x27;&#x27;输出：array([[1, 2, 3, 5, 5, 5], [4, 5, 6, 7, 8, 9]])&#x27;&#x27;&#x27; numpy的insert 函数可以沿给定轴，在数组中任意位置插入数据。 123456789101112131415161718192021222324252627282930313233import numpy as np# 创建一个二维数组x1 = np.array([[1,2,3],[4,5,6],[7,8,9]])# 直接在指定位置插入元素，返回平铺的一维数组np.insert(x1,2,[0,0,0])&#x27;&#x27;&#x27;输出：array([1, 2, 0, 0, 0, 3, 4, 5, 6, 7, 8, 9])原数组：array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])&#x27;&#x27;&#x27;# 指定位置，沿轴 0 插入元素np.insert(x1,1,[0,0,0],axis=0)&#x27;&#x27;&#x27;输出：array([[1, 2, 3], [0, 0, 0], [4, 5, 6], [7, 8, 9]])&#x27;&#x27;&#x27;# 指定位置，沿轴 1插入元素np.insert(x1,2,[0,0,0],axis=1)&#x27;&#x27;&#x27;输出：array([[1, 2, 0, 3], [4, 5, 0, 6], [7, 8, 0, 9]])&#x27;&#x27;&#x27; 20、如何对数组进行去重操作？numpy的unique 函数用于去除数组中的重复元素，返回一个新数组。 12345678import numpy as np# 创建一个一维数组x1 = np.array([2,3,5,1,3,8,1,0])np.unique(x1)&#x27;&#x27;&#x27;输出：array([0, 1, 2, 3, 5, 8])&#x27;&#x27;&#x27; unique函数还能返回重复元素的索引、计数等信息，可去查文档自定义参数。 参考资料[1]numpy文档: https://www.numpy.org.cn/ [2]菜鸟教程: https://www.runoob.com/numpy/numpy-tutorial.html","tags":[{"name":"Python","slug":"Python","permalink":"http://clarkhedi.github.io/tags/Python/"},{"name":"Numpy","slug":"Numpy","permalink":"http://clarkhedi.github.io/tags/Numpy/"}]},{"title":"TensorFlow Keras 高阶应用","date":"2020-04-09T12:15:32.000Z","path":"2020/04/09/tensorflow-keras-gao-jie-ying-yong/","text":"总体介绍上一讲主要讲解了 TensorFlow 中的一些基本概念与一些低阶 API ，在工业使用时，为了能够快速搭建出模型，人们往往更愿意去选择高阶 API。因此，本次主要讲解 TensorFlow 中常用的高阶 API。 知识点 TensorFlow Keras 简介TensorFlow 中的高阶 API 主要有 Keras 和 Estimators 这两个模块。由于 Keras 入门简单，功能强大，所以本次主要讲解 Keras。 KerasKeras 是一个用于构建和训练深度学习模型的高阶 API。它可用于快速设计原型、高级研究和生产，具有以下三个主要优势： 方便用户使用：Keras 具有针对常见用例做出优化的简单而一致的界面。它可针对用户错误提供切实可行的清晰反馈。 模块化和可组合：将可配置的构造块连接在一起就可以构建 Keras 模型，并且几乎不受限制。 易于扩展：可以编写自定义构造块以表达新的研究创意，并且可以创建新层、损失函数并开发先进的模型。 导入 tf.kerastf.keras 是 TensorFlow 对 Keras API 规范 的实现。这是一个用于构建和训练模型的高阶 API，包含对 TensorFlow 特定功能（例如 Eager Execution、tf.data 管道和 Estimator）的顶级支持。 tf.keras 使 TensorFlow 更易于使用，并且不会牺牲灵活性和性能。 首先，导入 tf.keras 以设置 TensorFlow 程序： 12345import tensorflow as tffrom tensorflow.keras import layersprint(tf.VERSION)print(tf.keras.__version__) tf.keras 可以运行任何与 Keras 兼容的代码，但请注意： 最新版 TensorFlow 中的 tf.keras 版本可能与 PyPI 中的最新 keras 版本不同。请查看 tf.keras.__version__。 保存模型的权重时，tf.keras 默认采用 检查点格式。请传递 save_format=&#39;h5&#39; 以使用 HDF5。 构建简单的模型在 Keras 中，可以通过组合层来构建模型。模型通常是由层构成的图。最常见的模型类型是层的堆叠：tf.keras.Sequential 模型。 现在我们使用 tf.keras.Sequential() 来构建一个简单的全连接网络，代码如下： 123456model = tf.keras.Sequential() # 定义模型# 添加 Dense 层，输入为 100，输出为 64 个单元，激活函数选用 Relu 函数model.add(layers.Dense(64, input_shape=(100,), activation=&#x27;relu&#x27;))model.add(layers.Dense(64, activation=&#x27;relu&#x27;))# 添加 Dense 层，输出为 10 个单元，激活函数选用 softmax 函数model.add(layers.Dense(10, activation=&#x27;softmax&#x27;)) 同通过上面仅 4 行代码，我们已经构建出了一个简单的神经网络模型，下面我们可以通过 summary 方法来查看所构建的模型信息。 1model.summary() 配置层上面主要讲述使用 tf.keras.Sequential() 来构建模型，现在讲解另一种 Keras 常用的构建模型方法： tf.keras.layers，与 tf.keras.Sequential() 方法差不多，这两者都具有一些相同的构造函数参数： activation：设置层的激活函数。此参数由内置函数的名称指定，或指定为可调用对象。默认情况下，系统不会应用任何激活函数。 kernel_initializer 和 bias_initializer：创建层权重的初始化方案。此参数是一个名称或可调用对象，默认为 &quot;Glorot uniform&quot; 初始化器。 kernel_regularizer 和 bias_regularizer：应用层权重的正则化方案，例如 L1 或 L2 正则化。默认情况下，系统不会应用正则化函数。 以下代码使用构造函数参数实例化 tf.keras.layers. Dense 层： 12345678# 创建一个层，输出单元为 64 ，激活函数为 sigmoid 函数layers.Dense(64, activation=&#x27;sigmoid&#x27;)# 创建一个层，使用 L1 正则化layers.Dense(64, kernel_regularizer=tf.keras.regularizers.l1(0.01))# 创建一个层，使用 L2 正则化layers.Dense(64, bias_regularizer=tf.keras.regularizers.l2(0.01))# 创建一个层，偏置参数的初始值设置为 2layers.Dense(64, bias_initializer=tf.keras.initializers.constant(2.0)) 训练和评估上面主要讲述 Keras 两种常用构建神经网络层的方法。两者也可以合起来使用，如下： 123456model = tf.keras.Sequential([ # 添加一个 Dense 层，输出为 64 ，激活函数为 Rule layers.Dense(64, activation=&#x27;relu&#x27;), layers.Dense(64, activation=&#x27;relu&#x27;), # 添加一个 Dense 层，输出为 10 ，激活函数为 softmax layers.Dense(10, activation=&#x27;softmax&#x27;)]) 构建好模型后，通过调用 compile 方法配置该模型的学习流程： 123model.compile(optimizer=tf.train.AdamOptimizer(0.001), loss=&#x27;categorical_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;]) tf.keras.Model.compile 主要含有三个重要参数： optimizer：此对象会指定训练过程。从 tf.train 模块向其传递优化器实例，例如 tf.train.AdamOptimizer、tf.train.RMSPropOptimizer 或 tf.train.GradientDescentOptimizer。 loss：要在优化期间最小化的函数。常见选择包括均方误差 (mse)、categorical_crossentropy 和 binary_crossentropy。损失函数由名称或通过从 tf.keras.losses 模块传递可调用对象来指定。 metrics：用于监控训练。它们是 tf.keras.metrics 模块中的字符串名称或可调用对象。 以下代码展示了配置模型以进行训练的几个示例： 123model.compile(optimizer=tf.train.AdamOptimizer(0.01), # 使用 Adam 优化算法 loss=&#x27;mse&#x27;, # 损失函数选用均方差损失 metrics=[&#x27;mse&#x27;]) # 使用均方差来评估模型 输入 NumPy 数据当构建好模型之后，需要对其进行训练，而训练时需要加载数据。对于小型数据集，可以直接使用 NumPy 数组训练和评估模型。使用 fit 方法来训练模型： 123456import numpy as npdata = np.random.random((1000, 32))labels = np.random.random((1000, 10))model.fit(data, labels, epochs=10, batch_size=32) 在训练时输出的日志中，sample - loss: 11.6251 表示损失值，categorical_accuracy: 0.1100 表示正确率，在该例子中，使用的数据集是随机产生的，因此准确率并不高。 tf.keras.Model.fit 采用三个重要参数： epochs：以周期为单位进行训练。一个周期是对整个输入数据的一次迭代（以较小的批次完成迭代）。 batch_size：当传递 NumPy 数据时，模型将数据分成较小的批次，并在训练期间迭代这些批次。此整数指定每个批次的大小。请注意，如果样本总数不能被批次大小整除，则最后一个批次可能更小。 validation_data：在对模型进行原型设计时，你需要轻松监控该模型在某些验证数据上达到的效果。传递此参数（输入和标签元组）可以让该模型在每个周期结束时以推理模式显示所传递数据的损失和指标。即我们通常所说的验证集或测试集。 下面是使用 validation_data 的示例： 12345678910import numpy as npdata = np.random.random((1000, 32))labels = np.random.random((1000, 10))val_data = np.random.random((100, 32))val_labels = np.random.random((100, 10))model.fit(data, labels, epochs=10, batch_size=32, validation_data=(val_data, val_labels)) 输入 tf.data 数据集传入数据集还有另一种方法，就是使用 TensorFlow 提供的接口 tf.data。 其提供的 Datasets API 可扩展为大型数据集或多设备训练。将 tf.data.Dataset 实例传递到 fit 方法： 1234567# 加载数据集dataset = tf.data.Dataset.from_tensor_slices((data, labels))dataset = dataset.batch(32)dataset = dataset.repeat()# 训练模型model.fit(dataset, epochs=10, steps_per_epoch=30) 在上方代码中，fit 方法使用了 steps_per_epoch 参数表示模型在进入下一个周期之前运行的训练步数。由于 Dataset 会生成批次数据，因此该代码段不需要设置 batch_size。 同样该方法传入的数据集也可用于验证： 123456789dataset = tf.data.Dataset.from_tensor_slices((data, labels))dataset = dataset.batch(32).repeat()val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))val_dataset = val_dataset.batch(32).repeat()model.fit(dataset, epochs=10, steps_per_epoch=30, validation_data=val_dataset, validation_steps=3) 评估和预测当模型训练完，我们需要对所训练完的模型进行评估时，可以使用 tf.keras.Model.evaluate 和 tf.keras.Model.predict 方法，并且这两种方法同样可以使用 NumPy 数据和 tf.data.Dataset 提供的数据。 要评估所提供数据的推理模式损失和指标，可以运行以下代码： 1234data = np.random.random((1000, 32))labels = np.random.random((1000, 10))model.evaluate(data, labels, batch_size=32) 同样的方法，采用 tf.data.Dataset 提供的数据。 1model.evaluate(dataset, steps=30) 要在所提供数据（采用 NumPy 数组形式）的推理中预测最后一层的输出，可以运行以下代码： 12result = model.predict(data, batch_size=32)result.shape 构建高级模型上面所讲述的 tf.keras.Sequential 模型是层的简单堆叠，这种方法构建模型简单，但往往无法构建出复杂模型。在 Keras 中，通常使用 Keras 函数式 API 来构建复杂的模型，例如： 多输入模型， 多输出模型， 具有共享层的模型（同一层被调用多次）， 具有非序列数据流的模型（例如，剩余连接）。 使用函数式 API 构建的模型具有以下特征： 层实例可调用并返回张量。 输入张量和输出张量用于定义 tf.keras.Model 实例。 此模型的训练方式和 Sequential 模型一样。 以下示例使用函数式 API 构建一个简单的全连接网络： 1234567inputs = tf.keras.Input(shape=(32,)) # 创建一个输入层# 创建 Dense 层x = layers.Dense(64, activation=&#x27;relu&#x27;)(inputs)x = layers.Dense(64, activation=&#x27;relu&#x27;)(x)predictions = layers.Dense(10, activation=&#x27;softmax&#x27;)(x)predictions 在给定输入和输出的情况下实例化模型。 12345678910# 实例化模型model = tf.keras.Model(inputs=inputs, outputs=predictions)# 编译模型，指的优化算法，损失函数等相关的参数model.compile(optimizer=tf.train.RMSPropOptimizer(0.001), loss=&#x27;categorical_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;])# 训练模型model.fit(data, labels, batch_size=32, epochs=5) 模型子类化我们也可以通过对 tf.keras.Model 进行子类化并定义前向传播来构建完全可自定义的模型。这种方法需要在 __init__ 方法中创建层并将它们设置为类实例的属性。此外，需要在 call 方法中定义前向传播。 在启用 Eager Execution 时，模型子类化特别有用，因为可以命令式地编写前向传播。 虽然模型子类化较为灵活，但代价是复杂性更高且用户出错率更高。如果可能，请首选函数式 API。 以下示例展示了使用自定义前向传播进行子类化的 tf.keras.Model： 12345678910111213141516171819class MyModel(tf.keras.Model): def __init__(self, num_classes=10): super(MyModel, self).__init__(name=&#x27;my_model&#x27;) self.num_classes = num_classes # 定义所想要构建模型的层 self.dense_1 = layers.Dense(32, activation=&#x27;relu&#x27;) self.dense_2 = layers.Dense(num_classes, activation=&#x27;sigmoid&#x27;) def call(self, inputs): # 定义模型的前向传播 x = self.dense_1(inputs) return self.dense_2(x) def compute_output_shape(self, input_shape): # 计算模型的输出 shape = tf.TensorShape(input_shape).as_list() shape[-1] = self.num_classes return tf.TensorShape(shape) 实例化新模型类： 123456789model = MyModel(num_classes=10) # 模型实例化# 编译模型，指的优化算法，损失函数等相关的参数model.compile(optimizer=tf.train.RMSPropOptimizer(0.001), loss=&#x27;categorical_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;])# 训练模型model.fit(data, labels, batch_size=32, epochs=5) 自定义层在我们构建模型时，有时候 Keras 提供的接口并不能满足我们的要求。因此可以通过对 tf.keras.layers.Layer 进行子类化并实现以下方法来创建自定义层： build：创建层的权重。使用 add_weight 方法添加权重。 call：定义前向传播。 compute_output_shape：指定在给定输入形状的情况下如何计算层的输出形状。 或者，可以通过实现 get_config 方法和 from_config 类方法序列化层。 下面是一个使用核矩阵实现输入 matmul 的自定义层示例： 1234567891011121314151617181920212223242526272829303132class MyLayer(layers.Layer): def __init__(self, output_dim, **kwargs): self.output_dim = output_dim super(MyLayer, self).__init__(**kwargs) def build(self, input_shape): shape = tf.TensorShape((input_shape[1], self.output_dim)) # 创建一个层所使用的权重值. self.kernel = self.add_weight(name=&#x27;kernel&#x27;, shape=shape, initializer=&#x27;uniform&#x27;, trainable=True) # 需要对其进行声明 super(MyLayer, self).build(input_shape) def call(self, inputs): return tf.matmul(inputs, self.kernel) def compute_output_shape(self, input_shape): shape = tf.TensorShape(input_shape).as_list() shape[-1] = self.output_dim return tf.TensorShape(shape) def get_config(self): base_config = super(MyLayer, self).get_config() base_config[&#x27;output_dim&#x27;] = self.output_dim return base_config @classmethod def from_config(cls, config): return cls(**config) 使用自定义层创建模型： 1234567891011model = tf.keras.Sequential([ MyLayer(10), layers.Activation(&#x27;softmax&#x27;)])# 编译模型，指定优化算法等参数model.compile(optimizer=tf.train.RMSPropOptimizer(0.001), loss=&#x27;categorical_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;])# 训练模型model.fit(data, labels, batch_size=32, epochs=5) 回调回调是传递给模型的对象，用于在训练期间记录模型日志或防止模型出现意外等。你可以编写自定义回调，也可以使用包含以下方法的内置 tf.keras.callbacks： tf.keras.callbacks.ModelCheckpoint：定期保存模型的检查点。 tf.keras.callbacks.LearningRateScheduler：动态更改学习速率。 tf.keras.callbacks.EarlyStopping：在验证效果不再改进时中断训练。 tf.keras.callbacks.TensorBoard：使用 TensorBoard 监控模型的行为。 要使用 tf.keras.callbacks.Callback，请将其传递给模型的 fit 方法： 12345678callbacks = [ # 如果在 2 epochs 内损失值没有变化，则中断训练 tf.keras.callbacks.EarlyStopping(patience=2, monitor=&#x27;val_loss&#x27;), # 记录日志 tf.keras.callbacks.TensorBoard(log_dir=&#x27;./logs&#x27;)]model.fit(data, labels, batch_size=32, epochs=5, callbacks=callbacks, validation_data=(val_data, val_labels)) 保存和恢复在 Keras 中，可以使用 tf.keras.Model.save_weights 保存并加载模型的权重： 12345678910111213model = tf.keras.Sequential([ layers.Dense(64, activation=&#x27;relu&#x27;), layers.Dense(10, activation=&#x27;softmax&#x27;)])model.compile(optimizer=tf.train.AdamOptimizer(0.001), loss=&#x27;categorical_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;])# 保存模型model.save_weights(&#x27;./weights/my_model&#x27;)# 加载模型model.load_weights(&#x27;./weights/my_model&#x27;) 默认情况下，会以 TensorFlow 检查点 文件格式保存模型的权重。权重也可以另存为 Keras HDF5 格式（Keras 多后端实现的默认格式）： 12345# S 保存为 HDF5 文件model.save_weights(&#x27;my_model.h5&#x27;, save_format=&#x27;h5&#x27;)# 加载模型model.load_weights(&#x27;my_model.h5&#x27;) 保存配置可以保存模型的配置，此操作会对模型架构（不含任何权重）进行序列化。即使没有定义原始模型的代码，保存的配置也可以重新创建并初始化相同的模型。Keras 支持 JSON 和 YAML 序列化格式： 123# 序列化模型为 json 形式json_string = model.to_json()json_string 输出为: 1&#39;&#123;&quot;class_name&quot;: &quot;Sequential&quot;, &quot;config&quot;: &#123;&quot;name&quot;: &quot;sequential_6&quot;, &quot;layers&quot;: [&#123;&quot;class_name&quot;: &quot;Dense&quot;, &quot;config&quot;: &#123;&quot;name&quot;: &quot;dense_24&quot;, &quot;trainable&quot;: true, &quot;dtype&quot;: null, &quot;units&quot;: 64, &quot;activation&quot;: &quot;relu&quot;, &quot;use_bias&quot;: true, &quot;kernel_initializer&quot;: &#123;&quot;class_name&quot;: &quot;GlorotUniform&quot;, &quot;config&quot;: &#123;&quot;seed&quot;: null, &quot;dtype&quot;: &quot;float32&quot;&#125;&#125;, &quot;bias_initializer&quot;: &#123;&quot;class_name&quot;: &quot;Zeros&quot;, &quot;config&quot;: &#123;&quot;dtype&quot;: &quot;float32&quot;&#125;&#125;, &quot;kernel_regularizer&quot;: null, &quot;bias_regularizer&quot;: null, &quot;activity_regularizer&quot;: null, &quot;kernel_constraint&quot;: null, &quot;bias_constraint&quot;: null&#125;&#125;, &#123;&quot;class_name&quot;: &quot;Dense&quot;, &quot;config&quot;: &#123;&quot;name&quot;: &quot;dense_25&quot;, &quot;trainable&quot;: true, &quot;dtype&quot;: null, &quot;units&quot;: 10, &quot;activation&quot;: &quot;softmax&quot;, &quot;use_bias&quot;: true, &quot;kernel_initializer&quot;: &#123;&quot;class_name&quot;: &quot;GlorotUniform&quot;, &quot;config&quot;: &#123;&quot;seed&quot;: null, &quot;dtype&quot;: &quot;float32&quot;&#125;&#125;, &quot;bias_initializer&quot;: &#123;&quot;class_name&quot;: &quot;Zeros&quot;, &quot;config&quot;: &#123;&quot;dtype&quot;: &quot;float32&quot;&#125;&#125;, &quot;kernel_regularizer&quot;: null, &quot;bias_regularizer&quot;: null, &quot;activity_regularizer&quot;: null, &quot;kernel_constraint&quot;: null, &quot;bias_constraint&quot;: null&#125;&#125;]&#125;, &quot;keras_version&quot;: &quot;2.1.6-tf&quot;, &quot;backend&quot;: &quot;tensorflow&quot;&#125;&#39; 123import jsonimport pprintpprint.pprint(json.loads(json_string)) 输出为: 1234567891011121314151617181920212223242526272829303132333435363738&#123;&#39;backend&#39;: &#39;tensorflow&#39;, &#39;class_name&#39;: &#39;Sequential&#39;, &#39;config&#39;: &#123;&#39;layers&#39;: [&#123;&#39;class_name&#39;: &#39;Dense&#39;, &#39;config&#39;: &#123;&#39;activation&#39;: &#39;relu&#39;, &#39;activity_regularizer&#39;: None, &#39;bias_constraint&#39;: None, &#39;bias_initializer&#39;: &#123;&#39;class_name&#39;: &#39;Zeros&#39;, &#39;config&#39;: &#123;&#39;dtype&#39;: &#39;float32&#39;&#125;&#125;, &#39;bias_regularizer&#39;: None, &#39;dtype&#39;: None, &#39;kernel_constraint&#39;: None, &#39;kernel_initializer&#39;: &#123;&#39;class_name&#39;: &#39;GlorotUniform&#39;, &#39;config&#39;: &#123;&#39;dtype&#39;: &#39;float32&#39;, &#39;seed&#39;: None&#125;&#125;, &#39;kernel_regularizer&#39;: None, &#39;name&#39;: &#39;dense_24&#39;, &#39;trainable&#39;: True, &#39;units&#39;: 64, &#39;use_bias&#39;: True&#125;&#125;, &#123;&#39;class_name&#39;: &#39;Dense&#39;, &#39;config&#39;: &#123;&#39;activation&#39;: &#39;softmax&#39;, &#39;activity_regularizer&#39;: None, &#39;bias_constraint&#39;: None, &#39;bias_initializer&#39;: &#123;&#39;class_name&#39;: &#39;Zeros&#39;, &#39;config&#39;: &#123;&#39;dtype&#39;: &#39;float32&#39;&#125;&#125;, &#39;bias_regularizer&#39;: None, &#39;dtype&#39;: None, &#39;kernel_constraint&#39;: None, &#39;kernel_initializer&#39;: &#123;&#39;class_name&#39;: &#39;GlorotUniform&#39;, &#39;config&#39;: &#123;&#39;dtype&#39;: &#39;float32&#39;, &#39;seed&#39;: None&#125;&#125;, &#39;kernel_regularizer&#39;: None, &#39;name&#39;: &#39;dense_25&#39;, &#39;trainable&#39;: True, &#39;units&#39;: 10, &#39;use_bias&#39;: True&#125;&#125;], &#39;name&#39;: &#39;sequential_6&#39;&#125;, &#39;keras_version&#39;: &#39;2.1.6-tf&#39;&#125; 从 json 重新创建模型（刚刚初始化）。 12# 加载模型fresh_model = tf.keras.models.model_from_json(json_string) 将模型序列化为 YAML 格式。 12yaml_string = model.to_yaml()print(yaml_string) 输出为: 1234567891011121314151617181920212223242526272829303132333435363738394041424344backend: tensorflowclass_name: Sequentialconfig: layers: - class_name: Dense config: activation: relu activity_regularizer: null bias_constraint: null bias_initializer: class_name: Zeros config: &#123;dtype: float32&#125; bias_regularizer: null dtype: null kernel_constraint: null kernel_initializer: class_name: GlorotUniform config: &#123;dtype: float32, seed: null&#125; kernel_regularizer: null name: dense_24 trainable: true units: 64 use_bias: true - class_name: Dense config: activation: softmax activity_regularizer: null bias_constraint: null bias_initializer: class_name: Zeros config: &#123;dtype: float32&#125; bias_regularizer: null dtype: null kernel_constraint: null kernel_initializer: class_name: GlorotUniform config: &#123;dtype: float32, seed: null&#125; kernel_regularizer: null name: dense_25 trainable: true units: 10 use_bias: true name: sequential_6keras_version: 2.1.6-tf 从 YAML 重新创建模型 12fresh_model = tf.keras.models.model_from_yaml(yaml_string)fresh_model 整个模型整个模型可以保存到一个文件中，其中包含权重值、模型配置乃至优化器配置。这样就可以对模型设置检查点并稍后从完全相同的状态继续训练，而无需访问原始代码。 1234567891011121314151617# 创建一个模型model = tf.keras.Sequential([ layers.Dense(10, activation=&#x27;softmax&#x27;, input_shape=(32,)), layers.Dense(10, activation=&#x27;softmax&#x27;)])model.compile(optimizer=&#x27;rmsprop&#x27;, loss=&#x27;categorical_crossentropy&#x27;, metrics=[&#x27;accuracy&#x27;])model.fit(data, labels, batch_size=32, epochs=5)# 保存整个模型为 HDF5 文件model.save(&#x27;my_model.h5&#x27;)# 加载整个模型model = tf.keras.models.load_model(&#x27;my_model.h5&#x27;)model 总结本次主要讲解了 TensorFlow 常用的高阶 API，并对其集成的 Keras 进行详细的讲解。相对于低阶 API ，高阶 API 往往会更加简单，因为其只要定义层即可。这也是 TensorFlow 官方极力推荐广大开发者使用高阶 API 的原因。","tags":[{"name":"Python","slug":"Python","permalink":"http://clarkhedi.github.io/tags/Python/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://clarkhedi.github.io/tags/TensorFlow/"}]},{"title":"TensorFlow 基本概念及构建","date":"2020-04-09T12:00:43.000Z","path":"2020/04/09/tensorflow-ji-ben-gai-nian-ji-gou-jian/","text":"总体介绍目前深度学习异常的火热，而深度学习模型的搭建需要依赖于深度学习框架，TensorFlow 就是其中的一种非常流行的深度学习框架。因此，想要学习深度学习算法，学习 TensorFlow 十分必要。而本次主要介绍 TensorFlow 的基本概念以及基本使用方法。 知识点 TensorFlow 张量 Tensor 计算图 Graph 线性回归实现 模型保存 Save TensorFlow 介绍TensorFlow 是目前最强大的深度学习框架之一，由 Google 团队主导开发，并在 2015 年进行开源。因此，TensorFlow 拥有非常活跃的社区。这意味着当你在使用 TensorFlow 遇到问题时，往往在许多搜索引擎中搜索相关的报错信息就能找到答案。 经过几年的不断优化和发展，TensorFlow 目前的代码量大约在 40 万行左右。因此，本系列不可能涵盖 TensorFlow 所有的内容，仅介绍其常用的操作或 API，具体如下： 简介 - 介绍了如何使用高阶 API 之外的低阶 TensorFlow API 的基础知识。 张量 - 介绍了如何创建、操作和访问张量（TensorFlow 中的基本对象）。 变量 - 详细介绍了如何在程序中表示共享持久状态。 图和会话 - 介绍了以下内容： 数据流图：这是 TensorFlow 将计算表示为操作之间的依赖关系的一种表示法。 会话：TensorFlow 跨一个或多个本地或远程设备运行数据流图的机制。如果您使用低阶 TensorFlow API 编程，请务必阅读并理解本单元的内容。如果你使用高阶 TensorFlow API（例如 Estimator 或 Keras）编程，则高阶 API 会为你创建和管理图和会话，但是理解图和会话依然对你有所帮助。 保存和恢复 - 介绍了如何保存和恢复变量及模型。 虽然使用 TensorFlow 的高阶 API 来搭建模型会更简单。但是由于其是低阶 API 的高层封装，所以往往更难调试。所以本次实验主要讲解低阶 API。 数据流图与其他科学计算库不一样，在 TensorFlow 中，每个运算操作都可以看做是一个计算图，如下图所示。 TensorFlow 使用数据流图将计算表示为独立的指令之间的依赖关系。这可生成低级别的编程模型，在该模型中，首先定义数据流图，然后创建 TensorFlow 会话，以便在一组本地和远程设备上运行所构建计算图的各个部分。 数据流 是一种用于并行计算的常用编程模型。在数据流图中，节点表示计算单元，边表示计算使用或产生的数据。例如，在 TensorFlow 图中，tf.matmul 操作对应于单个节点，该节点具有两个传入边（要相乘的矩阵）和一个传出边（乘法结果）。 在执行程序时，数据流可以为 TensorFlow 提供多项优势： 并行处理。 通过使用明确的边来表示操作之间的依赖关系，系统可以轻松识别能够并行执行的操作。 分布式执行。 通过使用明确的边来表示操作之间流动的值，TensorFlow 可以将程序划分到连接至不同机器的多台设备上（CPU、GPU 和 TPU）。TensorFlow 将在这些设备之间进行必要的通信和协调。 编译。 TensorFlow 的 XLA 编译器 可以使用数据流图中的信息生成更快的代码，例如将相邻的操作融合到一起。 可移植性。 数据流图是一种不依赖于语言的模型代码表示法。你可以使用 Python 构建数据流图，将其存储在 SavedModel 中，并使用 C++ 程序进行恢复，从而实现低延迟的推理。 在 TensorFlow 中，数据流图是一个 tf.Graph 对象，tf.Graph 包含两类相关信息： 图结构： 图的节点和边，表示各个操作组合在一起的方式，但不规定它们的使用方式。图结构与汇编代码类似：检查图结构可以传达一些有用的信息，但它不包含源代码传达的所有实用上下文信息。 图集合： TensorFlow 提供了一种在 tf.Graph 中存储元数据集合的通用机制。tf.add_to_collection 函数允许将对象列表与一个键关联（其中 tf.GraphKeys 定义了部分标准键），tf.get_collection 允许查询与某个键关联的所有对象。TensorFlow 库的许多部分会使用此设施资源：例如，当创建 tf.Variable 时，系统会默认将其添加到表示 “全局变量” 和 “可训练变量” 的集合中。当后续创建 tf.train.Saver 或 tf.train.Optimizer 时，这些集合中的变量将用作默认参数。 构建 tf.Graph大多数 TensorFlow 程序都以数据流图构建阶段开始。在 TensorFlow 中，我们可以使用 tf.Graph 来创建一个图。例如下面代码： 1234567import tensorflow as tfg_1 = tf.Graph() # 定义一个图with g_1.as_default(): # 在 g_1 图下创建节点 a = tf.constant(3.0, name=&#x27;a&#x27;) # 创建一个常量 a b = tf.constant(4.0, name=&#x27;b&#x27;) # 创建一个常量 b c = a + b # 创建一个操作 a + b 在上面的代码中，我们创建了一个图 g_1 ，并在该图中添加两个节点 a 和 b。然后对两者进行相加得到 c。如果使用 TensorBoard 可以将上面所构建的图打印出来，如下图所示.因 TensorBoard 在没有展示代码，如果你感兴趣可以在现在运行 官方文档 提供的案例。 现在我们打印出这三个节点。 123print(a)print(b)print(c) 从上面的输出结果可以看到，我们的输出结果为三个形如 Tensor(&quot;a:0&quot;, shape=(), dtype=float32) 的 Tensor 对象，其中 &quot;a:0&quot; 表示节点名称，shape=() 表示节点的形状，dtype=float32 为节点的数据类型。 一般情况下 TensorFlow 提供了一个默认图，而且大多数程序仅依赖于默认图。所以如果你的代码中只创建一个运算图，则不需要自己手动创建。 命名空间tf.Graph 对象会定义一个命名空间（为其包含的 tf.Operation 对象）。TensorFlow 会自动为数据流图中的每个指令选择一个唯一名称，也可以指定描述性名称，使程序阅读和调试起来更轻松。TensorFlow API 提供两种方法来覆盖操作名称： 如果 API 函数会创建新的 tf.Operation 或返回新的 tf.Tensor，则会接受可选 name 参数。例如，tf.constant(42.0, name=&quot;answer&quot;) 会创建一个新的 tf.Operation（名为 &quot;answer&quot;）并返回一个 tf.Tensor（名为 &quot;answer:0&quot;）。如果默认图已包含名为 &quot;answer&quot; 的操作，则 TensorFlow 会在名称上附加 &quot;_1&quot;、&quot;_2&quot; 等字符，以便让名称具有唯一性。 借助 tf.name_scope 函数，可以向在特定上下文中创建的所有操作添加名称作用域前缀。当前名称作用域前缀是一个用 &quot;/&quot; 分隔的名称列表，其中包含所有活跃 tf.name_scope 上下文管理器的名称。如果某个名称作用域已在当前上下文中被占用，TensorFlow 将在该作用域上附加 &quot;_1&quot;、&quot;_2&quot; 等字符。例如： 1234567891011121314e_0 = tf.constant(0, name=&quot;e&quot;)print(e_0)e_1 = tf.constant(2, name=&quot;e&quot;)print(e_1)with tf.name_scope(&quot;outer&quot;): # 在命名空间 outer 下创建常量 e_2 = tf.constant(2, name=&quot;e&quot;) print(e_2) with tf.name_scope(&quot;inner&quot;): # 在命名空间 inter 下创建常量 e_3 = tf.constant(3, name=&quot;e&quot;) print(e_3) e_4 = tf.constant(4, name=&quot;e&quot;) print(e_4) with tf.name_scope(&quot;inner&quot;): e_5 = tf.constant(5, name=&quot;e&quot;) 会话我们现在再来看上面所述的加法运算例子。 123456a = tf.constant(3.0, name=&#x27;a&#x27;) # 创建一个常量 ab = tf.constant(4.0, name=&#x27;b&#x27;) # 创建一个常量 bc = a + b # 创建一个操作 a+bprint(a)print(b)print(c) 上面我们说到 a，b，c 只是我们在数据流图中所构建的节点而已，所以我们直接对其进行打印，并不能直接打印出其值。在 TensorFlow 中，需要创建会话才能进行运算，并打印出结果。在TensorFlow 中，创建会话的语句为 tf.Session ，使用会话执行数据流图的计算为 tf.Session.run 。下面我们创建一个会话。 1234sess = tf.Session()print(sess.run(a))print(sess.run(b))print(sess.run(c)) 由上面的结果可知，输出的结果与我们预想的一致。由于 tf.Session 拥有物理资源（例如 GPU 和网络连接），因此通常（在 with 代码块中）用作上下文管理器，并在你退出代码块时自动关闭会话。当然，你也可以在不使用 with 代码块的情况下创建会话，但应在完成会话时明确调用 tf.Session.close 以便释放资源。 1234with tf.Session() as sess: print(sess.run(a)) print(sess.run(b)) print(sess.run(c)) 在实际使用中，tf.Session.run 也可以选择接受 feed 字典，该字典是从 tf.Tensor 对象（通常是 tf.placeholder 张量）到在执行时会替换这些张量的值，通常是 Python 标量、列表或 NumPy 数组的映射。例如： 123456x = tf.placeholder(tf.int32, shape=[3]) # 创建一个占位符y = tf.square(x) # 创建一个操作，对 x 取平方得到 ywith tf.Session() as sess: feed = &#123;x: [1, 2, 3]&#125; # 运行时，给占位符喂的值 print(sess.run(y, feed_dict=feed)) print(sess.run(y, &#123;x: [4, 5, 6]&#125;)) 这里需要注意的是使用 x = tf.placeholder(tf.int32, shape=[ 3]) 创建占位符表示的是在创建计算图时，x 没有被赋予实际的值，而在 tf.Session.close 运行计算图时需要对其传入数据，传入数据的方法采用上面所述的字典形式。 张量 Tensor在 TensorFlow 中，其基本的数据结构是张量（Tensor），其是对矢量和矩阵向潜在的更高维度的泛化。TensorFlow 在内部将张量表示为基本数据类型的 n 维数组，即我们通常所说的多维数组。 在 TensorFlow 中，张量被操作和传递的主要对象是 tf.Tensor，其具有以下属性： 数据类型（dtype）：指的是张量的数据类型，例如 float32、int32 或 string等； 形状（shape）：指的是张量的维度以及每个维度的大小，例如三维的张量：(4,2,6)。 名字（name）：指的是张量在计算图中的命名。 在 TensorFlow 中常用的主要有四种类型的张量，分别如下： tf.Variable 变量，其值可以在训练中被改变 tf.constant常量，其值可以在训练中不可改变 tf.placeholder占位符常量，在运行会话时，其值需要给定 tf.SparseTensor常量，稀疏张量 上面所列的四种类型的张量中，只有 tf.Variable 是可变张量，其他张量均不可改变。 张量的秩tf.Tensor 对象的阶是它本身的维数。阶的同义词包括：秩、等级或 n 维。请注意，TensorFlow 中的阶与数学中矩阵的阶并不是同一个概念。如下表所示，TensorFlow 中的每个阶都对应一个不同的数学实例： 阶 数学实例 0 标量（只有大小） 1 矢量（大小和方向） 2 矩阵（数据表） 3 3 阶张量（数据立体） n n 阶张量（自行想象） 以下演示了创建 0 阶变量的过程： 12mammal = tf.Variable(&quot;Elephant&quot;, tf.string)mammal 输出为： 1&lt;tf.Variable &#39;Variable:0&#39; shape&#x3D;() dtype&#x3D;string_ref&gt; 要创建 1 阶 tf.Tensor 对象，可以传递一个项目列表作为初始值。例如： 12cool_numbers = tf.Variable([3.14159, 2.71828], tf.float32)cool_numbers 输出为： 1&lt;tf.Variable &#39;Variable_1:0&#39; shape&#x3D;(2,) dtype&#x3D;float32_ref&gt; 2 阶 tf.Tensor 对象至少包含一行和一列： 12squarish_squares = tf.Variable([[4, 9], [16, 25]], tf.int32)squarish_squares 输出为： 1&lt;tf.Variable &#39;Variable_2:0&#39; shape&#x3D;(2, 2) dtype&#x3D;int32_ref&gt; 同样，更高阶的张量由一个 n 维数组组成。例如，在图像处理过程中，会使用许多 4 阶张量，维度对应批次大小、图像宽度、图像高度和颜色通道。 12my_image = tf.zeros([10, 299, 299, 3])my_image 输出为： 1&lt;tf.Tensor &#39;zeros:0&#39; shape&#x3D;(10, 299, 299, 3) dtype&#x3D;float32&gt; 要确定 tf.Tensor 对象的阶，需调用 tf.rank 方法。例如: 12r = tf.rank(my_image)r 输出为： 1&lt;tf.Tensor &#39;Rank:0&#39; shape&#x3D;() dtype&#x3D;int32&gt; 同样使用会话运行 r 才能得到其值。 12with tf.Session() as sess: print(sess.run(r)) 张量的切片由于 tf.Tensor 是 n 维单元数组，因此要访问 tf.Tensor 中的某一单元或元素，需要指定 n 个索引，这与 NumPy 是一致的。对于 2 阶 tf.Tensor，传递两个数字会如预期般返回一个标量： 1234my_matrix = tf.constant([[4, 9], [16, 25]], tf.int32)my_scalar = my_matrix[1, 0]with tf.Session() as sess: print(sess.run(my_scalar)) 从上面运行的结果可以知道，TensorFlow 中张量的切片与 NumPy 中数组的类似。只不过在 TensorFlow 中，任何运算都会看成是一个计算图，所以需要建立会话运行计算图，从而得到计算结果。 张量的形状张量的形状是每个维度中元素的数量。TensorFlow 在图的构建过程中自动推理形状。这些推理的形状可能具有已知或未知的阶。如果阶已知，则每个维度的大小可能已知或未知。 TensorFlow 文件编制中通过三种符号约定来描述张量维度：阶，形状和维数。下表阐述了三者如何相互关联： 阶 形状 维数 示例 0 [] 0-D 0 维张量。标量。 1 [D0] 1-D 形状为 [5] 的 1 维张量。 2 [D0, D1] 2-D 形状为 [3, 4] 的 2 维张量。 3 [D0, D1, D2] 3-D 形状为 [1, 4, 3] 的 3 维张量。 n [D0, D1, … Dn-1] n 维 形状为 [D0, D1, … Dn-1] 的张量。 可以通过两种方法获取 tf.Tensor 的形状。在构建图的时候，询问有关张量形状的已知信息通常很有帮助。可以通过查看 shape 属性（属于 tf.Tensor 对象）获取这些信息。该方法会返回一个 TensorShape 对象，这样可以方便地表示部分指定的形状，因为在构建图的时候，并不是所有形状都完全已知。 也可以获取一个将在运行时表示另一个 tf.Tensor 的完全指定形状的 tf.Tensor。为此，可以调用 tf.shape 操作。如此一来，可以构建一个图，通过构建其他取决于输入 tf.Tensor 的动态形状的张量来控制张量的形状。例如，以下代码展示了如何创建大小与给定矩阵中的列数相同的零矢量： 123456my_matrix = tf.constant([[4, 9], [16, 25]], tf.int32) # 创建一个常量print(my_matrix)zeros = tf.zeros(my_matrix.shape[0]) # 创建一个全为 0 的常量print(zeros)with tf.Session() as sess: print(sess.run(zeros)) # 打印 zeros 矩阵 张量的元素数量是其所有形状大小的乘积。由于通常有许多不同的形状具有相同数量的元素，因此如果能够改变 tf.Tensor 的形状并使其元素固定不变通常会很方便。为此，可以使用 tf.reshape。以下示例演示如何重构张量： 1234567891011121314151617rank_three_tensor = tf.ones([3, 4, 5]) # 创建一个全为 1 的矩阵常量print(rank_three_tensor)matrix = tf.reshape(rank_three_tensor, [6, 10]) # 改变形状print(matrix)matrixB = tf.reshape(matrix, [3, -1]) # -1 表示系统自行判断大小print(matrixB)matrixAlt = tf.reshape(matrixB, [4, 3, -1])print(matrixAlt)yet_another = tf.reshape(matrixAlt, [3, 2, -1])print(yet_another)&#x27;&#x27;&#x27;输出：Tensor(&quot;ones:0&quot;, shape=(3, 4, 5), dtype=float32)Tensor(&quot;Reshape:0&quot;, shape=(6, 10), dtype=float32)Tensor(&quot;Reshape_1:0&quot;, shape=(3, 20), dtype=float32)Tensor(&quot;Reshape_2:0&quot;, shape=(4, 3, 5), dtype=float32)Tensor(&quot;Reshape_3:0&quot;, shape=(3, 2, 10), dtype=float32)&#x27;&#x27;&#x27; 张量的数据类型除维度外，张量还具有数据类型。如需数据类型的完整列表，请参阅 tf.DType 页面。一个 tf.Tensor 只能有一种数据类型。但是，可以将 tf.Tensor 从一种数据类型转型为另一种，这需要通过 tf.cast 函数来执行，例如下面例子： 12345678list0 = tf.constant([1, 2, 3], dtype=tf.int32)print(list0)float_tensor = tf.cast(list0, dtype=tf.float32)print(float_tensor)&#x27;&#x27;&#x27;输出：Tensor(&quot;Const_9:0&quot;, shape=(3,), dtype=int32)Tensor(&quot;Cast:0&quot;, shape=(3,), dtype=float32)&#x27;&#x27;&#x27; 要检查 tf.Tensor 的数据类型，可以使用 Tensor.dtype 属性。用 Python 对象创建 tf.Tensor 时，可以选择指定数据类型。如果不指定数据类型，TensorFlow 会自动选择一个合适的数据类型。TensorFlow 会将 Python 整数转型为 tf.int32，并将 Python 浮点数转型为 tf.float32。此外，TensorFlow 使用 Numpy 在转换至数组时使用的相同规则。 数据集占位符适用于简单的实验，而 数据集 是将数据流传输到模型的首选方法。要从数据集中获取可运行的 tf.Tensor，必须先将其转换成 tf.data.Iterator，然后调用迭代器的 get_next 方法。创建迭代器的最简单的方式是采用 make_one_shot_iterator 方法。例如，在下面的代码中，next_item 张量将在每次 run 调用时从 my_data 阵列返回一行： 12345678my_data = [ # 初始化一个二维数组 [0, 1, ], [2, 3, ], [4, 5, ], [6, 7, ],]slices = tf.data.Dataset.from_tensor_slices(my_data) # 构建数据集next_item = slices.make_one_shot_iterator().get_next() # 定义一个批次取的迭代器 到达数据流末端时，Dataset 会抛出 OutOfRangeError。例如，下面的代码会一直读取 next_item，直到没有数据可读： 123456with tf.Session() as sess: while True: try: # 尝试去取数据 print(sess.run(next_item)) except tf.errors.OutOfRangeError: # 取完时报错，结束运行 break 如果 Dataset 依赖于有状态操作，即每个批次处理都依赖之前的批次数据或者中间结果来计算当前批次的数据。因此，需要在使用迭代器之前先初始化它，如下所示： 123456789101112r = tf.random_normal([10, 3])dataset = tf.data.Dataset.from_tensor_slices(r)iterator = dataset.make_initializable_iterator()next_row = iterator.get_next()with tf.Session() as sess: sess.run(iterator.initializer) # 初始化迭代器 while True: try: # 尝试去取数据 print(sess.run(next_row)) except tf.errors.OutOfRangeError: # 取完时报错，结束运行 break 要详细了解数据集和迭代器，请参阅 导入数据。 网络层TensorFlow 主要是用来搭建深度学习模型的，因此其通过各种各样的 层 来创建神经网络的每一层。 层将变量和作用于它们的操作打包在一起。例如， 密集连接层 会对每个输出对应的所有输入执行加权和，并应用 激活函数 （可选）。连接权重和偏差由层对象管理。 创建层下面的代码会创建一个 Dense 层，该层会接受一批输入矢量，并为每个矢量生成一个输出值。要将层应用于输入值，请将该层当做函数来调用。例如： 123x = tf.placeholder(tf.float32, shape=[None, 3]) # 创建一个占位符linear_model = tf.layers.Dense(units=1) # 创建一个 Dense 层y = linear_model(x) # 将 x 输入到 Dense 层，然后得到 y 层会检查其输入数据，以确定其内部变量的大小。因此，必须在这里设置 x 占位符的形状，以便层构建正确大小的权重矩阵。现在已经定义了输出值 y 的计算，在运行计算之前，还需要处理一个细节。 初始化层层包含的变量必须先初始化，然后才能使用。尽管可以单独初始化各个变量，但也可以轻松地初始化一个 TensorFlow 图中的所有变量，如下： 123init = tf.global_variables_initializer() # 定义一个全局初始化操作with tf.Session() as sess: sess.run(init) # 全局初始化操作 执行层我们现在已经完成了层的初始化，可以像处理任何其他张量一样评估 linear_model 的输出张量了。例如，下面的代码： 123with tf.Session() as sess: sess.run(init) print(sess.run(y, &#123;x: [[1, 2, 3], [4, 5, 6]]&#125;)) 层函数的快捷方式对于每个层类（如 tf.layers.Dense)，TensorFlow 还提供了一个快捷函数（如 tf.layers.dense）。两者唯一的区别是快捷函数版本是在单次调用中创建和运行层。例如： 1234567x = tf.placeholder(tf.float32, shape=[None, 3]) # 创建一个占位符 xy = tf.layers.dense(x, units=1) # 创建一个dense层，输入 x 得到 yinit = tf.global_variables_initializer() # 定义一个全局初始化操作with tf.Session() as sess: sess.run(init) print(sess.run(y, &#123;x: [[1, 2, 3], [4, 5, 6]]&#125;)) 尽管这种方法很方便，但无法访问 tf.layers.Layer 对象。这会让自省和调试变得更加困难，并且无法重复使用相应的层。 回归模型现在已经了解 TensorFlow 核心部分的基础知识了，我们来手动训练一个小型回归模型吧。 我们首先来定义一些输入值 x，以及每个输入值对应的真实输出值 y_true： 12x = tf.constant([[1], [2], [3], [4]], dtype=tf.float32)y_true = tf.constant([[0], [-1], [-2], [-3]], dtype=tf.float32) 接下来，建立一个简单的线性模型，其输出值只有 1 个： 12linear_model = tf.layers.Dense(units=1)y_pred = linear_model(x) 你可以如下评估预测值： 1234init = tf.global_variables_initializer()with tf.Session() as sess: sess.run(init) print(sess.run(y_pred)) 该模型尚未接受训练，因此四个 “预测” 值并不理想。因为网络层的权重值是随机初始化的，所以多次运行的输出应该有所不同： 要优化模型，首先需要定义损失函数。我们将使用均方误差，这是回归问题的标准损失。 虽然你可以使用较低级别的数学运算手动定义，但 tf.losses 模块提供了一系列常用的损失函数。你可以使用它来计算均方误差，具体操作如下所示： 1234loss = tf.losses.mean_squared_error(labels=y_true, predictions=y_pred)with tf.Session() as sess: sess.run(init) print(sess.run(loss)) TensorFlow 提供了执行标准优化算法的 优化器 。这些优化器被实现为 tf.train.Optimizer 的子类。它们会逐渐改变每个变量，以便将损失最小化。最简单的优化算法是 梯度下降法 ，由 tf.train.GradientDescentOptimizer 实现。它会根据损失相对于变量的导数大小来修改各个变量。例如： 12optimizer = tf.train.GradientDescentOptimizer(0.01) # 创建优化器train = optimizer.minimize(loss) # 优化损失 该代码构建了优化所需的所有图组件，并返回一个训练指令。该训练指令在运行时会更新图中的变量。你可以按以下方式运行该指令： 123456with tf.Session() as sess: sess.run(init) # 全局初始化 for i in range(100): _, loss_value = sess.run((train, loss)) if i % 10 == 0: print(loss_value) 由上面的输出结果可以知道，随着迭代次数的增加，模型的损失函数值在不断的下降。 模型的保存与恢复一般情况下，当我们训练完模型之后，需要把训练结果保存下来，以便测试的时候使用。在 TensorFlow 中，通过 tf.train.Saver() 来保存图模型。 创建 Saver来管理模型中的所有变量。例如，以下代码段展示了如何调用 tf.train.Saver.save 方法以将变量保存到检查点文件中。因为前面所构建的变量都存于一个图中，这里为了防止变量冲突，新建另一个图来运行。 12345678910111213g_2 = tf.Graph() # 重新定义一个图with g_2.as_default(): # 在 g_2 图下创建节点 x = tf.constant([[1], [2], [3], [4]], dtype=tf.float32) linear_model = tf.layers.Dense(units=1,name=&#x27;g_2&#x27;) y_pred = linear_model(x) init = tf.global_variables_initializer() saver = tf.train.Saver() with tf.Session(graph=g_2) as sess: sess.run(init) print(sess.run(y_pred)) save_path = saver.save(sess, &quot;./temp/model.ckpt&quot;) print(&quot;保存成功&quot;) print(&quot;Model saved in path: %s&quot; % save_path) 从上面的运行结果可以看出，我们已经成功保存了模型，我们可以通过下面命令来查看所保存的模型。 1!tree 输出为： 123456789.├── lab.ipynb└── temp ├── checkpoint ├── model.ckpt.data-00000-of-00001 ├── model.ckpt.index └── model.ckpt.meta1 directory, 5 files 可以看到我们所保存的模型在文件夹 temp 下方，总共含有四个文件。.meta 文件表示模型的图结构，.data-00000-of-00001 和 .index 文件表示模型的权重文件；checkpoint 表示检查点文件。 现在来将模型读取出来。这里需要注意的是 tf.train.Saver 对象不仅将变量保存到检查点文件中，还将恢复变量。当恢复变量时，不必事先将其初始化。例如，以下代码段展示了如何调用 tf.train.Saver.restore 方法以从检查点文件中恢复变量： 1234567891011g_2 = tf.Graph() with g_2.as_default(): x = tf.constant([[1], [2], [3], [4]], dtype=tf.float32) linear_model = tf.layers.Dense(units=1,name=&#x27;g_2&#x27;) y_pred = linear_model(x) saver = tf.train.Saver() with tf.Session(graph=g_2) as sess: save_path = saver.restore(sess, &quot;./temp/model.ckpt&quot;) print(sess.run(y_pred)) print(&quot;读取成功&quot;) print(&quot;Model saved in path: %s&quot; % save_path) 总结通过以上学习，我们主要了解了 TensorFlow 的基本概念，如数据量流图，会话，张量等，并动手使用 TensorFlow 来实现一个简单的线性回归例子。此外还讲解了模型的保存与恢复。相信你此时已经对 TensorFlow 有一个初步的了解。","tags":[{"name":"Python","slug":"Python","permalink":"http://clarkhedi.github.io/tags/Python/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://clarkhedi.github.io/tags/TensorFlow/"}]},{"title":"车牌识别LPR（七）-- 字符识别","date":"2020-04-02T17:05:30.000Z","path":"2020/04/02/che-pai-shi-bie-lpr-qi-zi-fu-shi-bie/","text":"第七篇：字符识别 车牌定位、车牌倾斜校正、车牌字符分割都是为车牌字符识别做的前提工作，这些前提工作直接关系到车牌识别系统的性能。车牌字符识别是车牌识别系统的核心部分，车牌字符识别的准确率是衡量车牌识别系统的一个很重要的指标。 一般字符识别的方法就是采用模式识别方法，简单的来说模式识别就是先通过提取输入模板的特征，然后通过模板的特征对样本进行分类，从而识别出样本。模式识别主要包括：数据采集、预处理、特征提取、特征匹配，其结构框架如图： 字符识别是模式识别的一个重要应用，首先提取待识别字符的特征；然后对提取出来的特征跟字符模板的特征匹配；最后根据准则判定该字符所属的类别。不同的训练方法，不同的特征提取， 不同的匹配规则，就相应的有不同的字符识别方法，基本上很多就是在这些地方做改进，或者是采用新的规则。但是万变不离其宗。 （1）模板匹配字符识别算法。 模板匹配字符识别算法是图像识别中的经典算法之一，该算法的核心思想是：通过比较待识别字符图像的字符特征和标准模板的字符特征，计算两者之间的相似性，相似性最大的标准模板的字符即为待识别的字符。该方法首先要建立标准模板库，其中标准模板库中的字符的大小是一样的；然后将待识别的字符规格化，其大小应该和模板库中的字符一样；最后将待识别的字符和标准模板库中的所有字符进行匹配，计算相似度。模板匹配字符识别算法适用于印刷字体、字体规范的字符等，但是对字符变形、弯曲、字符旋转等情况的抗干扰能力差。 （2）神经网络字符识别算法 主要思想是：通过神经网络学习大量字符样本，从而得到字符的样本特征。当对待识别的字符进行识别时，神经网络就会将待识别字符的特征和之前得到的样本特征匹配，从而识别出字符。该算法主要利用神经网络的学习和记忆功能。神经网络虽然有其优点，但是由于采用神经网络识别字符依赖于初始的样本的选择，并且容易陷入局部最优和收敛速度慢，因此采用神经网络识别字符的算法仍需要改进。 （3）支持向量机 主要思想：同上，都是先得到样本特征，进行训练，然后再分类。SVM应该算是用的的最多的分类方法，一般大多适合于二分类问题，在这里就需要使用多分类器来构造。 字符识别步骤： 1、归一化 主要包括位置归一化和大小归一化。由于本文处理的车牌字符都是标准的印刷体字符，且都进行过倾斜校正，所以不需要对其进行位置归一化。但由于摄像距离大小不一样，导致拍摄到的车辆图像中的车牌字符大小不一，为了达到更好的识别效果，就需要对分割出来的单个车牌字符进行大小归一化。常用的归一化方法有两种：一种是将字符图像的外边框按比例线性放大或缩小到规定尺寸；另一种是根据水平和垂直两个方向像素的分布进行大小归一化。一般用第一种。当映射到原图像的点的坐标不是整数，即位于几个像素之间，这就需要利用插值算法来决定该像素的值。使用常见的双线性插值法。将图像归一化为32*64的。 2、特征 根据上一篇的介绍，采用LBP特征来识别汉字，均匀网格特征来识别字母和数字。 3、分类器 SVM作为分类器。支持向量机的原理，其所涉及到的数学知识比较复杂，自己编程实现的话有一定难度。采用现成的支持 SVM 的工具箱，公认做的比较好的是台湾大学林智仁(Chih-Jen Lin)教授开发的 LibSVM，支持 SVM 的各种算法，可以解决回归和分类识别问题。LibSVM 不但提供了 Windows 系统的可执行文件，还提供了 C 语言的源代码，方便科研工作者根据自己的需要进行改进，而且还提供了 Java、Matlab、C#、Ruthon 等语言的接口。当然可以直接调用opencv中的SVM工具。 汉字的笔画很稠密，字符分辨率非常低:如果对车牌汉字字符进行二值化，将会丢失汉字的很多重要的结构信息，产生不必要的噪声，导致笔画断裂和笔画粘连等。 4、二次识别 总的来说，单个字符的识别率比较高，容易识别错的主要是相近字符，解决这类问题的最佳办法就是二次识别。将相似字符中的一个识别出来后，便能确定其属于哪一类相近字符类别,利用区分相近字符的细节特征，将这个字符到专门识别这类相近字符的分类器中进行二次识别。车牌字符中相近字符主要有5类，分为“0”、“D”、“Q”；“B”、“8”；“2”、”Z”；“5”、”S”和“A”、“4”。 (1) “0”、“D、“Q” 从字符中可以看出,它们的区分在左侧和右下角，其中“D”的左边为直线，黑色像素点较多，而“0”和“Q”的左边均为弧线,黑色像素点相对较少；字符“Q”的右下角的笔画丰富，黑色像素较多。 (2)“B、8“ 它们的区别在字符的左侧,“8”的左侧为弧线,而“B”的左侧为直线。 (3) “2、Z” 它们的区别在字符的上方,“2”的上方为弧线,“Z”的上方为直线。 (4)“5、S” 它们的区别在字符的上半部分，“5”的上半部分中，上方和左侧均为直线,而”S”的上半部分为弧线。 (5)“A、4” 由于存在倾斜等情况,仅仅通过基本特征会出现误识别,它们的区别在左下角。","tags":[{"name":"LPR","slug":"LPR","permalink":"http://clarkhedi.github.io/tags/LPR/"}]},{"title":"车牌识别LPR（六）-- 字符特征","date":"2020-04-02T16:46:16.000Z","path":"2020/04/02/che-pai-shi-bie-lpr-liu-zi-fu-te-zheng/","text":"第六篇：字符特征 选择的字符特征应该满足以下条件： （1）选取的字符特征具有较强的鲁棒性，不受字符变形、弯曲等影响。 （2）两个字符的字符特征不能完全相同，但部分相同是允许的，即选择的字符特征是唯一的，但是不能重复。 （3）选取的字符特征要尽可能的提供字符的信息。 （4）选择的字符特征提取方法易于实现，能够减少计算时间。 一般采用纹理、边缘特征。纹理特征是表示图像的另一种重要的视觉特征，纹理结构反映图像亮度的空间变化情况，具有局部与整体的自相似性。纹理是有纹理基元按某种确定性的规律或某种统计规律排列组成的，在纹理区域内各部分具有大致相同的结构。 提取特征的的方法： （1）逐像素特征提取是指对整幅二值图像进行扫描，若图像中的像素点为黑色像素点时，则令特征值为 1，否则特征值为 0。经过该方法提取的特征向量的维数与图像中的像素点的个数相同。 （2）骨架特征提取是先细化字符图像，然后从细化后的字符图像中逐像素地提取特征。 此方法适用不同大小的字符。 （3）垂直方法数据统计特征提取是首先对字符图像进行水平投影，统计水平投影值，此处的水平投影值为黑色像素的数目；然后通过对字符图像进行垂直投影，统计垂直投影值，此处的垂直投影值仍为黑色像素的个数；最后将水平和垂直投影值作为字符的特征向量。 （4）13 点特征提取方法的总体思路是：首先把字符平均分成 8 份，统计每一份黑色 像素点的个数作为 8 个特征。分别统计这 8 个区域中的黑色像素的数目，就可以得到 8 个特征；然后统计水平方向中间两行和垂直方向中间两列的黑色像素点的个数作为 4 个特征；最后统计所有黑色像素点的个数作为 13 个特征。 常用的特征求取：一、粗网格特征： 将归一化后的字符图像等分成 8×8 网格，统计各网格内黑像素的数量，取得一个 64 维的网格特征。 外围特征：提取字符外围特征的步骤为： ① 把归一化后的点阵图形等分为 8 行。 ② 计算每一行中点从图像左边缘至第一项由白变黑的长度（如果没有由白变黑的点，则默认为零）。 ③ 再计算每一行中点从图像左边缘至第二项由白变黑的长度（如果没有由白变黑的点，则默认为零）。 ④ 仿照上面 3 个步骤，提取其它 3 个边缘的特征。 采用上述方法可以提取另一个 4×2×8=64 维的外围特征。 通过采用基于像素数量的粗网格特征与外围特征相结合方法可以提取字符的128 维特征，用以字符识别。 二、PCA进行汉字识别，网格特征进行数字和字母的提取。 网格特征是指通过把二值化后的字符分成M×N个网格，统计每一个网格中的字符像素数量，把各个网格中的像素数量组合起来作为字符的网格特征来识别字符。字母数字相对于汉字来说笔画简单，也极少出现字符轮廓模糊的现象。因此，字母数字的识别相对来说比较简单。但是，字母数字之间存在相似字符的比例较高，而且相似字符之间的差异又比较小，很容易识别错。对字母数字的识别论文采用了二次识别的思想。 三、均匀网格特征 统计黑像素点在每个网格中所占的比例，属于统计特征中局部特征的一种，体现了文字点阵的整体形状的分布。它将字符图像二值化以后，再把样本字符图像分成m×n个M格，并统计每个网格中属于文字点阵的像数量，记为i；统计整个图像中趋于文字点阵的像素数量，记为j；计算各个网格中的文字点阵的像素数量整个像中文字点阵的像素数量之比P=i/j，将每个网格统计的百分比P组合起来作为字符的统计特征，用以实现对字符的识别。每个网格中的文字点阵比例反映了文字笔画在二维平面空间的分布特征。 网格特征的统计是以网格为单位进行的,即使个别像素点的统计有误差也不会对识别结果造成很大的影响，该特征还具有较强的区分相似字符的能力。此特征提取算法比较简单，计算速率很快,且易于实现,但其对字符图像配准要求较高，故需要在提取字符图像的特征之前，对图像进行去边框等预处理操作。此算法更适合印刷体等较规则的字体，而不适用于手写体。 四、LBP特征进行汉字识别 预处理模块对图像进行归一化操作；第二个模块计算出图像中每个像素点的LBP值；第三个模块用于将图像平均分割为M×N个网格；最后一个模块用于计算各块的LBP特征。 1、传统的LBP算法是基于3 × 3的窗口的，对应于9个灰度值。将该窗口的8邻域的灰度值与中心像素的灰度值比较，小于中心灰度值的像素点的置为0，反之将其置为1；然后，通过逆吋针或者顺时针将这8个二进制数转化为一个二进制序列，并求出其对应的十进制值，作为这个3×3窗口的中心像素点的特征值。即各像素点的LBP值。 2、将每个像素点的LBP值齊代它的灰度值,得到LBP阁像。并将LBP图像分块，对每个分块进行直方图统计。如,将LBP图像分为4×8块，每块大小为8×8。在每个分块内，将0-255的LBP值量化为32级，并进行直方图统计。即每个分块的LBP特征为32维。 3、将各个小块的LBP特征连起来，获得(4×8)×32=1024维的一个矢量，该矢量即为字符图像的LBP特征。 改进的LBP特征： 均匀模式：它们有一个共同点，即在LBP二值编码序列巾，最多有两个0到1或1到0的变化。LBP二值编码序列为11000001，从1到0的变化为1次,从0到1的变化为1次，即它的均匀性U(LBP)=2。满足U(LBP)&lt;=2的所有模式称为均匀模式。在8邻域中，满足U(LBP)&lt;=2的所有模式的个数为8×(8-1)+2。再进一步将它们旋转到最小值后，具有旋转不变性的均勾模式(Rotation Invariant Uniform Pattern)的个数则为8+1。 模式对应的LBP二进制中从0变化为1和从1变化为0的次数之和小于等于两次，则该模式就是均匀模式。再根据顺时针或逆时针方向读出8个二进制数作为一个二进制序列,计算其对应的十进制值，作为该3×3矩形的中心元的特征值。反之，则该模式就不是均匀模式，它们的LBP值均为8+1。 由于改进的LBP特征是用58种均匀模式和统一后的一种非均匀模式来表示的。即在每个分块内，将0-255的LBP倍转化为59级。将这59级量化到0-63、64-127、128-191、192-255这四个区间中，并进行直方图统计。即每个分块的LBP特征为4维。 将各个小块的LBP特征连起来，获得(4×8)×4=128维的一个矢量，矢量即为字符图像的LBP特征。均匀模式时的LBP特征向量维数=图像分块数×59，改进的LBP特征向量维数=图像分块数×4，大大地提高了识别速率。","tags":[{"name":"LPR","slug":"LPR","permalink":"http://clarkhedi.github.io/tags/LPR/"}]},{"title":"车牌识别LPR（五）-- 字符分割","date":"2020-04-02T16:25:45.000Z","path":"2020/04/02/che-pai-shi-bie-lpr-wu-zi-fu-fen-ge/","text":"第五篇：字符分割 在知道了车牌字符的规律之后，可以根据车牌的特点对字符进行分割。一般最容易想到的方法就是根据车牌投影、像素统计特征对车牌图像进行字符分割的方法。是一种最常用的、最基本的、最简单的车牌字符分割方法。它的精髓是对车牌图像进行逐列扫描，统计车牌字符的每列像素点个数，并得到投影图，根据车牌字符像素统计特点（投影图中的波峰或者波谷），把车牌分割成单个独立的字符。 图像的边缘信息一般都是高频信息，所以在水平、垂直方向上对车牌图像进行小波变换，对其高频信息进行重构，获得相应的高频信息方面的子图，在车牌垂直投影图像中找到每个车牌字符的边界所在位置，并记下边界位置的横坐标；同理在水平投影图像中找到相应的边界的纵坐标，再根据相应的字符坐标值将字符分割出来。 一般在进行分割之前需要对车牌进行预处理：倾斜校正和去噪处理。 在进行分割之后需要统一字符大小，对其进行归一化和去边框处理。 （1）统一车牌底色： 对不同类型的车牌灰度图像进行二位化以后，有的呈现的是黑底白字，而有的则是白底黑字，为了便于对字符进行分割，需首先将不同种类车牌的二值化结果进行景颜色和目标颜色的统一，然后再用相关字符分割的方法对车牌屮的字符进行切分和提収。统一车牌底色可以有两种方法： 基于颜色分量的判断，但由于我国车牌种类太多，这个方法并不能完全区分，但是区分两种车牌类型还是可以的，例如蓝底白字车牌中的R&lt;B，而黄底黑字中的B&gt;R，在考虑到光照影响和使用已久褪色车牌上这种方法就不好了。 基于二值图像中像素比例特征的车牌底色判断：一般情况下，二值化后的车牌图像中字符笔画的像素个数在整个车牌的像素数目中所占的比例要小于50%。因此，可以通过分别计算二值化后的车牌中两种像素值的像素个数的大小来判断是否需要反色，若目标像素的比例大于50%，则将图像进行反色，否则不进行处理。这种方法的优点是算法简单，适用各种底色类型的车牌。缺点是若车牌中含有的字符的笔画较粗或者是车牌上存在较多污点或者是有装饰物等因素影响时，往往不能准确的判断底色。 （2）图像去噪 采集的图像总是会受到各种噪声的影响。为了保证后续处理的精确度，需要抑制图像中的噪声。对二值化后的车牌图像进行中值滤波处理，它是一种常见的非线性滤波方法，是一种局部平均的图像平滑技术，也是一种低通滤波。经典的中值滤波算法步骤如下： 1、令一个 3*3模板沿行或者列方向的移动； 2、每次移动后，对模板覆盖区域的像素灰度值进行排序； 3、用排序得到的中值代替模板内中心位置的原始图像像素灰度值。 通过以上步骤可以看出，中值滤波的主要功能就是让与周围像素灰度值的绝对差较大的像素改为与周围像素灰度值接近的灰度值，去除那些相对于其领域像素更亮或更暗的灰度。一般来说，小于中值滤波器模板面积一半的亮或暗区域会被滤掉，而较大的物体则会几乎原封不动的保留下来。 （3）倾斜校正 通常车牌区域的上下沿是两条明显的平行直线，一般都采用Hough 变换，检测出这两条直线的倾斜角，然后对车牌进行校正。然而传统的 Hough变换是对整幅图像的每个像素进行计算，以求出图像中可能存在的直线。 要想使用 Hough 变换计算车牌的倾斜角度，必须先确定进行 Hough 变换所需要的数据，即车牌的边缘点。如果图像包含完整的车牌，一般采用检测车牌的上下边框边缘点来作为 Hough 变换的数据，但由于实际得到的车牌不一定含有边框或者只有极少量的边框，所以最常用的是直接检测车牌每个字符上下边缘点作为Hough 变换的数据来源，但是由于实际中得到的车牌含有噪声、污损等原因，用这种方法会产生大量的干扰点，影响校正效果。 方法：对车牌图像在垂直方向进行投影并用高斯滤波器进行平滑，定位投影曲线中的所有波谷点，然后在相应的二值图中，查找所有波谷点之间最高的连通区域，得到的各个区域大部分就是车牌中的各个字符，最终选取各个连通域中即字符的最高和最低点作为 Hough 变换的检测点。对图像进行旋转时采用双线性插值。 （4）去边框 定位出来的车牌图像往往会包含车牌的部分或者全部边框，甚至还包含部分车身，为车牌字符分割带来了不利影响。因此就需要先对车牌图像进行去边框处理，其原理如下：采用水平投影得到上下边界。 （5）字符分割 采用一种基于相邻字符最大间隔宽度的方法来对车牌中的字符进行分割。由单行车牌的特点可以知道，在第二个字符和第三个字符之间存在一个圆形的间隔符，且该间隔符在每个单行车牌中有且仅有一个，还有一个重要的特点就是此间隔符所在的间隙约是其他相邻字符之间间隙的2.6倍，是整个车牌图像中相邻字符的最大间隙，根据这一先验知识首先确定了第二个字符右边缘和第三个字符左边缘的位置，然后由二值图像的垂直投影及单个字符的高宽比确定后5个和前2个字符的精确位置，因此，该方法的最为关键的部分是寻找图像中间隔符所在的空隙。 采用连通域和投影相结合的方法来对车牌图像进行字符分割，采用四连通标记法对车牌字符边界进行标记，形成连通域；然后判断各个区域的高宽是否基本等于车牌字符区域的高宽（去边框时已经求出），若相差较大时，就进行垂直投影，把宽小于车牌字符宽的相邻区域进行合并，把宽大于车牌字符宽的相邻区域进行进一步分割；最后对各个区域加矩形边框，提取单个车牌字符。 在理想的情况下，波谷的值应该为零，并且两个字符之间应该存在波谷，但是由于受到噪声的干扰，使得波谷的值为非零。常见的字符分割的问题有：字符粘连、字符断裂、数字“1”。字符粘连是指两个以上的字符连在一起，在垂直投影上的表现是原本应该为波谷的地方，现在却为非零的垂直投影值；字符断裂是一个字符分裂为几部分，在垂直投影上的表现为几段垂直投影；数字“1”的垂直投影值比较小，容易误判为噪声。可以结合车牌中字符的几何特征解决上述问题。设车牌中字符的宽度为 Width。 1）字符粘连 当 Width&lt; charWdith &lt; 1.5Width，其中 charWidth 为粘连字符的宽度。此时为两个字符粘连的情形。可取 charWidth / 2 作为单个字符的宽度，以此来分割两个粘连的字符；若 1.5Width&lt; charWidth&lt; 2*Width，此时为三个字符粘连的情况。通过单个字符具有固定的宽高比的先验知识，利用字符的高度求出字符的宽度。然后根据字符的宽度对粘连的字符进行分割。 2）字符断裂 若 charWidthi&lt; 0.5*Width 且 0.5*Width &gt; charWidthi+1。其中 charWidthi为当前字符的宽度，charWidthi+1为下一个字符的宽度。此时把当前字符和下一个字符合并。 3）数字“1” 当 charWidthi&lt; 0.5Width 且 0.5Width &lt; charWidthi+1时，统计区间宽度 charWidthi内的投影值大于 0.8*Height 的个数 nums，其中 Height 为车牌图像的高度。当符合条件 nums ≥ Thresh 时，其中 Thresh 为阈值，此时判定为数字“1”，否则为噪声。 采用的车牌字符分割方法；对车牌图像进行灰度化处理，去除颜色信息，使后面的字符分割算法运行速度更快；对灰度车牌图像进行二值化处理（otsu），并统一车牌图像的背景和字符的颜色；对有一定倾斜角度的车牌图像进行倾斜校正处理，对车牌图像进行去边框处理；采用连通域与投影法相结合的方法对车牌图像进行字符分割，为后面的单个字符识别做准备。","tags":[{"name":"LPR","slug":"LPR","permalink":"http://clarkhedi.github.io/tags/LPR/"}]},{"title":"车牌识别LPR（四）-- 车牌定位","date":"2020-04-02T16:08:56.000Z","path":"2020/04/02/che-pai-shi-bie-lpr-si-che-pai-ding-wei/","text":"第四篇：车牌定位 车牌定位就是采用一系列图像处理或者数学的方法从一幅图像中将车牌准确地定位出来。车牌定位提取出的车牌是整个车牌识别系统的数据来源，它的效果的好坏直接影响到整个系统的表现，只有准确地定位出车牌，才会有后续的车牌分割与字符识别。 目前车牌定位有两大类、基于灰度、基于彩色。 基于灰度：​ 我们采用的是基于灰度的形态学的车牌定位：首先根据车牌区域中丰富的纹理特征，提取车牌图像中垂直方向的边缘并二值化。然后对得到的二值图像进行数学形态学(膨胀、腐烛、幵闭运算等)的运算，使得车牌区域形成一个闭合的连通区域。最后通过车牌的几何特征(高、宽、宽高比等)对得到的候选区域进行筛选，最终得到车牌图像。 基于灰度的还有边缘检测的车牌定位：由于车牌字符的灰度值与车牌底色的灰度值相差较大，字符与底色的交界处就有灰度突变，灰度突变处就会产生边缘，这是车牌定位技术中非常重要的特征。也可以通过检测车牌的外边框来定位车牌，由于外边框的上下左右四边都为直线，而且有明显的边缘特征，所以首先利用边缘检测算法提取车牌边框位置，然后，用Hough变换算法检测直线，确认外边框的上下左右四条边位置就确定了车牌在图像中的位置。 基于投影法的车牌定位方法：首先对车牌图像进行二值化，由于车牌区域存在明显的剧烈的字符与背景的灰度跳变，将跳变次数投影到垂直轴上，那么车牌区域对应的垂直轴上会有一个明显的峰值，这样可以得到车牌的上下边界。然后对上下边界内的区域进行水平投影，字符区域会出现明显的峰值，这样可以得到车牌的左右边界。这种方法比较理想化。 基于纹理分析的车牌定位方法：所谓的纹理特征是指对图像进行扫描得到的灰度变化曲线，由于扫描经过车牌得到的变化曲线明显不同于经过非车牌得到的曲线，根据这个特点再结合形态学操作和其它先验知识就能从图像中提取出车牌。 基于彩色的： 从颜色空间的角度来看，HSV (Hue色调，Saturation饱和度，Value亮度)颜色空间具有线性伸缩性，比RGB颜色空间更容易区分色彩。HSV车牌定位典型的思路是首先将车牌图像从RGB空间转换到HSV空间，然后寻找图像中含有蓝白相间、黄黑相间、白红相间和白黑相间的地方，对得到的候选区域进一步用字符颜色提取车牌字符，最后用车牌的字符特征确定车牌位置。基于彩色图像的车牌定位方法对字符颜色和背景颜色固定的车牌可以取得较好的效果。 基于彩色图像的边缘检测和区域生长相结合的车牌定位：实现该方法的基本思想是：首先可以利用边緣检测算子对原始彩色(RGB空问)图像进行边缘检测，使得车牌区域的纵向纹理特征得到增强；接着利用数学形态学中的膨胀算法实现区域的连通，然后采用区域生长的方法对候选区域进行标记，最后利用车牌具有的特征和字符排列的频率特点，去除伪车牌区域，得到车牌区域。 基于纹理和颜色综合特征的车牌定位：首先将原始彩色图像M0的颜色空间转化到HSV颜色空间M1；接着对M1进行色彩分割，把所需要的颜色的区域设置为前景白色，其他区域设为背景黑色，此时得到图像M2，其次对M2采用区域生长的方法进行处理，并生成连通区域，得到车牌区域的集合A，然后若集合A中不包含车牌，则继续对M1进行色彩分割，提取下一块前景颜色区域，并对该区域进行车牌特征分析，重复上述过程。 车牌轮廓特征判断条件： （1）外接轮廓的高度大于5个像素或小于25个像素 （2）外接轮廓的宽度大于20个像素或小于80个像素 （3）外接轮廓的宽高比大于2或小于10 由于我国车牌种类繁多，颜色组合不一致，会遇到以下问题：一方面各地发放的车牌的底色色调会有所不同，另一方面受自然光照变化影响，采集到车牌图像的色度的变化范围也很大。因此，定位我国车牌的方法不适宜直接利用颜色信息进行定位。 其实，还有一些文献里提出支持向量机和adaboost等分级分类的定位方法，虽然使用训练的方法可以很准确的得到车牌图像，但是实际中由于环境的复杂性，单纯的一种方法并不不能得到很好的结果。对图像进行预处理，结合三次定位，像素统计粗定位，颜色阈值定位，文理特征定位，一次次的精确定位结果，调整参数，直到得到正确的车牌图像。 这里有涉及到边缘检测的应用，其中边缘检测就有几种常用的算子方法。还涉及颜色空间的转换，这里不做具体展开。","tags":[{"name":"LPR","slug":"LPR","permalink":"http://clarkhedi.github.io/tags/LPR/"}]},{"title":"车牌识别LPR（三）-- LPR系统整体结构","date":"2020-04-02T15:50:26.000Z","path":"2020/04/02/che-pai-shi-bie-lpr-san-lpr-xi-tong-zheng-ti-jie-gou/","text":"第三篇：系统的整体架构 LPR系统大体上可由图像采集系统，图像处理系统，数据库管理系统三个子系统组成。它综合了通讯、信息、控制、传感、计算机等各种先进技术，构成一个智能电子系统。 图像采集系统：图像采集系统主要由传感器、辅助照明设备和图像采集设备组成，主要功能是采集车辆图像。当有车辆经过时会触发感应装置，感应装置一般为地感线圈，触发成功后摄像机或照相机会自动采集当前的图像，最后将采集到的图像传送到计算机或手持的嵌入式系统进行处理。 图像处理系统：图像处理系统即为本文主要讨论的算法处理模块，为整个系统的软件部分。它主要包括图像预处理、车牌定位、倾斜校正、字符分割和字符识别五个部分，它的任务是运用数字图像处理、模式识别等学科对获得的车辆图像进行处理以获得车牌上的字符内容信息，后面章节讲对它每一个部分做一个粗略的介绍。 数据管理系统：数据管理系统是一个后端管理数据库，它包含了几乎所有的图像输入是指利用摄像机或者数码相机采集到的车牌图像。车牌图像的质量与采集图像的设备和实际环境有关。性能好的摄像机能够得到质量更好的车牌图像，有利于识别车牌图像中的字符。在光照不均、恶劣天气的环境下，采集到的车牌图像的像质较差，导致车牌识别系统的性能降低。车牌登记信息，车牌中的字符信息被识别出来后就输入到这个系统进行查找对比，以方便公安机关追查被盗车辆，打击犯罪分子。 其中图像处理模块主要包括五个部分：预处理、车牌定位、倾斜校正、字符分割、字符识别。其中，车牌定位、字符分割、字符识别是车牌识别的关键技术。 ​ 图像预处理是指对采集到的图像进行二值化、边缘检测、去除噪声、图像灰度化等操作。经过预处理的车牌图像增能够强目标图像，提高目标和背景图像的对比度，方便车牌识别的后续工作。 车牌定位是从一幅拍摄到的图片中定位出车牌的位置，并从图片中提取出车牌图像。车牌定位正确与否直接影响到字符分割和识别的工作，是所有关键技术中的第一步。 倾斜校正是指检测车牌图像的倾斜角度，并校正车牌图像。倾斜的车牌图像会导致车牌中的字符倾斜，直接影响到车牌字符的分割和识别，因此必须对倾斜的车牌图像进行校正。 字符分割是对提取出的车牌图像进行切割，从车牌图像中提取出单个车牌字符的图像。由于字符识别是以分割出的单个字符为输入，所以字符分割的准确与否直接影响到字符识别。 字符识别是指对分割出的字符进行处理，识别出车牌中的字符。因为我国的车牌号码的字符包含：汉字、英文字母、数字，增加了对字符识别的难度。字符识别直接影响到整个车牌识别系统结果的准确性。 ​ 这是一个LPR系统最基本的结构组成，每个模块的功能也清晰的给出来了。 ​ 最后，在开发 LPR 算法之前，要确定算法的目的和要求。LPR 算法的最终目的是识别车辆的车牌号码，所以识别正确率自然是系统设计中应该首要考虑的因素。影响识别正确率的因素有很多，主要的有以下几点：一是定位的准确性；二是识别前字符的预处理；三是字符识别的算法。为了提高识别正确率，需要对现有的车牌字符识别算法进行改进，在后面的章节中会有详细的介绍。 其次，LPR 算法在工作时需要实时处理交通流量信息，所以系统的工作效率——即识别时间也是系统设计时必须要考虑的因素，一般要求在 1s 内能够完成识别，这就要求识别算法的复杂度、运算量不能太大。 除了算法识别正确率和识别时间外，算法软件的操作界面应尽量简单、友好，还要考虑系统的无故障运行时间，系统体积的大小等因素。最后，算法设计要面向现场、面向终端客户的需求，考虑到 LPR 系统在户外工作，所以要克服外面环境的复杂性及光照条件的变化，设计出一套适应性较强的算法。","tags":[{"name":"LPR","slug":"LPR","permalink":"http://clarkhedi.github.io/tags/LPR/"}]},{"title":"车牌识别LPR（二）-- 车牌特征及难点","date":"2020-04-02T15:31:45.000Z","path":"2020/04/02/che-pai-shi-bie-lpr-er-che-pai-te-zheng-ji-nan-dian/","text":"第二篇：车牌的特征及难点 2.1 对我国车牌的认识 我国目前使用的汽车牌号标准是 2007 年开始实施的《中华人民共和国机动车号牌》GA36-2007（2010 年修订）。根据 GA36-2007 对机动车牌号编排规则规定，我国汽车的车牌构造特点如下： 汽车车牌号的编排规则：我国的标准车辆车牌是由一个省份汉字（军警车牌为其他汉字）后跟字母或阿拉伯数字组成的 7 个字序列。标准车牌的的具体排列格式是：X1X2·X3X4X5X6X7，X1是各省、直辖市的简称或军警，X2是英文字母，代表该汽车所在地的地市代码，比如 A 代表省会，B 代表该省的第二大城市，C 代表该省的第三大城市，X3X4X5X6X7为英文字母或阿拉伯数字，2010年以前车牌号码的分布规律是，前面是字母，后面是数字。但是，随着车辆保有量的增加，每个字母所属号段越来越不够用。按照新《中华人民共和国机动车号牌》（2010 年修订）标准，将允许字母在后五位编码中任意一位出现，但不能超过两个。除了第一个汉字外，字母和数字的笔画在竖直方向都是联通的。 牌照类型如下图： ​ 绝大部分的汽车牌照的宽度为1100px，高度为350px，牌照上一共有7个或8个字符，其中，每个字符的宽度为45mm，高度为90mm，间隔符的宽度为10mm，除了第二个和第三个字符之间的间距为 34mm 外，字符之间的间隔宽度12mm。民用的汽车牌照上有所属省、自治区或直辖市的简称(军用、警察牌为其他汉字)，监督机关及发证照的代号(大写的英文字母)后跟阿拉伯数字或英文字母组成的7个字符序列。 可以简单的归纳为以下特征： 1、颜色特征：即前面的六种类型，采用了对比度较为强烈的两种颜色的组合使车牌能明显区分于其它物体，而且车牌边框为白色或黑色两种颜色。使领馆车牌中的“使”和“领”字为红色，港澳出入境车牌中的“港”和“澳“两字为白色。警用汽车摩托车为白底黑字组合，其中”警“字为红色。 2、车牌具有统一的标准尺寸，这便于字符的分割和车牌的定位。 3、边缘特征：汽车的车牌边框是有规则的边缘，由于汽车车牌的字符排列规则，汽车车牌的垂直边缘比水平边缘更为丰富，而汽车的车身却有丰富的水平边缘，垂直边缘不明显。 4、黑白跳变特征：车牌区域二值化后，字符和背景为一黑一白，存在明显的黑白跳变，且跳变的次数在一定范围内。 5、投影特征：汽车车牌图像进行垂直投影后的图像是由波峰、波谷交替组成的连续分布图，垂直投影后的图像会有约七个波峰或波谷区；汽车车牌图像进行水平投影后的图像中灰度跳变的像素点数累加值很大。 了解我国车牌的特征，有利于后续对车牌进行的各种操作，在项目步骤中，这属于对需求目标的全面了解。对车牌的了解不能跳过，因清楚的知道我们所要处理的的目标的各个特性，这样才有利于我们利用这些特性来操作车牌图像。 2.2 技术难点2.2.1、车牌定位中的难点 从环境等客观因素上来说，汽车的类型有很多且构造不同，使得不同汽车上的悬挂车牌的位置就会不同。这样，汽车车身与车牌区域出现相似的颜色、纹理，就很可能会造成车牌定位出错或需更长的时间才能定位出车牌。 车牌定位是指从拍摄的含有车牌的图像中定位出车牌的淮确位置，然后进一步的提取出车牌图像。其主要的难点有： 周围环境因素，比如随机噪声，天气气候(雪天，雨天，雾天等)，光线(白天强光，晚上漆黑等)等。 车牌自身因素，比如车牌倾斜，字迹模糊，车牌乱挂装饰物，车牌周围广告标语覆盖或干扰等。 2.2.2、字符分割中的难点 字符分割是指从含有字符的车牌图像中将字符分割出来，字符分割的好坏会直接 影响到下一步的字符识别。其主要的难点有： 光照影响，不的照射光源(车灯，太阳光或辅助光源)，不同的气候条件(雨雪阴晴)，不同的光照角度。 汽车由于长途奔袭，再加上风吹日晒等各种原因，车牌上的字符可能会粘连，缺损或断裂，这会给字符分割带来一定的麻烦。 缺乏统一的车牌标准，车牌主要包括普通车牌，外事车牌和军用车牌等，这些车牌的规格，适用范围和颜色各有不同。 实际应用中，摄像设备所放的方位和角度有可能造成拍摄出来的车牌图像倾斜、畸变或部分被遮挡；当汽车处于高速行驶时，所拍摄的车辆图像清晰度不高；背景复杂的车辆图像，定位会有一定的困难，对后续的字符分割和字符识别带来严重的困难。 2.2.3、字符识别中的难点 字符识别是指将分割好的字符图像送到分类器中，对图像中的字符进行识别。字符识别是整个车牌识别系统中的最后一步，也是最为关键的一步。主要的难点有： 车牌汉字中繁多的字符笔画，汉字较字母和数字的识别难度较大。 字符图像的分辨率较低时使得字符笔画结构特征不明显，特征难以提取。 相似字符的识别(B和8，D和0等)。 从算法上来说，由于采集到的车辆图像质量不高，存在噪声、图像模糊失真、车牌污损、其它字符区域干扰等情况，车牌识别技术中定位、分割、识别实现起来都有很多困难。算法的简捷、实用、快速往往和算法的速度形成冲突。怎样提高现有算法的识别率和速度，如何利用车牌的彩色信息进行车牌识别，一幅图像中多个车牌的情况怎样识别，怎样满足系统实时性要求等，这些都是车牌识别有待研究和解决的问题。","tags":[{"name":"LPR","slug":"LPR","permalink":"http://clarkhedi.github.io/tags/LPR/"}]},{"title":"车牌识别LPR（一）-- 研究背景","date":"2020-04-02T15:10:47.000Z","path":"2020/04/02/che-pai-shi-bie-lpr-yi-yan-jiu-bei-jing/","text":"第一篇：LPR研究背景 汽车的出现改变了以往出行徒步和以马代步的时代，极大地改变了人们的生活方式，扩大了人们的活动范围，加强了人与人之间的交流。全世界的汽车拥有量呈爆炸性增长，汽车虽方便了我们的出行，但同时也造成了城市交通压力，应用现代科技解决汽车不断增长而出现的交通问题已经成为一项重要的研究课题，智能交通系统应孕而出。 智能交通系统(Intelligent Transportation System，简称 ITS)是一种充分利用各种先进的高新技术来实现实吋、准确、高效的交通管理系统，使交通更畅通更安全，它也是一种交通信息服务系统，使人们出行更方便更快捷。随着智能交通系统的快速发展，智能交通系统已经融入人们的日常生活，使人们的生活越来越方便。车辆是智能交通系统中的重点研究对象，每辆车都有自身唯一的车牌号码，车牌号码反映了车辆信息以及关联着车主信息，通过车牌号码可以记录对应车辆的交通行为，因此，车牌识别技术是智能交通系统中最核心最基础的技术之一，决定着智能交通系统的发展速度和技术水平。 它能够实时地对城市的车辆进行检测、监控和管理，实现智能交通的实时性和高效性；它不仅可以有效地减少人工操作的参与，节约成本；还可以在一定程度上杜绝一些交通工作人员的违规、舞弊操作，解决收费流失等问题；它还可以对城市的过往车流量进行检测、指导相关工作，减少交通拥堵现象。 在这个大力倡导智慧型城市概念的社会，随着互联网技术的提升，网络的发展，智能的车牌识别系统早已经深入人们的生活中，监测车流量等。 电子警察系统：一种抓拍车辆违章违规行为的智能系统，大大降低了交通管理压力。 卡口系统：对监控路段的机动车辆进行全天候的图像抓拍，自动识别车牌号码，通过公安专网与卡口系统控制中心的黑名单数据库进行比对，当发现结果相符合时，系统自动向相关人员发出警报信号。 高速公路收费系统：自动化管理，当车辆在高速公路收费入口站时，系统进行车牌识别，保存车牌信息，当车辆在高速公路收费出口站时，系统再次进行车牌识别，与进入车辆的车牌信息进行比对，只有进站和出站的车牌一致方可让车辆通行。 停车场收费系统：随处可见，收费系统抓拍车辆图片进行车牌识别，保存车辆信息和进入时间,并语音播报空闲车位，当车辆离幵停车场时，收费系统自动识别出该车的车牌号码和保存车辆离幵的时间，并在数据库中查找该车的进入时间，计算出该车的停车费周，车主交完费用后，收费系统自动放行。 智能公交报站：当公交车进入和离开公交站台时，报站系统对其进行车牌识别，然后与数据库中的车牌进行比对，语音报读车牌结果和公交线路。 车牌识别技术应用广泛，当然，上面所指的应用只是其中的一小部分。随着智能交通的迅猛发展，社会对车牌自动识别的需求量会越来越高多，技术上也会越来越高。 车牌自动识别系统也叫做LPR（License Plate Recognition）系统，目前国内做的比较成熟的产品有北京汉王科技有限公司开发的“汉王眼”车牌识别系统，厦门宸天电子科技有限公司研发的 Supplate系列，深圳吉通电子有限公司研发的“车牌通”车牌识别产品、亚洲视觉科技有限公司研发的 VECON-VIS 自动识别系统等。也有很多高校在研究这个课题。国外相对的在这个方面开始的比较早，同时他们的车牌种类单一，字符简单，容易定位识别有关，取得不错的成就。 关于车牌识别的研究，虽然国内外学者已经作了大量的工作，但仍然存在一些问题。在车辆还比较新的时候，车牌上的字迹清晰，较容易识别，随着车龄越来越大，车子经过风吹雨淋，车牌难免受到一定程度的磨损，这样就会造成识别的难度。比如车牌图像的倾斜、车牌自身的磨损、光线的干扰都会影响到定位的精度。 车牌字符识别是在车牌准确定位的基础上，对车牌上的汉字、字母、数字进行有效确认的过程。目前已有的方法很多，但其效果与实际的要求相差很远，难以适应现代化交通系统高速度、快节奏的要求。因而对字符识别的进一步研究也同样具有紧迫性和必要性。","tags":[{"name":"LPR","slug":"LPR","permalink":"http://clarkhedi.github.io/tags/LPR/"}]},{"title":"Python GUI之tkinter窗口视窗教程大集合(看这篇就够了)","date":"2020-03-16T15:34:26.000Z","path":"2020/03/16/python-gui-zhi-tkinter-chuang-kou-shi-chuang-jiao-cheng-da-ji-he-kan-zhe-pian-jiu-gou-liao/","text":"Python GUI之tkinter窗口视窗教程大集合（看这篇就够了） 一、Tkinter是什么​ Tkinter 是使用 python 进行窗口视窗设计的模块。Tkinter模块(“Tk 接口”)是Python的标准Tk GUI工具包的接口。作为 python 特定的GUI界面，是一个图像的窗口，tkinter是python 自带的，可以编辑的GUI界面，我们可以用GUI 实现很多直观的功能，比如想开发一个计算器，如果只是一个程序输入，输出窗口的话，是没用用户体验的。所有开发一个图像化的小窗口，就是必要的。 对于稍有GUI编程经验的人来说，Python的Tkinter界面库是非常简单的。python的GUI库非常多，选择Tkinter，一是最为简单，二是自带库，不需下载安装，随时使用，三则是从需求出发，Python作为一种脚本语言，一种胶水语言，一般不会用它来开发复杂的桌面应用，它并不具备这方面的优势，使用Python，可以把它作为一个灵活的工具，而不是作为主要开发语言，那么在工作中，需要制作一个小工具，肯定是需要有界面的，不仅自己用，也能分享别人使用，在这种需求下，Tkinter是足够胜任的！ 这篇文章主要做一个简单概述和实践编程，对于从没有接触过GUI的新手，在脑中树立一个基本的界面编程概念，同时自己也能学会如何简单的实现一些小的图形窗口功能。 对于Tkinter编程，可以用两个比喻来理解： 第一个，作画。我们都见过美术生写生的情景，先支一个画架，放上画板，蒙上画布，构思内容，用铅笔画草图，组织结构和比例，调色板调色，最后画笔勾勒。相应的，对应到tkinter编程，那么我们的显示屏就是支起来的画架，根窗体就是画板，在tkinter中则是Toplevel，画布就是tkinter中的容器（Frame），画板上可以放很多张画布（Convas），tkinter中的容器中也可以放很多个容器，绘画中的构图布局则是tkinter中的布局管理器（几何管理器），绘画的内容就是tkinter中的一个个小组件，一幅画由许多元素构成，而我们的GUI界面，就是有一个个组件拼装起来的，它们就是widget。 第二个，我们小时候都玩过积木，只要发挥创意，相同的积木可以堆出各种造型。tkinter的组件也可以看做一个个积木，形状或许不同，其本质都是一样的，就是一个积木，不管它长什么样子，它始终就是积木！所以这些小组件都有许多共性，另外，个人认为，学习界面编程，最重要的不是一开始学习每个积木的样子，不是学习每个组件怎么用，而是这些组件该怎么放。初始学习中，怎么放远远比怎么用重要的多。网上有大量的文章资料，基本全是介绍组件怎么用的，对于怎么放，也就是tkinter中的布局管理器，都是一笔带过，这对初学者有点本末倒置，或许绝大部分是转载的原因吧，极少是自己真正写的。组件怎么用不是最迫切的，用到的时候再去了解也不迟，边用边学反而更好。因此我将专门写一章，详细介绍布局管理器的使用。 二、Tkinter 控件详细介绍1. 常用窗口部件及简要说明： Tkinter支持16个核心的窗口部件，这个16个核心窗口部件类简要描述如下： ​ Button：一个简单的按钮，用来执行一个命令或别的操作。 ​ Canvas：组织图形。这个部件可以用来绘制图表和图，创建图形编辑器，实现定制窗口部件。 ​ Checkbutton：代表一个变量，它有两个不同的值。点击这个按钮将会在这两个值间切换。 ​ Entry：文本输入域。 ​ Frame：一个容器窗口部件。帧可以有边框和背景，当创建一个应用程序或dialog(对话）版面时，帧被用来组织其它的窗口部件。 ​ Label：显示一个文本或图象。 ​ Listbox：显示供选方案的一个列表。listbox能够被配置来得到radiobutton或checklist的行为。 ​ Menu：菜单条。用来实现下拉和弹出式菜单。 ​ Menubutton：菜单按钮。用来实现下拉式菜单。 ​ Message：显示一文本。类似label窗口部件，但是能够自动地调整文本到给定的宽度或比率。 ​ Radiobutton：代表一个变量，它可以有多个值中的一个。点击它将为这个变量设置值，并且清除与这同一变量相关的其它radiobutton。 ​ Scale：允许你通过滑块来设置一数字值。 ​ Scrollbar：为配合使用canvas, entry, listbox, and text窗口部件的标准滚动条。 ​ Text：格式化文本显示。允许你用不同的样式和属性来显示和编辑文本。同时支持内嵌图象和窗口。 ​ Toplevel：一个容器窗口部件，作为一个单独的、最上面的窗口显示。 ​ messageBox：消息框，用于显示你应用程序的消息框。(Python2中为tkMessagebox) 2. Tkinter 模块元素简要说明 注意在Tkinter中窗口部件类没有分级；所有的窗口部件类在树中都是兄弟关系。 所有这些窗口部件提供了Misc和几何管理方法、配置管理方法和部件自己定义的另外的方法。此外，Toplevel类也提供窗口管理接口。这意味一个典型的窗口部件类提供了大约150种方法。 三、 动手实践学习1. 创建主窗口及Label部件(标签)创建使用 我们要学习使用上面提到的这些控件首先要创建一个主窗口，就像作画一样，先要架好架子和画板，然后才能在上面放画纸和各种绘画元素，创建好主窗口才能在上面放置各种控件元素。而创建过程是很简单的，如下： 示例代码： 12345678910111213141516171819202122232425262728293031# coding: utf-8# __author__ = &quot;HD&quot;# Date: 2020/3/16import tkinter as tk # 使用Tkinter前需要先导入def main(): # 第1步，实例化object，建立窗口window window = tk.Tk() # 第2步，给窗口的可视化起名字 window.title(&#x27;My Window&#x27;) # 第3步，设定窗口的大小(长 * 宽) window.geometry(&#x27;500x300&#x27;) # 这里的乘是小x # 第4步，在图形界面上设定标签 l = tk.Label(window, text=&#x27;你好！this is Tkinter&#x27;, bg=&#x27;white&#x27;, font=(&#x27;微软雅黑&#x27;, 12), width=30, height=2) # 说明： bg为背景，font为字体，width为长，height为高，这里的长和高是字符的长和高，比如height=2,就是标签有2个字符这么高 # 第5步，放置标签 l.pack() # Label内容content区域放置位置，自动调节尺寸 # 放置lable的方法有：1）l.pack(); 2)l.place(); # 第6步，主窗口循环显示 window.mainloop() # 注意，loop因为是循环的意思，window.mainloop就会让window不断的刷新，如果没有mainloop,就是一个静态的window,传入进去的值就不会有循环，mainloop就相当于一个很大的while循环，有个while，每点击一次就会更新一次，所以我们必须要有循环 # 所有的窗口文件都必须有类似的mainloop函数，mainloop是窗口文件的关键的关键。 if __name__ == &quot;__main__&quot;: main() 测试效果： 2. Button窗口部件 简单说明： Button（按钮）部件是一个标准的Tkinter窗口部件，用来实现各种按钮。按钮能够包含文本或图象，并且你能够将按钮与一个Python函数或方法相关联。当这个按钮被按下时，Tkinter自动调用相关联的函数或方法。 按钮仅能显示一种字体，但是这个文本可以跨行。另外，这个文本中的一个字母可以有下划线，例如标明一个快捷键。默认情况，Tab键用于将焦点移动到一个按钮部件。 什么时候用按钮部件 简言之，按钮部件用来让用户说“马上给我执行这个任务”，通常我们用显示在按钮上的文本或图象来提示。按钮通常用在工具条中或应用程序窗口中，并且用来接收或忽略输入在对话框中的数据。关于按钮和输入的数据的配合，可以参看Checkbutton和Radiobutton部件。 如何创建： 普通的按钮很容易被创建，仅仅指定按钮的内容（文本、位图、图象）和一个当按钮被按下时的回调函数即可： b = tk.Button(window, text=”hit me”, command=hit_me) 没有回调函数的按钮是没有用的，当你按下这个按钮时它什么也不做。你可能在开发一个应用程序的时候想实现这种按钮，比如为了不干扰你的beta版的测试者： b = tk.Button(window, text=”Help”, command=DISABLED) 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445# coding: utf-8# __author__ = &quot;HD&quot;# Date: 2020/3/16import tkinter as tk # 使用Tkinter前需要先导入def main(): # 第1步，实例化object，建立窗口window window = tk.Tk() # 第2步，给窗口的可视化起名字 window.title(&#x27;My Window&#x27;) # 第3步，设定窗口的大小(长 * 宽) window.geometry(&#x27;500x300&#x27;) # 这里的乘是小x # 第4步，在图形界面上设定标签 var = tk.StringVar() # 将label标签的内容设置为字符类型，用var来接收hit_me函数的传出内容用以显示在标签上 l = tk.Label(window, textvariable=var, bg=&#x27;white&#x27;, fg=&#x27;black&#x27;, font=(&#x27;微软雅黑&#x27;, 12), width=30, height=2) # 说明： bg为背景，fg为字体颜色，font为字体，width为长，height为高，这里的长和高是字符的长和高，比如height=2,就是标签有2个字符这么高 l.pack() # 定义一个函数功能（内容自己自由编写），供点击Button按键时调用，调用命令参数command=函数名 on_hit = False def hit_me(): global on_hit if on_hit == False: on_hit = True var.set(&#x27;you hit me&#x27;) else: on_hit = False var.set(&#x27;&#x27;) # 第5步，在窗口界面设置放置Button按键 b = tk.Button(window, text=&#x27;hit me&#x27;, font=(&#x27;Arial&#x27;, 12), width=10, height=1, command=hit_me) b.pack() # 第6步，主窗口循环显示 window.mainloop()if __name__ == &quot;__main__&quot;: main() 测试效果： 3. Entry窗口部件 简单说明： Entry是tkinter类中提供的的一个单行文本输入域，用来输入显示一行文本，收集键盘输入(类似 HTML 中的 text)。 什么时候用： 需要用户输入用户信息时，比如我们平时使用软件、登录网页时，用户交互界面让我们登录账户信息等时候可以用到。 示例代码： 12345678910111213141516171819202122232425262728# coding: utf-8# __author__ = &quot;HD&quot;# Date: 2020/3/16import tkinter as tk # 使用Tkinter前需要先导入def main(): # 第1步，实例化object，建立窗口window window = tk.Tk() # 第2步，给窗口的可视化起名字 window.title(&#x27;My Window&#x27;) # 第3步，设定窗口的大小(长 * 宽) window.geometry(&#x27;500x300&#x27;) # 这里的乘是小x # 第4步，在图形界面上设定输入框控件entry并放置控件 e1 = tk.Entry(window, show=&#x27;*&#x27;, font=(&#x27;微软雅黑&#x27;, 14)) # 显示成密文形式 e2 = tk.Entry(window, show=None, font=(&#x27;微软雅黑&#x27;, 14)) # 显示成明文形式 e1.pack() e2.pack() # 第5步，主窗口循环显示 window.mainloop() if __name__ == &quot;__main__&quot;: main() 测试效果： 4. Text窗口部件 简单说明： Text是tkinter类中提供的的一个多行文本区域，显示多行文本，可用来收集(或显示)用户输入的文字(类似 HTML 中的 textarea)，格式化文本显示，允许你用不同的样式和属性来显示和编辑文本，同时支持内嵌图象和窗口。 什么时候用： 在需要显示编辑用户、产品多行信息时，比如显示用户详细描述文字，产品简介等等，支持随时编辑。 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# coding: utf-8# __author__ = &quot;HD&quot;# Date: 2020/3/16import tkinter as tk # 使用Tkinter前需要先导入def main(): # 第1步，实例化object，建立窗口window window = tk.Tk() # 第2步，给窗口的可视化起名字 window.title(&#x27;My Window&#x27;) # 第3步，设定窗口的大小(长 * 宽) window.geometry(&#x27;500x300&#x27;) # 这里的乘是小x # 第4步，在图形界面上设定输入框控件entry框并放置 e = tk.Entry(window, show=None) # 显示成明文形式 e.pack() # 第5步，定义两个触发事件时的函数insert_point和insert_end（注意：因为Python的执行顺序是从上往下，所以函数一定要放在按钮的上面） def insert_point(): # 在鼠标焦点处插入输入内容 var = e.get() t.insert(&#x27;insert&#x27;, var) def insert_end(): # 在文本框内容最后接着插入输入内容 var = e.get() t.insert(&#x27;end&#x27;, var) # 第6步，创建并放置两个按钮分别触发两种情况 b1 = tk.Button(window, text=&#x27;insert point&#x27;, width=10, height=2, command=insert_point) b1.pack() b2 = tk.Button(window, text=&#x27;insert end&#x27;, width=10, height=2, command=insert_end) b2.pack() # 第7步，创建并放置一个多行文本框text用以显示，指定height=4为文本框是四个字符高度 t = tk.Text(window, height=4) t.pack() # 第8步，主窗口循环显示 window.mainloop()if __name__ == &quot;__main__&quot;: main() 测试效果： 5. Listbox窗口部件 简单说明： Text是tkinter类中提供的的列表框部件，显示供选方案的一个列表。listbox能够被配置来得到radiobutton或checklist的行为。 什么时候用： 在有一个很多内容选项组成的列表提供用户选择时会用到。 示例代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# coding: utf-8# __author__ = &quot;HD&quot;# Date: 2020/3/16import tkinter as tk # 使用Tkinter前需要先导入def main(): # 第1步，实例化object，建立窗口window window = tk.Tk() # 第2步，给窗口的可视化起名字 window.title(&#x27;My Window&#x27;) # 第3步，设定窗口的大小(长 * 宽) window.geometry(&#x27;500x300&#x27;) # 这里的乘是小x # 第4步，在图形界面上创建一个标签label用以显示并放置 var1 = tk.StringVar() # 创建变量，用var1用来接收鼠标点击具体选项的内容 l = tk.Label(window, bg=&#x27;white&#x27;, fg=&#x27;black&#x27;, font=(&#x27;微软雅黑&#x27;, 12), width=10, textvariable=var1) l.pack() # 第6步，创建一个方法用于按钮的点击事件 def print_selection(): value = lb.get(lb.curselection()) # 获取当前选中的文本 var1.set(value) # 为label设置值 # 第5步，创建一个按钮并放置，点击按钮调用print_selection函数 b1 = tk.Button(window, text=&#x27;print selection&#x27;, width=15, height=2, command=print_selection) b1.pack() # 第7步，创建Listbox并为其添加内容 var2 = tk.StringVar() var2.set((1, 2, 3, 4)) # 为变量var2设置值 # 创建Listbox lb = tk.Listbox(window, listvariable=var2) # 将var2的值赋给Listbox # 创建一个list并将值循环添加到Listbox控件中 list_items = [11, 22, 33, 44] for item in list_items: lb.insert(&#x27;end&#x27;, item) # 从最后一个位置开始加入值 lb.insert(1, &#x27;first&#x27;) # 在第一个位置加入&#x27;first&#x27;字符 lb.insert(2, &#x27;second&#x27;) # 在第二个位置加入&#x27;second&#x27;字符 lb.delete(2) # 删除第二个位置的字符 lb.pack() # 第8步，主窗口循环显示 window.mainloop()if __name__ == &quot;__main__&quot;: main() 测试效果： 6. Radiobutton窗口部件 简单说明： Radiobutton：代表一个变量，它可以有多个值中的一个。点击它将为这个变量设置值，并且清除与这同一变量相关的其它radiobutton。 什么时候用： 在有一个很多内容选项组成的选项列表提供用户选择时会用到，用户一次只能选择其中一个，不能多选。 示例代码： 12345678910111213141516171819202122232425262728293031323334353637383940# coding: utf-8# __author__ = &quot;HD&quot;# Date: 2020/3/16import tkinter as tk # 使用Tkinter前需要先导入def main(): # 第1步，实例化object，建立窗口window window = tk.Tk() # 第2步，给窗口的可视化起名字 window.title(&#x27;My Window&#x27;) # 第3步，设定窗口的大小(长 * 宽) window.geometry(&#x27;500x300&#x27;) # 这里的乘是小x # 第4步，在图形界面上创建一个标签label用以显示并放置 var = tk.StringVar() # 定义一个var用来将radiobutton的值和Label的值联系在一起. l = tk.Label(window, bg=&#x27;green&#x27;, width=20, text=&#x27;empty&#x27;) l.pack() # 第6步，定义选项触发函数功能 def print_selection(): l.config(text=&#x27;you have selected &#x27; + var.get()) # 第5步，创建三个radiobutton选项，其中variable=var, value=&#x27;A&#x27;的意思就是，当我们鼠标选中了其中一个选项，把value的值A放到变量var中，然后赋值给variable r1 = tk.Radiobutton(window, text=&#x27;Option A&#x27;, variable=var, value=&#x27;A&#x27;, command=print_selection) r1.pack() r2 = tk.Radiobutton(window, text=&#x27;Option B&#x27;, variable=var, value=&#x27;B&#x27;, command=print_selection) r2.pack() r3 = tk.Radiobutton(window, text=&#x27;Option C&#x27;, variable=var, value=&#x27;C&#x27;, command=print_selection) r3.pack() # 第7步，主窗口循环显示 window.mainloop()if __name__ == &quot;__main__&quot;: main() 测试效果： 7. Checkbutton窗口部件 简单说明： Checkbutton：代表一个变量，它有两个不同的值。点击这个按钮将会在这两个值间切换，选择和取消选择。 什么时候用： 在有一个很多内容选项组成的选项列表提供用户选择时会用到，用户一次可以选择多个。 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# coding: utf-8# __author__ = &quot;HD&quot;# Date: 2020/3/16import tkinter as tk # 使用Tkinter前需要先导入def main(): # 第1步，实例化object，建立窗口window window = tk.Tk() # 第2步，给窗口的可视化起名字 window.title(&#x27;My Window&#x27;) # 第3步，设定窗口的大小(长 * 宽) window.geometry(&#x27;500x300&#x27;) # 这里的乘是小x # 第4步，在图形界面上创建一个标签label用以显示并放置 l = tk.Label(window, bg=&#x27;yellow&#x27;, width=20, text=&#x27;empty&#x27;) l.pack() # 第6步，定义触发函数功能 def print_selection(): if (var1.get() == 1) &amp; (var2.get() == 0): # 如果选中第一个选项，未选中第二个选项 l.config(text=&#x27;I love only Python &#x27;) elif (var1.get() == 0) &amp; (var2.get() == 1): # 如果选中第二个选项，未选中第一个选项 l.config(text=&#x27;I love only C++&#x27;) elif (var1.get() == 0) &amp; (var2.get() == 0): # 如果两个选项都未选中 l.config(text=&#x27;I do not love either&#x27;) else: l.config(text=&#x27;I love both&#x27;) # 如果两个选项都选中 # 第5步，定义两个Checkbutton选项并放置 var1 = tk.IntVar() # 定义var1和var2整型变量用来存放选择行为返回值 var2 = tk.IntVar() c1 = tk.Checkbutton(window, text=&#x27;Python&#x27;, variable=var1, onvalue=1, offvalue=0, command=print_selection) # 传值原理类似于radiobutton部件 c1.pack() c2 = tk.Checkbutton(window, text=&#x27;C++&#x27;, variable=var2, onvalue=1, offvalue=0, command=print_selection) c2.pack() # 第7步，主窗口循环显示 window.mainloop() if __name__ == &quot;__main__&quot;: main() 测试效果： 8. Scale窗口部件 简单说明： Scale： 尺度（拉动条），允许你通过滑块来设置一数字值。 什么时候用： 在需要用户给出评价等级，或者给出一个评价分数，或者拉动滑动条提供一个具体的数值等等。 示例代码： 123456789101112131415161718192021222324252627282930313233343536# coding: utf-8# __author__ = &quot;HD&quot;# Date: 2020/3/16import tkinter as tk # 使用Tkinter前需要先导入def main(): # 第1步，实例化object，建立窗口window window = tk.Tk() # 第2步，给窗口的可视化起名字 window.title(&#x27;My Window&#x27;) # 第3步，设定窗口的大小(长 * 宽) window.geometry(&#x27;500x300&#x27;) # 这里的乘是小x # 第4步，在图形界面上创建一个标签label用以显示并放置 l = tk.Label(window, bg=&#x27;green&#x27;, fg=&#x27;white&#x27;, width=20, text=&#x27;empty&#x27;) l.pack() # 第6步，定义一个触发函数功能 def print_selection(v): l.config(text=&#x27;you have selected &#x27; + v) # 第5步，创建一个尺度滑条，长度200字符，从0开始10结束，以2为刻度，精度为0.01，触发调用print_selection函数 s = tk.Scale(window, label=&#x27;try me&#x27;, from_=0, to=10, orient=tk.HORIZONTAL, length=200, showvalue=0, tickinterval=2, resolution=0.01, command=print_selection) s.pack() # 第7步，主窗口循环显示 window.mainloop()if __name__ == &quot;__main__&quot;: main() 测试效果： 9. Canvas窗口部件 简单说明： Canvas：画布，提供绘图功能(直线、椭圆、多边形、矩形) 可以包含图形或位图，用来绘制图表和图，创建图形编辑器，实现定制窗口部件。 什么时候用： 在比如像用户交互界面等，需要提供设计的图标、图形、logo等信息是可以用到画布。 示例代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243# coding: utf-8# __author__ = &quot;HD&quot;# Date: 2020/3/16import tkinter as tk # 使用Tkinter前需要先导入def main(): # 第1步，实例化object，建立窗口window window = tk.Tk() # 第2步，给窗口的可视化起名字 window.title(&#x27;My Window&#x27;) # 第3步，设定窗口的大小(长 * 宽) window.geometry(&#x27;500x300&#x27;) # 这里的乘是小x # 第4步，在图形界面上创建 500 * 200 大小的画布并放置各种元素 canvas = tk.Canvas(window, bg=&#x27;green&#x27;, height=200, width=500) # 说明图片位置，并导入图片到画布上 image_file = tk.PhotoImage(file=&#x27;pic.gif&#x27;) # 图片位置（相对路径，与.py文件同一文件夹下，也可以用绝对路径，需要给定图片具体绝对路径） image = canvas.create_image(250, 0, anchor=&#x27;n&#x27;, image=image_file) # 图片锚定点（n图片顶端的中间点位置）放在画布（250,0）坐标处 # 定义多边形参数，然后在画布上画出指定图形 x0, y0, x1, y1 = 100, 100, 150, 150 line = canvas.create_line(x0 - 50, y0 - 50, x1 - 50, y1 - 50) # 画直线 oval = canvas.create_oval(x0 + 120, y0 + 50, x1 + 120, y1 + 50, fill=&#x27;yellow&#x27;) # 画圆 用黄色填充 arc = canvas.create_arc(x0, y0 + 50, x1, y1 + 50, start=0, extent=180) # 画扇形 从0度打开收到180度结束 rect = canvas.create_rectangle(330, 30, 330 + 20, 30 + 20) # 画矩形正方形 canvas.pack() # 第6步，触发函数，用来一定指定图形 def moveit(): canvas.move(rect, 2, 2) # 移动正方形rect（也可以改成其他图形名字用以移动一起图形、元素），按每次（x=2, y=2）步长进行移动 # 第5步，定义一个按钮用来移动指定图形的在画布上的位置 b = tk.Button(window, text=&#x27;move item&#x27;, command=moveit).pack() # 第7步，主窗口循环显示 window.mainloop()if __name__ == &quot;__main__&quot;: main() 所用图片： 当然你可以随意用你的一张图片导入画布试一试效果，图片可以用画图工具改一下像素大小，以免图片太大，导入画布显示不全，当然你也可以用我提供的素材，下面是链接：https://files.cnblogs.com/files/shwee/pic.gif 图片锚定点位置参数图： 测试效果： 10. Menu窗口部件 简单说明： Menu：菜单条，用来实现下拉和弹出式菜单，点下菜单后弹出的一个选项列表,用户可以从中选择 什么时候用： 在比如像软件或网页交互界面等，需要提供菜单选项功能提供用户选择菜单选项功能时用到。 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# coding: utf-8# __author__ = &quot;HD&quot;# Date: 2020/3/16import tkinter as tk # 使用Tkinter前需要先导入def main(): # 第1步，实例化object，建立窗口window window = tk.Tk() # 第2步，给窗口的可视化起名字 window.title(&#x27;My Window&#x27;) # 第3步，设定窗口的大小(长 * 宽) window.geometry(&#x27;500x300&#x27;) # 这里的乘是小x # 第4步，在图形界面上创建一个标签用以显示内容并放置 l = tk.Label(window, text=&#x27; &#x27;, bg=&#x27;green&#x27;) l.pack() # 第10步，定义一个函数功能，用来代表菜单选项的功能，这里为了操作简单，定义的功能比较简单 counter = 0 def do_job(): global counter l.config(text=&#x27;do &#x27;+ str(counter)) counter += 1 # 第5步，创建一个菜单栏，这里我们可以把他理解成一个容器，在窗口的上方 menubar = tk.Menu(window) # 第6步，创建一个File菜单项（默认不下拉，下拉内容包括New，Open，Save，Exit功能项） filemenu = tk.Menu(menubar, tearoff=0) # 将上面定义的空菜单命名为File，放在菜单栏中，就是装入那个容器中 menubar.add_cascade(label=&#x27;File&#x27;, menu=filemenu) # 在File中加入New、Open、Save等小菜单，即我们平时看到的下拉菜单，每一个小菜单对应命令操作。 filemenu.add_command(label=&#x27;New&#x27;, command=do_job) filemenu.add_command(label=&#x27;Open&#x27;, command=do_job) filemenu.add_command(label=&#x27;Save&#x27;, command=do_job) filemenu.add_separator() # 添加一条分隔线 filemenu.add_command(label=&#x27;Exit&#x27;, command=window.quit) # 用tkinter里面自带的quit()函数 # 第7步，创建一个Edit菜单项（默认不下拉，下拉内容包括Cut，Copy，Paste功能项） editmenu = tk.Menu(menubar, tearoff=0) # 将上面定义的空菜单命名为 Edit，放在菜单栏中，就是装入那个容器中 menubar.add_cascade(label=&#x27;Edit&#x27;, menu=editmenu) # 同样的在 Edit 中加入Cut、Copy、Paste等小命令功能单元，如果点击这些单元, 就会触发do_job的功能 editmenu.add_command(label=&#x27;Cut&#x27;, command=do_job) editmenu.add_command(label=&#x27;Copy&#x27;, command=do_job) editmenu.add_command(label=&#x27;Paste&#x27;, command=do_job) # 第8步，创建第二级菜单，即菜单项里面的菜单 submenu = tk.Menu(filemenu) # 和上面定义菜单一样，不过此处实在File上创建一个空的菜单 filemenu.add_cascade(label=&#x27;Import&#x27;, menu=submenu, underline=0) # 给放入的菜单submenu命名为Import # 第9步，创建第三级菜单命令，即菜单项里面的菜单项里面的菜单命令（有点拗口，笑~~~） submenu.add_command(label=&#x27;Submenu_1&#x27;, command=do_job) # 这里和上面创建原理也一样，在Import菜单项中加入一个小菜单命令Submenu_1 # 第11步，创建菜单栏完成后，配置让菜单栏menubar显示出来 window.config(menu=menubar) # 第12步，主窗口循环显示 window.mainloop()if __name__ == &quot;__main__&quot;: main() 测试效果：https://images2018.cnblogs.com/blog/1372069/201808/1372069-20180808224139791-265028894.gif 11. Frame 窗口部件 简单说明： Frame：框架，用来承载放置其他GUI元素，就是一个容器，是一个在 Windows 上分离小区域的部件, 它能将 Windows 分成不同的区,然后存放不同的其他部件. 同时一个 Frame 上也能再分成两个 Frame, Frame 可以认为是一种容器. 什么时候用： 在比如像软件或网页交互界面等，有不同的界面逻辑层级和功能区域划分时可以用到，让交互界面逻辑更加清晰。 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344# coding: utf-8# __author__ = &quot;HD&quot;# Date: 2020/3/16import tkinter as tk # 使用Tkinter前需要先导入def main(): # 第1步，实例化object，建立窗口window window = tk.Tk() # 第2步，给窗口的可视化起名字 window.title(&#x27;My Window&#x27;) # 第3步，设定窗口的大小(长 * 宽) window.geometry(&#x27;500x300&#x27;) # 这里的乘是小x # 第4步，在图形界面上创建一个标签用以显示内容并放置 tk.Label(window, text=&#x27;on the window&#x27;, bg=&#x27;red&#x27;, font=(&#x27;微软雅黑&#x27;, 16)).pack() # 和前面部件分开创建和放置不同，其实可以创建和放置一步完成 # 第5步，创建一个主frame，长在主window窗口上 frame = tk.Frame(window) frame.pack() # 第6步，创建第二层框架frame，长在主框架frame上面 frame_l = tk.Frame(frame)# 第二层frame，左frame，长在主frame上 frame_r = tk.Frame(frame)# 第二层frame，右frame，长在主frame上 frame_l.pack(side=&#x27;left&#x27;) frame_r.pack(side=&#x27;right&#x27;) # 第7步，创建三组标签，为第二层frame上面的内容，分为左区域和右区域，用不同颜色标识 tk.Label(frame_l, text=&#x27;on the frame_l1&#x27;, bg=&#x27;green&#x27;).pack() tk.Label(frame_l, text=&#x27;on the frame_l2&#x27;, bg=&#x27;green&#x27;).pack() tk.Label(frame_l, text=&#x27;on the frame_l3&#x27;, bg=&#x27;green&#x27;).pack() tk.Label(frame_r, text=&#x27;on the frame_r1&#x27;, bg=&#x27;yellow&#x27;).pack() tk.Label(frame_r, text=&#x27;on the frame_r2&#x27;, bg=&#x27;yellow&#x27;).pack() tk.Label(frame_r, text=&#x27;on the frame_r3&#x27;, bg=&#x27;yellow&#x27;).pack() # 第8步，主窗口循环显示 window.mainloop()if __name__ == &quot;__main__&quot;: main() 测试效果： 12. messageBox窗口部件 简单说明： messageBox：消息框，用于显示你应用程序的消息框。(Python2中为tkMessagebox)，其实这里的messageBox就是我们平时看到的弹窗。 我们首先需要定义一个触发功能，来触发这个弹窗，这里我们就放上以前学过的button按钮，通过触发功能，调用messagebox吧，点击button按钮就会弹出提示对话框。下面给出messagebox提示信息的几种形式： 123456tkinter.messagebox.showinfo(title=&#x27;Hi&#x27;, message=&#x27;你好！&#x27;) # 提示信息对话窗tkinter.messagebox.showwarning(title=&#x27;Hi&#x27;, message=&#x27;有警告！&#x27;) # 提出警告对话窗tkinter.messagebox.showerror(title=&#x27;Hi&#x27;, message=&#x27;出错了！&#x27;) # 提出错误对话窗print(tkinter.messagebox.askquestion(title=&#x27;Hi&#x27;, message=&#x27;你好！&#x27;)) # 询问选择对话窗return &#x27;yes&#x27;, &#x27;no&#x27;print(tkinter.messagebox.askyesno(title=&#x27;Hi&#x27;, message=&#x27;你好！&#x27;)) # return &#x27;True&#x27;, &#x27;False&#x27;print(tkinter.messagebox.askokcancel(title=&#x27;Hi&#x27;, message=&#x27;你好！&#x27;)) # return &#x27;True&#x27;, &#x27;False&#x27; 什么时候用： 在比如像软件或网页交互界面等，有不同的界面逻辑层级和功能区域划分时可以用到，让交互界面逻辑更加清晰。 示例代码： 123456789101112131415161718192021222324252627282930313233343536# coding: utf-8# __author__ = &quot;HD&quot;# Date: 2020/3/16import tkinter as tk # 使用Tkinter前需要先导入import tkinter.messagebox # 要使用messagebox先要导入模块def main(): # 第1步，实例化object，建立窗口window window = tk.Tk() # 第2步，给窗口的可视化起名字 window.title(&#x27;My Window&#x27;) # 第3步，设定窗口的大小(长 * 宽) window.geometry(&#x27;500x300&#x27;) # 这里的乘是小x # 第5步，定义触发函数功能 def hit_me(): tkinter.messagebox.showinfo(title=&#x27;Hi&#x27;, message=&#x27;你好！&#x27;) # 提示信息对话窗 # tkinter.messagebox.showwarning(title=&#x27;Hi&#x27;, message=&#x27;有警告！&#x27;) # 提出警告对话窗 # tkinter.messagebox.showerror(title=&#x27;Hi&#x27;, message=&#x27;出错了！&#x27;) # 提出错误对话窗 # print(tkinter.messagebox.askquestion(title=&#x27;Hi&#x27;, message=&#x27;你好！&#x27;)) # 询问选择对话窗return &#x27;yes&#x27;, &#x27;no&#x27; # print(tkinter.messagebox.askyesno(title=&#x27;Hi&#x27;, message=&#x27;你好！&#x27;)) # return &#x27;True&#x27;, &#x27;False&#x27; # print(tkinter.messagebox.askokcancel(title=&#x27;Hi&#x27;, message=&#x27;你好！&#x27;)) # return &#x27;True&#x27;, &#x27;False&#x27; # 第4步，在图形界面上创建一个标签用以显示内容并放置 tk.Button(window, text=&#x27;hit me&#x27;, bg=&#x27;green&#x27;, font=(&#x27;微软雅黑&#x27;, 14), command=hit_me).pack() # 第6步，主窗口循环显示 window.mainloop()if __name__ == &quot;__main__&quot;: main() 测试效果： 13. 窗口部件三种放置方式pack/grid/place 参考来源： The Grid Geometry ManagerThe Pack Geometry ManagerThe Place Geometry Manager 1. Grid：The Grid Geometry Manager grid 是方格, 所以所有的内容会被放在这些规律的方格中。例如： 123for i in range(3): for j in range(3): tk.Label(window, text=1).grid(row=i, column=j, padx=10, pady=10, ipadx=10, ipady=10) 以上的代码就是创建一个三行三列的表格，其实 grid 就是用表格的形式定位的。这里的参数 row 为行，colum 为列，padx 就是单元格左右间距，pady 就是单元格上下间距，ipadx是单元格内部元素与单元格的左右间距，ipady是单元格内部元素与单元格的上下间距。 示例代码： 12345678910111213141516171819202122232425262728# coding: utf-8# __author__ = &quot;HD&quot;# Date: 2020/3/16import tkinter as tk # 使用Tkinter前需要先导入def main(): # 第1步，实例化object，建立窗口window window = tk.Tk() # 第2步，给窗口的可视化起名字 window.title(&#x27;My Window&#x27;) # 第3步，设定窗口的大小(长 * 宽) window.geometry(&#x27;500x300&#x27;) # 这里的乘是小x # 第4步，grid 放置方法 for i in range(3): for j in range(3): tk.Label(window, text=1).grid(row=i, column=j, padx=10, pady=10, ipadx=10, ipady=10) # 第5步，主窗口循环显示 window.mainloop()if __name__ == &quot;__main__&quot;: main() 测试效果： 2. Pack：The Pack Geometry Manager 我们常用的pack(), 他会按照上下左右的方式排列.例如： 1234tk.Label(window, text=&#x27;P&#x27;, fg=&#x27;red&#x27;).pack(side=&#x27;top&#x27;) # 上tk.Label(window, text=&#x27;P&#x27;, fg=&#x27;red&#x27;).pack(side=&#x27;bottom&#x27;) # 下tk.Label(window, text=&#x27;P&#x27;, fg=&#x27;red&#x27;).pack(side=&#x27;left&#x27;) # 左tk.Label(window, text=&#x27;P&#x27;, fg=&#x27;red&#x27;).pack(side=&#x27;right&#x27;) # 右 示例代码： 1234567891011121314151617181920212223242526272829# coding: utf-8# __author__ = &quot;HD&quot;# Date: 2020/3/16import tkinter as tk # 使用Tkinter前需要先导入def main(): # 第1步，实例化object，建立窗口window window = tk.Tk() # 第2步，给窗口的可视化起名字 window.title(&#x27;My Window&#x27;) # 第3步，设定窗口的大小(长 * 宽) window.geometry(&#x27;500x300&#x27;) # 这里的乘是小x # 第4步，pack 放置方法 tk.Label(window, text=&#x27;P&#x27;, fg=&#x27;red&#x27;).pack(side=&#x27;top&#x27;) # 上 tk.Label(window, text=&#x27;P&#x27;, fg=&#x27;red&#x27;).pack(side=&#x27;bottom&#x27;) # 下 tk.Label(window, text=&#x27;P&#x27;, fg=&#x27;red&#x27;).pack(side=&#x27;left&#x27;) # 左 tk.Label(window, text=&#x27;P&#x27;, fg=&#x27;red&#x27;).pack(side=&#x27;right&#x27;) # 右 # 第5步，主窗口循环显示 window.mainloop()if __name__ == &quot;__main__&quot;: main() 测试效果： 3. Place：The Place Geometry Manager 再接下来我们来看place(), 这个比较容易理解，就是给精确的坐标来定位，如此处给的(50, 100)，就是将这个部件放在坐标为(x=50, y=100)的这个位置, 后面的参数 anchor=’nw’，就是前面所讲的锚定点是西北角。例如： 1tk.Label(window, text=&#x27;Pl&#x27;, font=(&#x27;微软雅黑&#x27;, 20), ).place(x=50, y=100, anchor=&#x27;nw&#x27;) 示例代码： 1234567891011121314151617181920212223242526# coding: utf-8# __author__ = &quot;HD&quot;# Date: 2020/3/16import tkinter as tk # 使用Tkinter前需要先导入def main(): # 第1步，实例化object，建立窗口window window = tk.Tk() # 第2步，给窗口的可视化起名字 window.title(&#x27;My Window&#x27;) # 第3步，设定窗口的大小(长 * 宽) window.geometry(&#x27;500x300&#x27;) # 这里的乘是小x # 第4步，place 放置方法（精准的放置到指定坐标点的位置上） tk.Label(window, text=&#x27;Pl&#x27;, font=(&#x27;微软雅黑&#x27;, 20), ).place(x=50, y=100, anchor=&#x27;nw&#x27;) # 第5步，主窗口循环显示 window.mainloop()if __name__ == &quot;__main__&quot;: main() 测试效果： 14. 综合练习，用户登录窗口例子 编写一个用户登录界面，用户可以登录账户信息，如果账户已经存在，可以直接登录，登录名或者登录密码输入错误会提示，如果账户不存在，提示用户注册，点击注册进去注册页面，输入注册信息，确定后便可以返回登录界面进行登录。 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138# coding: utf-8# __author__ = &quot;HD&quot;# Date: 2020/3/16import tkinter as tk # 使用Tkinter前需要先导入import tkinter.messageboximport pickledef main(): # 第1步，实例化object，建立窗口window window = tk.Tk() # 第2步，给窗口的可视化起名字 window.title(&#x27;Welcome to HD Website&#x27;) # 第3步，设定窗口的大小(长 * 宽) window.geometry(&#x27;400x300&#x27;) # 这里的乘是小x # 第4步，加载 wellcome image canvas = tk.Canvas(window, width=400, height=135, bg=&#x27;green&#x27;) image_file = tk.PhotoImage(file=&#x27;pic.gif&#x27;) image = canvas.create_image(200, 0, anchor=&#x27;n&#x27;, image=image_file) canvas.pack(side=&#x27;top&#x27;) tk.Label(window, text=&#x27;Welcome&#x27;, font=(&#x27;微软雅黑&#x27;, 16)).pack() # 第5步，用户信息 tk.Label(window, text=&#x27;User name:&#x27;, font=(&#x27;微软雅黑&#x27;, 14)).place(x=10, y=170) tk.Label(window, text=&#x27;Password:&#x27;, font=(&#x27;微软雅黑&#x27;, 14)).place(x=10, y=210) # 第6步，用户登录输入框entry # 用户名 var_usr_name = tk.StringVar() var_usr_name.set(&#x27;example@python.com&#x27;) entry_usr_name = tk.Entry(window, textvariable=var_usr_name, font=(&#x27;微软雅黑&#x27;, 14)) entry_usr_name.place(x=120,y=175) # 用户密码 var_usr_pwd = tk.StringVar() entry_usr_pwd = tk.Entry(window, textvariable=var_usr_pwd, font=(&#x27;微软雅黑&#x27;, 14), show=&#x27;*&#x27;) entry_usr_pwd.place(x=120,y=215) # 第8步，定义用户登录功能 def usr_login(): # 这两行代码就是获取用户输入的usr_name和usr_pwd usr_name = var_usr_name.get() usr_pwd = var_usr_pwd.get() # 这里设置异常捕获，当我们第一次访问用户信息文件时是不存在的，所以这里设置异常捕获。 # 中间的两行就是我们的匹配，即程序将输入的信息和文件中的信息匹配。 try: with open(&#x27;usrs_info.pickle&#x27;, &#x27;rb&#x27;) as usr_file: usrs_info = pickle.load(usr_file) except FileNotFoundError: # 这里就是我们在没有读取到`usr_file`的时候，程序会创建一个`usr_file`这个文件，并将管理员 # 的用户和密码写入，即用户名为`admin`密码为`admin`。 with open(&#x27;usrs_info.pickle&#x27;, &#x27;wb&#x27;) as usr_file: usrs_info = &#123;&#x27;admin&#x27;: &#x27;admin&#x27;&#125; pickle.dump(usrs_info, usr_file) usr_file.close() # 必须先关闭，否则pickle.load()会出现EOFError: Ran out of input # 如果用户名和密码与文件中的匹配成功，则会登录成功，并跳出弹窗how are you? 加上你的用户名。 if usr_name in usrs_info: if usr_pwd == usrs_info[usr_name]: tkinter.messagebox.showinfo(title=&#x27;Welcome&#x27;, message=&#x27;How are you? &#x27; + usr_name) # 如果用户名匹配成功，而密码输入错误，则会弹出&#x27;Error, your password is wrong, try again.&#x27; else: tkinter.messagebox.showerror(message=&#x27;Error, your password is wrong, try again.&#x27;) else: # 如果发现用户名不存在 is_sign_up = tkinter.messagebox.askyesno(&#x27;Welcome！ &#x27;, &#x27;You have not sign up yet. Sign up now?&#x27;) # 提示需不需要注册新用户 if is_sign_up: usr_sign_up() # 第9步，定义用户注册功能 def usr_sign_up(): def sign_to_HD_Website(): # 以下三行就是获取我们注册时所输入的信息 np = new_pwd.get() npf = new_pwd_confirm.get() nn = new_name.get() # 这里是打开我们记录数据的文件，将注册信息读出 with open(&#x27;usrs_info.pickle&#x27;, &#x27;rb&#x27;) as usr_file: exist_usr_info = pickle.load(usr_file) # 这里就是判断，如果两次密码输入不一致，则提示Error, Password and confirm password must be the same! if np != npf: tkinter.messagebox.showerror(&#x27;Error&#x27;, &#x27;Password and confirm password must be the same!&#x27;) # 如果用户名已经在我们的数据文件中，则提示Error, The user has already signed up! elif nn in exist_usr_info: tkinter.messagebox.showerror(&#x27;Error&#x27;, &#x27;The user has already signed up!&#x27;) # 最后如果输入无以上错误，则将注册输入的信息记录到文件当中，并提示注册成功Welcome！,You have successfully signed up!，然后销毁窗口。 else: exist_usr_info[nn] = np with open(&#x27;usrs_info.pickle&#x27;, &#x27;wb&#x27;) as usr_file: pickle.dump(exist_usr_info, usr_file) tkinter.messagebox.showinfo(&#x27;Welcome&#x27;, &#x27;You have successfully signed up!&#x27;) # 然后销毁窗口。 window_sign_up.destroy() # 定义长在窗口上的窗口 window_sign_up = tk.Toplevel(window) window_sign_up.geometry(&#x27;300x200&#x27;) window_sign_up.title(&#x27;Sign up window&#x27;) new_name = tk.StringVar() # 将输入的注册名赋值给变量 new_name.set(&#x27;example@python.com&#x27;) # 将最初显示定为&#x27;example@python.com&#x27; tk.Label(window_sign_up, text=&#x27;User name: &#x27;).place(x=10, y=10) # 将`User name:`放置在坐标（10,10）。 entry_new_name = tk.Entry(window_sign_up, textvariable=new_name) # 创建一个注册名的`entry`，变量为`new_name` entry_new_name.place(x=130, y=10) # `entry`放置在坐标（150,10）. new_pwd = tk.StringVar() tk.Label(window_sign_up, text=&#x27;Password: &#x27;).place(x=10, y=50) entry_usr_pwd = tk.Entry(window_sign_up, textvariable=new_pwd, show=&#x27;*&#x27;) entry_usr_pwd.place(x=130, y=50) new_pwd_confirm = tk.StringVar() tk.Label(window_sign_up, text=&#x27;Confirm password: &#x27;).place(x=10, y=90) entry_usr_pwd_confirm = tk.Entry(window_sign_up, textvariable=new_pwd_confirm, show=&#x27;*&#x27;) entry_usr_pwd_confirm.place(x=130, y=90) # 下面的 sign_to_HD_Website btn_comfirm_sign_up = tk.Button(window_sign_up, text=&#x27;Sign up&#x27;, command=sign_to_HD_Website) btn_comfirm_sign_up.place(x=180, y=120) # 第7步，login and sign up 按钮 btn_login = tk.Button(window, text=&#x27;Login&#x27;, command=usr_login) btn_login.place(x=120, y=240) btn_sign_up = tk.Button(window, text=&#x27;Sign up&#x27;, command=usr_sign_up) btn_sign_up.place(x=200, y=240) # 第10步，主窗口循环显示 window.mainloop()if __name__ == &quot;__main__&quot;: main() 测试效果： 注：不同电脑可能配置环境略有不同，如有小错误可以自己调试一下。 转载于:https://www.cnblogs.com/shwee/p/9427975.html","tags":[{"name":"Python","slug":"Python","permalink":"http://clarkhedi.github.io/tags/Python/"},{"name":"GUI","slug":"GUI","permalink":"http://clarkhedi.github.io/tags/GUI/"}]},{"title":"英语强化","date":"2019-05-13T19:01:43.000Z","path":"2019/05/13/ying-yu-xue-xi/","text":"Only two things in this world so that our souls are deeply shocked First, our brilliant stars overhead, First, our hearts lofty moral laws.这个世界惟有两样东西让我们的心灵感到深深的震撼,一是我们头顶上灿烂的星空,一是我们内心崇高的道德法则. 一. 英语口语句子 勤奋是真实的内涵 二. 英语四六级翻译必背 坚持是你唯一的胜利 1.计划生育 family planning 2.计划生育基本国策 the basic state policy of family planning 3.青才申文明建设 the construction of spiritual civilization 4.居委会 neighborhood committee 5.科教兴国 national rejuvenation through science and education 6.可持续发展 sustainable development 7.廉洁高效 honesty and high efficiency 8.两岸关系 cross-straits relations 9.两岸谈判 cross-straits negotiations 10.领土完整 territorial integrity 11.民族精神 national spirit 12.普选制 general election system 13.求同存异 seek common ground while shelving differences 14.人大代表 NPC member 15.物质文明和精神文明 material and spiritual civilization 16.小康社会 a well-off society 17.小康水平 a well-off standard 18.一个中国原则 the one-China principle 19.与时俱进 keep pace with the times 20.综合国力 overall national strength 21.共同愿望 common desire 22.“走出去(战略) going global 23.不结盟 non-alignment 24.单边主义 unilateralism 25.多边政策 multilateralism 26.多极世界 multipolar world 27.人口老龄化 aging of population 28.人口出生率 birth rate 29.社区月服务 community service 30.道德法庭 court of ethics 31.盗用公款 embezzlement 32.成人夜校 night school for adults 33.在职进修班 on-job training courses 34.政治思想教育 political and ideological edu-cation 35.毕业生分酉己 graduate placement; assign-ment of graduate 36.充电 update one’s knowledge 37.初等教育 elementary education 38.大学城 college town 39.大学社区 college community 40.高等教育 higher education 41.高等教育”211 工程” the “211 Project” forhigher education 42.高等学府 institution of higher education 43.综合性大学 comprehensive university 44.文科院校 colleges of (liberal) arts 45.理工科大学 college / university of scienceand engineering 46.师范学院 teachers’ college; normal college 47.高分低能 high scores and low abilities 48.高考 (university/college) entrance examination 49.高校扩招 the college expansion plan 50.教育界 education circle 51.教育投入 input in education 52.九年义务教育 nine-year compulsory education 53.考研 take the entrance exams for postgraduate schools 54.课外活动 extracurricular activities 55.必修课 required/compulsory course 56.选修课 elective/optional course 57.基础课 basic courses 58.专业课 specialized courses 59.课程表 school schedule 60.教学大纲 teaching program; syllabus 61.学习年限 period of schooling 62.学历 record of formal schooling 63.学分 credit 64.启发式教学 heuristic teaching 65.人才交流 talent exchange 66.人才战 competition for talented people 67.商务英语证书 Business English Certificate(BEC) 68.适龄儿童入学率 enrollment rate for children of school age 69.升学率 proportion of students enteringschools of a higher grade; enrollment rate 70.硕博连读 a continuous academic project that involves postgraduate and doctoral study 71.素质教育 quality-oriented education 72.填鸭式教学 cramming method of teaching 73.希望工程 Project Hope 74.走读生 extern; non-resident student 75.住宿生 boarder 76.研究生 graduate student; post graduate(student) 77.应届毕业生 graduating student; current year’s graduate 78.校园数字化 campus digitalization 校园文化 campus culture 79.学汉语热 enthusiasm in learning Chinese 80.学历教育 education with record of formal schooling 81.学龄儿重 school-ager 82.学前教育 preschool education 83.学生减负 alleviate the burden on students 84.应试教育 exam-oriented education 85.职业道德 work ethics; professional ethics 86.记者招待会 press conference 87.国家教委 State Education Commission 88.国家统计局 State Statistical Bureau 89.职业培训 job training 90.职业文盲 functional illiterate 91.智力引进 recruit/introduce (foreign) talents 92.智商 intelligence quotient (IQ) 93.助学行劫 activity to assist the impoverished students 94.网絡世界 cyber world 95.网絡文化 cyber culture 96.网絡犯罪 cyber crime 97.网上鈎物 online shopping 98.高产优质 high yield and high quality 99.高科技园 high-tech park 100.工业园区 industrial park 101.火炬计划 Torch Program (a plan to develop new and high technology) 102.信息港 info port 103.信息革命 information revolution 104.电子货币 e-currency 105.人エ智能 artificial intelligence (AI) 106.生物技术 bio-technology 107.克隆 cloning 108.基因工程 genetic engineering 109.转基因食品 genetically modified food (GM food) 110.试管婴儿 test-tube baby 111.基因突变 genetic mutation 112.网絡出版 e-publishing 113.三维电影 three-dimensional movie 114.光谷 optical valley 115.虚拟银行 virtual bank 116.信息化 informationization 117.信息高速公路 information superhighway 118.新兴学科 new branch of science; emerging discipline 119.纳米 nanometer 120.个人数字助理 personal digital assistant(PDA) 121.生态农业 environment-friendly agriculture 122.技术密集产品 technology- intensive product 123.数码科技 digital technology 124.同步卫星 geostationary satellite 125.神舟五号载人飞船 manned spacecraft Shenzhou V 126.风云二号气象卫星 Fengyun II meteorological satellite 127.登月舱 lunar module 128.多任务小卫星 small multi-mission satellite(SMMS) 129.多媒体短信服务 Multimedia Messaging Service (MMS) 130.电子商务 e-business; e-commerce 131.电子管理 e-management 132.办公自动化 Office Automation (OA) 133.信息高地 information highland 134.信息检索 information retrieval 135.电话会议 teleconference 136.无土栽培 soilless cultivation 137.超级杂交水稻 super-hybrid rice 138.科技发展 scientific and technological advancement 139.重点项目 key project 140.国家重点工程 national key projects 141.南水北调 South-to-North water diversion 142.西电东送 West- East electricity transmission project 143.西气东输 West- East natural gas transmission project 144.网络造谣 fabricating online rumors 145.恶意侵害他人名誉 maliciously harming the reputation of others 146.停止月服务 closure/shutdown of service 147.公司歇业 closure of business 148.道路封闭 road closure 149.人为操作差错 man-made operational mistakes 150.生态系统 ecosystem 151.森林生态系统 forest ecosystem 152.海洋生态系统 marine ecosystem 153.垄断价格 to monopolize the price 154.垄断市场 to monopolize/forestall/captive/corner the market 155.限购私用汽车 to curb the purchase of vehicles for private use 156.汽车限购 vehicle purchase restrictions 157.汽车购买配额 vehicle purchase quotas 158.车牌摇号 a lottery for license plates 159.牌照单双号限行 odd-even license plate system 160.黑名单制度 a blacklist system 161.执业医师 practicing physician; licensed doctors 162.二代身份证 2nd-generation ID cards 163.防伪技术 anti-forgery technology 164.非法交易 illegal transaction 165.冒名顶替 identification fraud 166.洗钱 money laundering 167.挂失 to report the loss 168.补办 to re-apply/post-register 169.户籍 household registration 170.居住证 residence permit 171.山洪暴发 flash floods 172.水位 water level 173.低洼地区 low-lying areas 174.淹没农田 to inundate crops 175.大桥蜂塌 bridge collapse 176.最严重受灾地区 worst-hit/worst-stricken area 177.直接经济损失 direct economic loss 178.应急系统 emergency response system 179.闯红灯 running red light 180.遮挡、污损号牌 blocking or defacing license plates 181.扣分处罚 point penalty 182.酒驾 drunk driving 183.终身禁驾 lifetime ban from driving","tags":[{"name":"记单词","slug":"记单词","permalink":"http://clarkhedi.github.io/tags/%E8%AE%B0%E5%8D%95%E8%AF%8D/"}]},{"title":"Linux中vim编辑器学习笔记","date":"2019-05-03T17:03:41.000Z","path":"2019/05/03/linux-zhong-vim-bian-ji-qi-xue-xi-bi-ji/","text":"Linux中vim编辑器学习笔记 **vim**是Linux是非常常用的编辑器，是编程达人的标志，也是编程开发中的神器之一。接下来，是我学习vim编辑器的一些笔记，总结如下： 首先：我们接触的vim编辑器一共有三种模式，分别为命令模式、编辑模式、末行模式。具体架构如下： 注意：命令模式只能输入命令,末行模式的功能是实现保存和退出的。 基本命令如下： 第一：命令模式&gt;&gt;编辑模式i:在光标之前输入 I:在行首进行输入 a:在光标后进行输入 A:在行末尾进行输入 o:在光标下一行进行输入 O:光标上一行进行输入 编辑模式&gt;&gt;命令模式按Esc即可 第二命令模式&gt;&gt;末行模式输入”:”即可（注意所有的命令必须是英文状态下的输入） 末行模式实现的功能是保存输入、退出vim等等 具体如下： w：保存编辑 q：退出vim q+!：不保存直接退出vim wq：保存退出vim 末行模式&gt;&gt;命令模式按Esc即可 对于命令模式还有许多常用命令接下来进行简单汇总命令模式下常用命令第一：命令行中的复制、剪切（删除）、粘贴、撤销、反撤销复制： yy：复制光标所在行； 4yy：复制从光标所在行开始往下的四行； 剪切： dd：剪切（删除）管标所在行； 4dd：剪切（删除）从光标所在行开始往下的四行； d+0(零)：从当前光标的前一位开始剪切到行首； D：从当前光标开始剪切至行尾。 粘贴： p：粘贴复制或者剪切的内容，如果剪切的内容没有进一步粘贴那么，就相当于删除。 删除： dd：剪切（删除）管标所在行； 4dd：剪切（删除）从光标所在行开始往下的四行； x：删除当前光标所在的位置，每次只删除光标所在字符 X：删除当前光标前一个所在的位置，每次只删除光标所在字符 dw：删除一个单词（以单词进行删除） 撤销： u：撤销之前的操作，一步一步撤销 反撤销： Ctrl+r: 反撤销 第二：命令行中的前后左右h：左 l：右 j：下 k：上 第三：命令行中的屏幕内容移动M：光标移动到到当前屏幕的中间 H：光标移动到当前屏幕的上方 L：光标移动到当前屏幕的下方 Ctrl+f：当前屏幕向下翻一页 Ctrl+b：当前屏幕向上翻一页 Ctrl+d：当前屏幕向下翻半页 Ctrl+u：当前屏幕向上翻半页 {：按照代码块向上跳 }：按照代码块向下跳 第四：命令行中的快速定位20G：快速跳到第20行所在的代码 G：快速跳到整个代码的最后一行 gg：快速跳转到整个代码的第一行 w：光标以单词为单位，向后跳，跳到下一个单词的第一个位置 b：光标以单词为单位，向前跳，跳到上一个单词的第一个位置 第五：命令行中的缩进或者反缩进方法一： 按下命令v &gt;&gt;&gt;&gt;&gt; 按命令j向下选中要缩进的行 &gt;&gt;&gt;&gt;&gt; 然后按下&gt;号进行缩进或者 按下&lt;进行反缩进 方法二： 按下命令V &gt;&gt;&gt;&gt;&gt; 按命令j向下选中要缩进的行 &gt;&gt;&gt;&gt;&gt; 然后按下&gt;号进行缩进或者 按下&lt;进行反缩进 注意：按下&gt;/&lt;号后，如果还要进行重复操作可以通过按下‘.’来执行。 第六：命令行中的搜索和替换r：先按下命令r，然后输入你要输入的内容，注意：只能替换光标所在的字符 R：先按下R命令，然后从当前光标开始替换，输入多少内容就替换多少字符 /money：搜索money所在的位置，找到后，光标会一定自动跳到money上 注意：因为找到money后，可能会有多个，这个时候可以使用n向下寻找，使用N向上寻找。 替换： :%s/print/out/g：将整个代码中的print用output替换 %20,25s/out/print/g：将20-25代码中的print用output替换 第七：命令行中的退出vim方法shift+zz：保存并且退出vim，和末行模式中的wq一致。 参考：Linux vi/vim | 菜鸟教程","tags":[{"name":"vim","slug":"vim","permalink":"http://clarkhedi.github.io/tags/vim/"}]},{"title":"Win10-anaconda与tensorflow_gpu 2.0/py37的安装教程与配置","date":"2019-04-22T19:09:27.000Z","path":"2019/04/22/win10-anaconda-yu-tensorflow-gpu-2.0py37-de-an-zhuang-jiao-cheng-yu-pei-zhi/","text":"Win10-anaconda与tensorflow_gpu 2.0/py37的安装教程与配置 Content：​ 1.首先安装anaconda ​ 2.创建一个环境，用来安装tensorflow2.0以及相关的python packages ​ 3.激活创建的环境，安装tensorflow2.0 gpu版本及cudnn,cudatoolkit numba ​ 4.测试是否安装成功 ​ 5.jupyter notebook中kernel的添加 ​ 6.福利：Tensorflow教程资源 1.首先安装anaconda点击anaconda进入官网下载根据电脑下载，我是下载的Windows64位下载完成后双击安装，点击Next点击I Agree点击Next由于anaconda很大有2.4G，所以我选择在了D盘，然后点击Next默认Install等待安装，然后Next最后Finish安装完成后找到如下图点击打开Anaconda Prompt输入python出现如下图说明anaconda安装完成了 然后配置下载源来使⽤国内镜像加速下载:(添加清华源，命令行中直接使用如下命令) 1234561.conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/2.conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge3.conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/#设置搜索时显示通道地址4.conda config --set show_channel_urls yes 2.创建一个环境，用来安装tensorflow2.0以及相关的python packages123#加上cudatoolkit and cudnn这样不论你的机器原来装的是否合适，都可以用tensorflow2.0gpu版本conda create -n tf2 python=3.7 #创建python=3.7版本的环境，取名叫tf2conda remove -n tf2 --all #删除环境（不要乱删啊啊啊） 要想安装gpu版本的同学，首先要查看自己的电脑CUDA driver version（驱动版本）：就是NVIDIA GPU的驱动程序版本，查看命令：nvidia-smi我们看到我的GPU的驱动程序版本是：388.73，所以我的电脑不能安装使用tensorflow-gpu 2.0,我win10上安装了tf2.0cpu版本，因为我的ubuntu18.04上我的GPU的驱动程序版本是：418.56所以在ubuntu18.04上安装了py3.7–tf_gpu-2.0.0a0—cuda10,cudnn7.3和py3.6–tf_gpu-1.13.1—cuda10,cudnn7.3两个环境 具体官方windows参考网https://tensorflow.google.cn/install/source_windows 官方Linux参考网https://tensorflow.google.cn/install/source CUDA、显卡驱动和Tensorflow版本之间的对应关系https://blog.csdn.net/IT_xiao_bai/article/details/88342921 CUDA版本官方文档对显卡驱动版本有要求，见如下链接。 https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html 3.激活创建的环境，安装tensorflow2.0 gpu版本及cudnn,cudatoolkit numba12345conda activate tf2 #激活环境conda deactivate #退出环境pip install tensorflow==2.0.0a0 #cpu版本pip install tensorflow_gpu==2.0.0a0 #gpu版本--cuda要10.0及以上conda install cudatoolkit=10.0 cudnn=7.3 numba #对于GPU版,安装对应版本的cudatoolkit和cudnn程序包 以上就完成了tensorflow2.0的安装 4.测试是否安装成功12345678910111213141516#输入python，进入python环境import tensorflow as tfprint(tf.__version__) #查看tensorflow版本#输出2.0.0-alpha0#测试GPU能否调用,先查看显卡使用情况import os os.system(&quot;nvidia-smi&quot;)#调用显卡@tf.functiondef f(): passf()#这时会打印好多日志，我电脑上还有warning，感觉不影响#再次查询显卡os.system(&quot;nvidia-smi&quot;) 5.jupyter notebook中kernel的添加很多使用jupyter的同学会遇到这样一个问题，在anaconda中创建了多个环境，启动jupyter notebook后，在new的下拉菜单中却找不到。本文就解决这样的问题。 1.解决方法 ​ anaconda默认的是python3，比如上面我创建了一个tf2的环境，但在Anaconda Prompt输入jupyter notebook打开jupyter notebook发现kernel只有python3可用，而我想使用tf2这个环境却找不到。 首先，在anaconda中切换到tf2环境下，确认是否安装了ipykernel这个包，如果没有则安装 12conda activate tf2 #进入tf2环境pip install ipykernel #安装ipykernel 然后，在这个环境下输入一下命令 12345678910# xxx是在jupyter中显示的名字，建议使用环境的名字，但是不一样也没关系# 我这里和环境名字一样，使用tf2这个名字python -m ipykernel install --name XXXX#比如我创建的tf2python -m ipykernel install --name tf2conda deactivate #退出tf2环境conda install cudatoolkit=10.0 cudnn=7.3 numba #对base启动jupyter notebook导入tf且不报错jupyter kernelspec list #查看安装的所以kerneljupyter kernelspec remove xxx #删除不想要的kernel 在jupyter notebook中安装扩展 1234561. pip install jupyter_contrib_nbextensions 或者 pip install https://github.com/ipython- contrib/jupyter_contrib_nbextensions/tarball/master2. jupyter contrib nbextension install --userpip install yapf #安装Code prettify需要的包 如图 打开jupyter notebook查看如下： 对于import tensorflow as tf排障可以参考https://blog.csdn.net/krrmjssf/article/details/82986647 2.遇到困难（选） ​ 在第二步中，linux环境下可能会遇到权限不足的问题，需要sudo权限。但是使用了sudo权限后，默认的python就不是环境中的python了，可以使用which python来查看。两个方法： 我们手动告知python的具体位置 12# 这里我们手动告知python的路径sudo /home/test/anaconda3/envs/tf2/bin/python -m ipykernel install --name tf2 改变系统默认的python，不推荐（已去掉） 6.福利：Tensorflow教程资源 适合初学者的Tensorflow教程和代码示例：https://github.com/aymericdamien/TensorFlow-Examples该教程不光提供了一些经典的数据集，更是从实现最简单的“Hello World”开始，到机器学习的经典算法，再到神经网络的常用模型，一步步带你从入门到精通，是初学者学习Tensorflow的最佳教程。 从Tensorflow基础知识到有趣的项目应用:https://github.com/pkmital/tensorflow_tutorials同样是适合新手的教程，从安装到项目实战，教你搭建一个属于自己的神经网络。 Tensorflow入门教程Github学习:https://github.com/amusi/TensorFlow-From-Zero-To-One","tags":[{"name":"Python","slug":"Python","permalink":"http://clarkhedi.github.io/tags/Python/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"http://clarkhedi.github.io/tags/TensorFlow/"}]},{"title":"CV领域Paper论文常见单词","date":"2019-04-20T20:38:13.000Z","path":"2019/04/20/cv-ling-yu-paper-lun-wen-chang-jian-dan-ci/","text":"Paper论文常见单词 CV领域论文常用单词,黑色标记的是论文中经常出现或是在论文中能反映出作者态度观点的重要单词,(毕竟paper也是一门写作课,需要讲究语言的艺术,而且程序员们是一种爱恨分明的动物,许多paper词汇用地很是口语化). 刚开始阅读CV和ML相关领域paper时,会遇到很多生词, 这些词可能在论文语境下有特殊的含义,因此整理了部分常见的单词： trivial 琐碎的，微不足道的(一般用否定形式) non-trivial意为重要的 bound 限制在 separate 分开的，单独的 counterfeit 伪造的 latent 潜在的 interaction 相互作用 prominent 重要的；著名的，突出的 scalar 标量 assign 确定 simultaneously 同时地 state of the art 当前最好的(炼丹侠们的目标) prohibitive 禁止的 analogous 类似的 optimum/optimal 最佳的；最适宜的条件 proposition 计划；主张；提议 saturate 饱和，充满 objective 目标 differentiate 区分，分开;求微分 region 区域 theorem 定理 semantic 语义的;意义 (划重点!) segmentation 分割 semantic segmentation 语义分割 substantial 显著的，重要的 substantially 相当多地 counteract 抵消；抵制 augment 增加 texture 结构，纹理 plausible 貌似合理的 alternatively 或者 alternative 可供替代的；n.选择 inherently 内在地，本质上地 external 外在的 state of art 最先进的 geometry 几何学 spark 启发 synthesis 合成；n.综合体 compression 压缩 wavelet 小波 deviation 偏差；[数]偏差 Standard Deviation 标准差 texture 结构，纹理，质地 synthetic 合成的,人工的 assessment 评价 property 特性 intriguing 引起兴趣的 quantization数字化 quantitative 定量分析的 give rise to 造成，导致 convergence 聚合，收敛 exclude 排除 intuitive 凭直觉的 suppression 抑制，阻碍 coordinate 坐标;套装 retrieve 取回，检索 harness 利用 denote 表示；意味着 redundancy 多余，冗余 overlap 重叠的 take into account 考虑到 context 背景；环境；上下文 contextual 上下文的，背景的 pixel-wise 像素级别 generic 一般的 propagation 传播 prototype 原型 topological 拓扑的 dilation 膨胀 dilation convolution 空洞卷积 derive 得出，导出 dramatically 显著地 inverse 相反的；逆 underdetermined 证据不足的,待定的 hierarchical 分级的 junction 汇合处；枢纽站 Norm 范数 Fisher matrix 费雪矩阵 KL-divergence KL散度 metric 度量标准 curvature 曲率，曲度 First-order 一阶 order为 阶数 的意思 conjugate gradient 共轭梯度 episode 一个事件；(美剧中的剧集常用该词汇) approximation 近似值 partition 划分 sparse 稀少的；稀疏的 decay 衰减；腐烂 redundant 被裁剪的；多余的 median 中等的；n.中位数 co-efficent 系数 fuse 融合 with respect to 至于；关于 manifold 多种多样的 adjacent 毗邻的，邻近的 ba cast to 被认为 blur 模糊 intractable 难对付的；倔强的 sidestep 回避；绕开 piece wise 分段的 analogous 相似的，可比拟的 adversarial 对抗的 overlap 重叠部分 modality 方式 distill 提取 cardiovascular 心血管的 anatomy 解剖学 promising 前景好的 hinder 阻碍，妨碍 manual 手工的 chamber 心室 annotation 注释 dense 浓密的，密集的 utility 实用的；实用程序；公共事业 interpolation 插补；插值 optional 可选择的 crop 修剪 incorporation 吸收；合并 ground truth alignments 标记数据集 silhouettes 轮廓 validation 认可 spatiotemporal 时空的 encapsulate 封装；概述 reside 属于；居住 bridge 弥补；跨越 exponentially 呈几何级数地 exponent 指数； cornerstone 基础，垫脚石 outline 提纲，梗概 residual 剩余的，残余的 explicitly 明确地；直接地 extremely 非常，极大地 model 模仿 utilize 利用 inferior 下级的；较差的 conceptually 概念上地 minor 较小的，轻微的 cascade 传递；层叠 accordance 依照 in accordance with 按照…规则 exploited 发挥；利用；开发 extent 范围；程度 threshold 门槛，阈值；下限；起征点 suppress 抑制；阻止 regime 政权，管理体制 stack 堆叠 evaluation 估计；评估(常用简写eval) surveillance 监视 lately 最近 ensemble 合奏曲；团体 spread over 分布，散开 convergence 汇聚，相交 factor 因素；因子 propose 提出 termed 被称为 in comparison to 与….相比 engineered 设计谋划的 chunk 大量的部分 replicated 复制的 keep track of 记录；保持联系 aforementioned 上述的 minor 较小的，轻微的 favorably 正面地；很好地 impractical 不现实的 scenario 设想的情况 methodology 方法 correspond to 相当于 rectified 修复 moderate 一般的；温和的；适当的 facilitate 促进，帮助；加快 aggregated 总的 scalable 可扩展的；大小可变的 besides 而且；此外 principally 主要的 pronounced 明显的，显著的 typically 典型的；一般的 sole 仅有的，唯一的 novel 新的，与众不同的 be prone to 易于…；有…倾向 complementary 互补的；辅助性的 incrementally 增长地 attribute to 归因于 effectiveness 有效性 is equivalent to 等同于 bandwidth 带宽 alleviate 缓解，减轻 ambiguity 模棱两可，不明之处 scheme 策略；方案 breathtaking 惊人的；非常激动人心的 cavern 大山洞；挖空 drift 漂流，流动 circularly 圆地；循环地 denote 表示；意味着 diagonalize 对角化 ridge 屋脊 consider 考虑到 objective 目标；客观的 resemblance 相似处 criteria/criterion 标准 holistic 全面的，整体的 perceptual 感觉上的 be subject to 受支配；易遭受 appealing 有吸引力的 paradigm 范例,范式 variants 变体；不同版本 pedestrian 行人(自动联想到行人重识别) mitigate 缓和 relatively 相对地 valid 合理的；符合逻辑的 address 处理 early 之前的 spread over 分散，传开 procedure 程序 is tuned to 被调整为 shallow 浅的；微弱的 decompose 分解 contiguous 毗邻的,邻近的；共同的 adjacent 毗连的，邻近的 sound 完整的 manner 方式 observe 观察；注意到；遵守 is comparable to 比得上 hypothesis 假说，假设 counterpart 对应物；相当的人 clarity 清晰；明确性 convention 惯例，公约 literature 文献 split 分开的 qualitative 性质的 exhibit 表现出 animation 动画片；动画制作技术 retain 保留，保持；记住 leverage 对…施加影响 contradict 与…矛盾；反驳 distract 转移注意力 impair 削弱；降低 surpass 超过 prioritization 优先考虑，优先顺序 slightly 略微 credit 声誉；信用 preference 偏爱 pulmonary 肺的(自动联想到医学图像) sensitively 谨慎周到地；善解人意地 nodule 瘤 (自动联想到医学图像) proceeding 进展；继续 clinically 客观地; 临床方式地 ensemble 全体,整体 considerably 相当多地 deploy 部署；有效利用 plane 平面 rich 丰富的 advent 出现，到来 foreground 前景 background 背景 isolation 隔离；孤立 purge 清除 mechanism 机制；途径；机械装置 readily 乐意地；容易地 collaboration 合作；合作成果 trade-off 权衡,做取舍(论文常见) conservative 传统的；保守的 computationally 计算上地 exclusive 独有的；独家报道 recover 追回；恢复 geometric 几何的 approach 接近；处理 dilemma 困境,进退两难 stabilize 使稳定 halve 减半 symmetric 对称的 be proportional to 与…成比例 middle 中间的 namely 即 polarized 偏振的；两极分化的 pipeline 管道,流水线;设计模式(简单点理解就是作者的方法) cubic 立方的；三次的 grain 纹理；颗粒,谷物 fine-grained 细粒度(简单理解为精细化的操作) contrast 差异；对比度 represent 代表；相当于 negligible 可忽略不计的 empirically 以经验为依据地 identical 相同的 expressive 生动的；有特殊意义的 definite 明确的 analogously 类似地；近似的 subsequently 随后 be sensitive to 对…敏感的 observed 观察到的 accommodate 适应 discipline 惩罚；纪律；学科 remainder 剩余的 invoke 唤起 fidelity 精度;保真度 matricy 度量标准 visually 在视觉上地 intrinsic 本身的；固有的 progressively 逐渐地 conducive 有助于 常见搭配be conducive to significantly 显著地 marginal 微不足道的;边缘的 (划重点!) scheme 计划；体系；阴谋 hypothesize 假设 remark 值得注意的点 be bound to 注定;一定要 refactor 重构 irrespective 无关的；不考虑的 asynchronous 异步的 (EE领域paper常见单词) handy 方便的；易于使用的 volatile 变化无常的,易变的；轻快的(此单词在pytorch中经常看到) deprecation 强烈不赞成(函数弃用warning会出现) compatible 相容的；和谐的；能共处的 identify 找到，返现；确认 to the point 中肯地；贴题 intuitive 凭直觉的；直观的,简单方便的 (划重点!) fashion 方法 pathological 病态的 thereby 因此 encouraging 令人鼓舞的 time-consuming 耗时的 in the context of 在…情况下；在….背景下 destructive 破坏性的；消极的 slack 懈怠的；松弛的(一款程序员聊天软件) intrinsically 本质上；真正的 deteriorate 恶化；变坏 transparent 透明的；显而易见的；坦白的 vulnerable 脆弱的；易受攻击的 mutation 转变；基因突变 aesthetic 美观的 versus prep.对抗；与…相对 blurry 模糊不清的 entail 导致；必须要 carry out 开展…. indispensable 必不可少的 retrieve 恢复；取回 additive 添加剂 hence 因此 term 条件，说法，措辞 resistance 抵抗，抵制 magnitude 重大，巨大；大小 temporal 时间的 latch 门闩；把…闩上 span 持续时间段 erase 消除，抹去 transmit 传播 assess 估算；评价 cover letter 求职信(投论文给杂志社写的自荐信) discrete 分离的 hamper 阻碍 precondition 先决条件；预处理 in real case 在实际案例中 asymptotically 渐进地 calibration 标定；校准 fringe 边缘 spectrum 光谱，频谱；范围 occupy 占用；占据 in the sense that 从这个意义上来说 of arbitrary 任意的 fluctuation 波动 faithfully 忠实地；如实地 conduction 电导；传导性 dominant 占优势的；统治的，支配的 is central to 是..关键 sophisticated 复杂的；精致的；有经验的 inference 推断 abstract 提取 concisely 简洁地 deploy 部署；有效利用 sane 神志正常的 recipe 处方，秘诀 infrastructure 基础设施 broad 明显的；宽阔的 derivation 引出,导出; 求导; 起源，由来 compatibility 适合；通用性 comprehensive 综合的；广泛的；用理解力的 preliminary 初步的；开端的 supplement 补充，增加 geometric 成几何级数增减的 justify 为…辩解 shed light on 为…提供线索；阐明…. by a large margin 大幅度 clinical 临床的；诊所的；简陋的 ethic 道德准则；行为准则 (投论文时就会看到这个单词(*^__^*)) vendor 小贩；供应商；卖方 confidential 秘密的，机密的；表示信任的 prevalent 流行的；普遍发生的 gain 增益 explanatory 解释的 bracket 把…括在一起；把…分类; n.括号 mandatory 强制的；命令的 proof 证明，校验 self-contained 独立的；自给自足的 substantive 真实的；独立的；重大的 discretion 慎重；判断力 guideline 指南；指导原则 increment 增量 overview 概述；回顾，复习 enclose 把…装入信封;把…围起来 remark 言论；注意的点 in a similar manner 以类似的方式 fractional 极小的 intentionally 有意地 ceaselessly 不停地，持续地 borne 推动；传达；承载 brood 沉思；焦虑的思考 imply 暗示；意味着 manifold 流行(流行空间和流行学习,一种机器学习方法,简单理解就是数据在不同维度的一些 运算) notorious 臭名昭著的；众所周知的 (用于diss之前存在的问题,从而印证自己算法的NB!) 加油！！！","tags":[{"name":"记单词","slug":"记单词","permalink":"http://clarkhedi.github.io/tags/%E8%AE%B0%E5%8D%95%E8%AF%8D/"}]},{"title":"OpenCV-Python学习笔记（一）","date":"2019-04-12T22:22:54.000Z","path":"2019/04/12/opencv-python-xue-xi-bi-ji-yi/","text":"OpenCV-Python学习笔记（一） 使用工具Python3.6.8 使用numpy;opencv;matplotlib 1. OpenCV的图像读取显示及保存1如果用的是64位系统，需将k&#x3D;cv2.waitKey(0)改k&#x3D;cv2.waitKey(0)&amp;0xff 12345678910import cv2img = cv2.imread(&#x27;08.jpg&#x27;,0)cv2.imshow(&#x27;img&#x27;,img) #运行显示图片如图output_1k = cv2.waitKey(0)&amp;0xff if k==27: cv2.destroyAllWindows()elif k==ord(&#x27;s&#x27;): cv2.imwrite(&#x27;08.png&#x27;,img) cv2.destroyAllWindows() 12345678import numpy as npimport cv2from matplotlib import pyplot as pltimg = cv2.imread(&#x27;08.jpg&#x27;,0)plt.imshow(img,cmap=&#x27;gray&#x27;,interpolation=&#x27;bicubic&#x27;)plt.xticks([]),plt.yticks([]) #to hide tick values on X and Y axisplt.show() #如图output_2 output_1:​ output_2：​ 2. OpenCV视频操作 学习阅读视频，显示视频和保存视频。 学习从摄像头捕捉并显示它。 您将学习这些功能：cv2.VideoCapture()，cv2.VideoWriter() 1、用摄像头捕获视频cv2.VideoCapture() ：0为默认计算机默认摄像头，1可以更换来源； 1234567891011121314151617import cv2cap = cv2.VideoCapture(0)while True: # capture frame-by-frame ret, frame = cap.read() # our operation on the frame come here gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #display the resulting frame cv2.imshow(&#x27;frame&#x27;, gray) if cv2.waitKey(1) &amp; 0xff == ord(&#x27;q&#x27;): # 按q键退出 break# when everything done , release the capturecap.release()cv2.destroyAllWindows() cap.read()返回一个布尔True/False。如果帧被正确读取，则为True。所以你可以通过检查这个返回值来检查视频的结束。 有时候，cap可能没有初始化捕获。在这种情况下，这段代码显示错误。你可以通过cap.isOpened()方法检查它是否被初始化。如果它是True，好的。否则使用cap.open()打开它。 您还可以使用cap.get(propId)方法访问此视频的某些功能，其中propId是一个从0到18的数字。每个数字表示视频的一个属性（如果该视频适用于该视频），详细信息可以在这里可以看到：属性标识符。其中一些值可以使用cap.set(propId，value)进行修改。 值是你想要的新值。 例如，其中一些值可以使用cap.set(propId,value)来修改，例如cap.get(3)和cap.get(4)来查看每一帧的宽和高，默认是640x480。我们可以使用ret=cap.set(3,320)和ret = cap.set(4,240)来把宽和高改成320x240。 2、从文件中播放视频把设备索引号改成文件名即可。在播放每一帧时，使用cv2.waitKey()适当持续时间，如果它太少，视频会非常快，如果它太高，视频会很慢（那么，这是如何以慢动作显示视频）。正常情况下，25ms即可。 12345678910111213import cv2cap = cv2.VideoCapture(&#x27;mm.avi&#x27;)while (cap.isOpened()): ret, frame = cap.read() gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) cv2.imshow(&#x27;frame&#x27;, gray) if cv2.waitKey(1) &amp; 0xff == ord(&#x27;q&#x27;): breakcap.release()cv2.destroyAllWindows() 代码中尝试修改视频流的一些属性： ​ ​ 3、保存视频所以我们拍摄一个视频，逐帧处理，我们要保存视频。对于图像来说，这非常简单，只是使用cv2.imwrite()。 但是视频需要更多的工作。 创建一个VideoWrite的对象，确定输出文件名，指定FourCC编码，播放频率和帧的大小，最后是isColor标签True为彩色。 FourCC是一个4字节码，用来确定视频的编码格式。 1、In Fedora : DIVX , XVID , MJPG , X264 , WMV1 , WMV2 XVID是最好的，MJPG是高尺寸视频，X264得到小尺寸视频 2、In Windows : DIVX 3、In OSX :不知道用什么好 设置FourCC格式时，原文里采用了·cv2.VideoWriter_fourcc()·这个函数，若运行程序的时候显示这个函数不存在，可以改用了·cv2.cv.CV_FOURCC·这个函数。 1234567891011121314151617181920212223242526import cv2cap = cv2.VideoCapture(0)# Define the codec and create VideoWriter objectfourcc = cv2.VideoWriter_fourcc(*&#x27;XVID&#x27;)out = cv2.VideoWriter(&#x27;output.avi&#x27;, fourcc, 20.0, (640, 480))while (cap.isOpened()): ret, frame = cap.read() if ret == True: frame = cv2.flip(frame, 1) #0--垂直翻转；1--水平翻转；-1--水平垂直翻转 # write the flipped frame out.write(frame) cv2.imshow(&#x27;frame&#x27;, frame) if cv2.waitKey(1) &amp; 0xFF == ord(&#x27;q&#x27;): break else: break# Release everything if job is finishedcap.release()out.release()cv2.destroyAllWindows()","tags":[{"name":"Python","slug":"Python","permalink":"http://clarkhedi.github.io/tags/Python/"},{"name":"OpenCV","slug":"OpenCV","permalink":"http://clarkhedi.github.io/tags/OpenCV/"}]}]
<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><link rel="stylesheet" type="text/css" href="//fonts.loli.net/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.5"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.5"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><link rel="stylesheet" type="text/css" href="https://unpkg.com/gitalk/dist/gitalk.css?v=2.0.5"><title>triplet-loss学习 | 我中意你23332</title><meta name="generator" content="Hexo 5.2.0"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">triplet-loss学习</h1><a id="logo" href="/.">我中意你23332</a><p class="description">Tomorrow comes never.</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="搜索"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">triplet-loss学习</h1><div class="post-meta"><a href="/2020/12/13/triplet-loss-xue-xi/#comments" class="comment-count"></a><p><span class="date">Dec 13, 2020</span><span><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="category">深度学习笔记</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><blockquote>
<p>一些参考资料：</p>
<p><a target="_blank" rel="noopener" href="https://www.jb51.net/article/189556.htm">torch.max/eq()…</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/hbu_pig/article/details/81454503">torch.expand/squeeze()…</a></p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/7e72cc1ab7a0">torch.contiguous()</a></p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/5d1f8cd5fe31">torch.gather()</a></p>
<p><a target="_blank" rel="noopener" href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/#loss-functions">loss funtion</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/u013082989/article/details/83537370">Triplet-Loss原理及其实现、应用</a></p>
<p><a target="_blank" rel="noopener" href="https://omoindrot.github.io/triplet-loss#batch-hard-strategy">batch-hard-strategy</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_32523711/article/details/103826600">PyTorch triphard代码理解</a></p>
</blockquote>
<img src="/2020/12/13/triplet-loss-xue-xi/image-20201202185243758.png" class="" title="image-20201202185243758">

<h3 id="三元组怎么挑选？"><a href="#三元组怎么挑选？" class="headerlink" title="三元组怎么挑选？"></a>三元组怎么挑选？</h3><h4 id="batch的形成-PK取样"><a href="#batch的形成-PK取样" class="headerlink" title="batch的形成/PK取样"></a>batch的形成/PK取样</h4><p>​    随机的从dataset中取样P个人、每个人取K张图片，比如P=16，K=4，则一个batch中有16*4=64张图片。</p>
<h4 id="构建三元组"><a href="#构建三元组" class="headerlink" title="构建三元组"></a>构建三元组</h4><p>​    由上面得到一个batch中的图片都经过网络提取特征，得到64个特征。接下来构建三元组：</p>
<ul>
<li>把每一个图片都当成anchor，总共可以选出64个三元组（其实按照排列组合可以选出很多三元组的，In defense of triplet loss这篇文章就只构建有代表性的64个三元组）</li>
<li>每个三元组的anchor选定后，positive从K-1个中选一个与anchor特征距离最远的样本，negative从P*K-K个中选一个与anchor特征距离最近的样本，这样子对这个anchor来说，选出来的positive和negative都是最困难的。这样组建了P*K个三元组，计算出P*K个triplet loss，把这些loss取平均进行反传。</li>
</ul>
<p>数据集迭代的过程是按照person id来循环的，假设数据集有751个id，一个batch取掉了16个id，这样经过<code>int(751/16)</code>个batch就循环了一次（一个epoch），接下来把id的顺序打乱，进行下一轮迭代（下一个epoch）。</p>
<h3 id="训练方法"><a href="#训练方法" class="headerlink" title="训练方法"></a>训练方法</h3><h4 id="offline"><a href="#offline" class="headerlink" title="offline"></a><code>offline</code></h4><ul>
<li>训练集<strong>所有数据</strong>经过计算得到对应的 <code>embeddings</code>, 可以得到 很多<code>&lt;i, j, k&gt;</code> 的三元组，然后再计算 <code>triplet loss</code></li>
<li>效率不高，因为需要过一遍所有的数据得到三元组，然后训练反向更新网络</li>
</ul>
<h4 id="online"><a href="#online" class="headerlink" title="online"></a><code>online</code></h4><ul>
<li>从训练集中抽取<code>B</code>个样本，然后计算 <code>B</code> 个<code>embeddings</code>，可以产生 B*B*B个 <code>triplets</code> （当然其中有不合法的，因为需要的是<code>&lt;a, p, n&gt;</code>）</li>
<li>实际使用中采用此方法，又分为两种策略 （是在一篇<strong>行人重识别</strong>的论文中提到的 <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1703.07737">In Defense of the Triplet Loss for Person Re-Identification</a>），假设 B = P*K , 其中<code>P</code>个身份的人，每个身份的人<code>K</code>张图片（一般<code>K</code> 取 <code>4</code>）<ul>
<li><code>Batch All</code>: 计算<code>batch_size</code>中所有<code>valid</code>的的<code>hard triplet</code> 和 <code>semi-hard triplet</code>， 然后取平均得到<code>Loss</code>。<ul>
<li>注意因为很多 <code>easy triplets</code>的情况，所以平均会导致<code>Loss</code>很小，所以是对所有 <strong>valid</strong> 的所有求平均。</li>
<li>可以产生 P K ( K − 1 ) ( P K − K ) 个 <code>triplets</code><ul>
<li><code>PK</code>个 <code>anchor</code></li>
<li><code>K-1</code> 个 <code>positive</code></li>
<li><code>PK-K</code> 个 <code>negative</code></li>
</ul>
</li>
</ul>
</li>
<li><code>Batch Hard</code>: 对于每一个<code>anchor</code>， 选择距离最大的<code>d(a, p)</code> 和 距离最小的 <code>d(a, n)</code><ul>
<li>共有 P K个 三元组<code>triplets</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="margin的选择？"><a href="#margin的选择？" class="headerlink" title="margin的选择？"></a>margin的选择？</h3><ul>
<li><p>当 margin 值越小时，loss 也就较容易的趋近于 0，于是 Anchor 与 Positive 都不需要拉的太近，Anchor 与 Negative 不需要拉的太远，就能使得 loss 很快的趋近于 0。这样训练得到的结果，不能够很好的区分相似的图像。</p>
</li>
<li><p>当 margin 值越大时，就需要使得网络参数要拼命地拉近 Anchor、Positive 之间的距离，拉远 Anchor、Negative 之间的距离。如果 margin 值设置的太大，很可能最后 loss 保持一个较大的值，难以趋近于 0 。</p>
</li>
</ul>
<h3 id="torch-nn-MarginRankingLoss"><a href="#torch-nn-MarginRankingLoss" class="headerlink" title="torch.nn.MarginRankingLoss()"></a>torch.nn.MarginRankingLoss()</h3><img src="/2020/12/13/triplet-loss-xue-xi/image-20201201211259123.png" class="" title="image-20201201211259123">

<p>两个<strong>N维向量</strong>之间的相似度，用于排序任务，该方法计算两组数据之间的差异，返回一个N*N的loss矩阵</p>
<img src="/2020/12/13/triplet-loss-xue-xi/image-20201201204030817.png" class="" title="image-20201201204030817">

<p><strong>y=1，希望x1比x2大，当x1&gt;x2时，不产生loss</strong></p>
<p><strong>y=-1，希望x1比x2小，当x2&gt;x1时，不产生loss</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">x1 = torch.tensor([[<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">x2 = torch.tensor([[<span class="number">2</span>], [<span class="number">2</span>], [<span class="number">2</span>]], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">target = torch.tensor([<span class="number">1</span>, <span class="number">1</span>, <span class="number">-1</span>], dtype=torch.<span class="built_in">float</span>)  <span class="comment">#这是y</span></span><br><span class="line">loss_f_none = nn.MarginRankingLoss(margin=<span class="number">0</span>, reduction=<span class="string">&#x27;none&#x27;</span>) <span class="comment"># margin ：边界值，reduction：计算模式</span></span><br><span class="line">loss = loss_f_none(x1, x2, target)</span><br><span class="line"><span class="comment"># y=-1 x1[2]=3  3-2 3-2 3-2 1 1 -1 ---&gt;0 0 1</span></span><br><span class="line"><span class="comment">#输出：</span></span><br><span class="line">loss:tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">1.</span>]])</span><br></pre></td></tr></table></figure>

<h3 id="torch-nn-SoftMarginLoss"><a href="#torch-nn-SoftMarginLoss" class="headerlink" title="torch.nn.SoftMarginLoss()"></a>torch.nn.SoftMarginLoss()</h3><img src="/2020/12/13/triplet-loss-xue-xi/image-20201201211337668.png" class="" title="image-20201201211337668">

<p><strong>二分类logistic损失：</strong></p>
<img src="/2020/12/13/triplet-loss-xue-xi/image-20201201204700095.png" class="" title="image-20201201204700095">

<p>其中，<code>x.nelement()</code>是<strong>平均值</strong>，<code>y=1或-1</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">inputs = torch.tensor([[<span class="number">0.3</span>, <span class="number">0.7</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>]])</span><br><span class="line">target = torch.tensor([[<span class="number">-1</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">-1</span>]], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line"></span><br><span class="line">loss_f = nn.SoftMarginLoss(reduction=<span class="string">&#x27;none&#x27;</span>)</span><br><span class="line">loss = loss_f(inputs, target)</span><br><span class="line"><span class="comment">#输出：</span></span><br><span class="line">SoftMargin:  tensor([[<span class="number">0.8544</span>, <span class="number">0.4032</span>],[<span class="number">0.4741</span>, <span class="number">0.9741</span>]])</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">idx = <span class="number">0</span></span><br><span class="line">inputs_i = inputs[idx, idx]</span><br><span class="line">target_i = target[idx, idx]</span><br><span class="line"></span><br><span class="line">loss_h = np.log(<span class="number">1</span> + np.exp(-target_i * inputs_i))</span><br><span class="line"><span class="comment">#输出：tensor(0.8544)</span></span><br></pre></td></tr></table></figure>



<hr>
<img src="/2020/12/13/triplet-loss-xue-xi/image-20201125155209931.png" class="" title="image-20201125155209931"></div><div class="post-copyright"><blockquote><p>原文作者: 贺同学</p><p>原文链接: <a href="http://clarkhedi.github.io/2020/12/13/triplet-loss-xue-xi/">http://clarkhedi.github.io/2020/12/13/triplet-loss-xue-xi/</a></p><p>版权声明: 转载请注明出处(必须保留原文作者署名原文链接)</p></blockquote></div><div class="tags"><a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/">损失函数</a></div><div class="post-share"><div class="social-share"><span>分享到:</span></div><div class="bdsharebuttonbox"><span style="float:left;line-height: 28px;height: 28px;font-size:16px;font-weight:blod">分享到:</span><a href="#" data-cmd="more" class="bds_more"></a><a href="#" data-cmd="mshare" title="分享到一键分享" class="bds_mshare"></a><a href="#" data-cmd="fbook" title="分享到Facebook" class="bds_fbook"></a><a href="#" data-cmd="twi" title="分享到Twitter" class="bds_twi"></a><a href="#" data-cmd="linkedin" title="分享到linkedin" class="bds_linkedin"></a><a href="#" data-cmd="youdao" title="分享到有道云笔记" class="bds_youdao"></a><a href="#" data-cmd="evernotecn" title="分享到印象笔记" class="bds_evernotecn"></a><a href="#" data-cmd="weixin" title="分享到微信" class="bds_weixin"></a><a href="#" data-cmd="qzone" title="分享到QQ空间" class="bds_qzone"></a><a href="#" data-cmd="tsina" title="分享到新浪微博" class="bds_tsina"></a></div></div><div class="post-nav"><a href="/2021/04/05/tensor-zhang-liang-jie-shao/" class="pre">Tensor（张量）介绍</a><a href="/2020/11/25/python-duo-xian-cheng-ru-men/" class="next">Python多线程入门</a></div><div id="comments"><div id="container"><script type="text/javascript" src="https://unpkg.com/gitalk/dist/gitalk.min.js?v=2.0.5"></script><script type="text/javascript" src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js?v=2.0.5"></script><script>var gitalk = new Gitalk({
  clientID: 'd6d4fb51a5284e4df5fd',
  clientSecret: '80ba8b4586bfce6df672e814df089b31e49a5549',
  repo: 'Gitalk',
  owner: 'clarkhedi',
  admin: ['clarkhedi'],
  id: md5(window.location.pathname),
  distractionFreeMode: false,
  language: 'zh-CN',
  pagerDirection: 'last'
})
gitalk.render('container')</script></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%89%E5%85%83%E7%BB%84%E6%80%8E%E4%B9%88%E6%8C%91%E9%80%89%EF%BC%9F"><span class="toc-text">三元组怎么挑选？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#batch%E7%9A%84%E5%BD%A2%E6%88%90-PK%E5%8F%96%E6%A0%B7"><span class="toc-text">batch的形成&#x2F;PK取样</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E4%B8%89%E5%85%83%E7%BB%84"><span class="toc-text">构建三元组</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%96%B9%E6%B3%95"><span class="toc-text">训练方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#offline"><span class="toc-text">offline</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#online"><span class="toc-text">online</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#margin%E7%9A%84%E9%80%89%E6%8B%A9%EF%BC%9F"><span class="toc-text">margin的选择？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#torch-nn-MarginRankingLoss"><span class="toc-text">torch.nn.MarginRankingLoss()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#torch-nn-SoftMarginLoss"><span class="toc-text">torch.nn.SoftMarginLoss()</span></a></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2022/11/18/hexo-start/">Hexo Start</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/16/ge-xing-hua-ding-zhi-ni-de-github-zhu-ye/">2021年，教程 | 个性化定制你的 GitHub 主页</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/07/you-mei-de-sublime-text/">优美的Sublime Text</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/05/08/pyqt5-xue-xi-bi-ji-yi/">PyQt5学习笔记（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/17/kaiming-he-chu-shi-hua-de-xue-xi/">Kaiming He初始化的学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/05/autograd-yu-luo-ji-hui-gui/">autograd与逻辑回归</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/05/ji-suan-tu-yu-dong-tai-tu-ji-zhi/">计算图与动态图机制</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/05/zhang-liang-cao-zuo-yu-xian-xing-hui-gui/">张量操作与线性回归</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/05/tensor-zhang-liang-jie-shao/">Tensor（张量）介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/13/triplet-loss-xue-xi/">triplet-loss学习</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/GitHub%E5%AD%A6%E4%B9%A0/">GitHub学习</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo%E5%AD%A6%E4%B9%A0/">Hexo学习</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Jupyter%E8%AF%AD%E6%B3%95/">Jupyter语法</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux%E5%AD%A6%E4%B9%A0/">Linux学习</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/OpenCV-Python%E6%89%8B%E8%AE%B0/">OpenCV-Python手记</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">Python学习笔记</a><span class="category-list-count">8</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/PyQt5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">PyQt5学习笔记</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">Pytorch学习笔记</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%86%E7%B1%BB%E6%8A%80%E6%9C%AF/">分类技术</a><span class="category-list-count">14</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%86%E7%B1%BB%E6%8A%80%E6%9C%AF/LBP%E5%AD%A6%E4%B9%A0/">LBP学习</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%86%E7%B1%BB%E6%8A%80%E6%9C%AF/SVM%E5%85%AB%E8%82%A1/">SVM八股</a><span class="category-list-count">10</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">图像处理学习笔记</a><span class="category-list-count">7</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%AB/">车牌识别</a><span class="category-list-count">7</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AE%9E%E9%AA%8C%E6%A5%BC%E5%AD%A6%E4%B9%A0/">实验楼学习</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9D%82%E9%A1%B9/">杂项</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E8%B8%A9%E5%9D%91/">环境搭建踩坑</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/">英语学习</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">论文学习笔记</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/CLBP/" style="font-size: 15px;">CLBP</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">论文学习</a> <a href="/tags/vim/" style="font-size: 15px;">vim</a> <a href="/tags/OpenCV/" style="font-size: 15px;">OpenCV</a> <a href="/tags/PyQt5/" style="font-size: 15px;">PyQt5</a> <a href="/tags/GUI/" style="font-size: 15px;">GUI</a> <a href="/tags/%E8%AE%B0%E5%8D%95%E8%AF%8D/" style="font-size: 15px;">记单词</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/TensorFlow/" style="font-size: 15px;">TensorFlow</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 15px;">损失函数</a> <a href="/tags/GitHub/" style="font-size: 15px;">GitHub</a> <a href="/tags/Resume/" style="font-size: 15px;">Resume</a> <a href="/tags/LBP/" style="font-size: 15px;">LBP</a> <a href="/tags/LPR/" style="font-size: 15px;">LPR</a> <a href="/tags/Numpy/" style="font-size: 15px;">Numpy</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/">2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/">2021</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/">2020</a><span class="archive-list-count">36</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/">2019</a><span class="archive-list-count">5</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-you"> 友情链接</i></div><ul></ul><a href="https://github.com/chaooo/hexo-theme-BlueLake" title="BlueLake主题" target="_blank">BlueLake主题</a><ul></ul><a href="https://mp.weixin.qq.com/s?__biz=MzIyNjM2MzQyNg==&amp;mid=2247484443&amp;idx=1&amp;sn=7110e42ef9e95a8c16064dde5b897960&amp;chksm=e870d556df075c4053a90d207c078e5fe965b5f9004de7f34dee09fccf1a37977aa3860b3a96&amp;mpshare=1&amp;scene=23&amp;srcid=0428XfRkvl0HsaHMU71k04dq#rd" title="重磅|完备的AI学习路线,最详细的资源整理！" target="_blank">重磅|完备的AI学习路线,最详细的资源整理！</a><ul></ul><a href="https://mp.weixin.qq.com/s?__biz=MzI5NDY1MjQzNA==&amp;mid=2247489096&amp;idx=1&amp;sn=ca2e1d72c9decd021c0365cc9e93a539&amp;chksm=ec5ec935db2940237482c5581b7a45f2bd50b138efa6488ed9b942c182486a4e74131e9af523&amp;mpshare=1&amp;scene=23&amp;srcid=#rd" title="推荐|机器学习入门方法和资料合集" target="_blank">推荐|机器学习入门方法和资料合集</a><ul></ul><a href="https://mp.weixin.qq.com/s?__biz=MzU4NTY4Mzg1Mw==&amp;mid=100000497&amp;idx=1&amp;sn=96cc795f1c22f7da2f3260d4ea364ff3&amp;chksm=7d8784134af00d05e41da36475bca417851535ed9710c7bd44ae7365cf40857015d922671c95&amp;mpshare=1&amp;scene=23&amp;srcid=04138MekLgFi3vNAz2E2rTrv#rd" title="良心推荐：机器学习入门资料汇总及学习建议（2018版）" target="_blank">良心推荐：机器学习入门资料汇总及学习建议（2018版）</a><ul></ul><a href="https://mp.weixin.qq.com/s?__biz=MzA3NDIyMjM1NA==&amp;mid=2649032678&amp;idx=1&amp;sn=7ce30241f24dae790f7361173132ee04&amp;chksm=8712b99bb065308d6626ac71d358d386199f5fdcc0d20f48b9ff7f7f84f32892325075413d78&amp;mpshare=1&amp;scene=1&amp;srcid=1213VnRvWgKRhAswA6qj9C6U&amp;sharer_sharetime=1607823235596&amp;sharer_shareid=6f3d2b6e1888cc6674af1cb9d8f856b5&amp;key=94e16379e8fc498f20603adf1c7c1474460f32c861df423924a01860bf66b23e3b54ec715f59513ed57f7be44b91602324165303caa8015279359147bf99dc0ac5c9482bbf323df6415707db1df1dbb44795972834805221b6810c0783bc61213b424afc1f9c747d8eddfe17782e3165ddfff5144eff7867ea82ee34ab2e6e44&amp;ascene=1&amp;uin=MzMyMzAzNzE5OA%3D%3D&amp;devicetype=Windows+10+x64&amp;version=6300002f&amp;lang=en&amp;exportkey=A%2Fn4vOWzACQbiXdS3ts1%2BmU%3D&amp;pass_ticket=X0sXcXVfthe9ne%2BkdsNidLJDaUos8pPBg0qSPgQJE8kY3CQmybx%2FB2TVL1w9Glu6&amp;wx_header=0" title="深度学习CV算法工程师从入门到初级面试" target="_blank">深度学习CV算法工程师从入门到初级面试</a></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">网站地图</a> |  <a href="/atom.xml">订阅本站</a> |  <a href="/about/">联系博主</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次，本站总访客数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人</p><p><span> Copyright &copy;<a href="/." rel="nofollow">贺同学.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a target="_blank" rel="noopener" href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.json.js?v=2.0.5"></script><div id="fullscreen-img" class="hide"><span class="close"></span></div><script type="text/javascript" src="/js/imgview.js?v=2.0.5" async></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.5" async></script><link rel="stylesheet" type="text/css" href="/share/css/share.css"><script type="text/javascript" src="/share/js/social-share.js" charset="utf-8"></script><script type="text/javascript" src="/share/js/qrcode.js" charset="utf-8"></script><script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":["mshare","weixin","tsina","qzone","linkedin","fbook","twi","print","renren","sqq","evernotecn","bdysc","tqq","tqf","bdxc","kaixin001","tieba","douban","bdhome","thx","ibaidu","meilishuo","mogujie","diandian","huaban","duitang","hx","fx","youdao","sdo","qingbiji","people","xinhua","mail","isohu","yaolan","wealink","ty","iguba","h163","copy"],"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"]}};with(document)0[(getElementsByTagName('head')[0]||head).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script></body></html>
<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><link rel="stylesheet" type="text/css" href="//fonts.loli.net/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.5"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.5"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><link rel="stylesheet" type="text/css" href="https://unpkg.com/gitalk/dist/gitalk.css?v=2.0.5"><title>SVM入门（八）松弛变量 | 我中意你23332</title><meta name="generator" content="Hexo 5.2.0"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">SVM入门（八）松弛变量</h1><a id="logo" href="/.">我中意你23332</a><p class="description">Tomorrow comes never.</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="搜索"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">SVM入门（八）松弛变量</h1><div class="post-meta"><a href="/2020/07/06/svm-ru-men-ba-song-chi-bian-liang/#comments" class="comment-count"></a><p><span class="date">Jul 06, 2020</span><span><a href="/categories/%E5%88%86%E7%B1%BB%E6%8A%80%E6%9C%AF/" class="category">分类技术</a><a href="/categories/%E5%88%86%E7%B1%BB%E6%8A%80%E6%9C%AF/SVM%E5%85%AB%E8%82%A1/" class="category">SVM八股</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><p>现在我们已经把一个本来线性不可分的文本分类问题，通过映射到高维空间而变成了线性可分的。就像下图这样：<img src="/2020/07/06/svm-ru-men-ba-song-chi-bian-liang/image_thumb.png" class="">  </p>
<p>圆形和方形的点各有成千上万个（毕竟，这就是我们训练集中文档的数量嘛，当然很大了）。现在想象我们有另一个训练集，只比原先这个训练集多了一篇文章，映射到高维空间以后（当然，也使用了相同的核函数），也就多了一个样本点，但是这个样本的位置是这样的：<img src="/2020/07/06/svm-ru-men-ba-song-chi-bian-liang/image_thumb_1.png" class=""> </p>
<p>就是图中黄色那个点，它是方形的，因而它是负类的一个样本，这单独的一个样本，使得原本线性可分的问题变成了线性不可分的。这样类似的问题（仅有少数点线性不可分）叫做“近似线性可分”的问题。</p>
<p>以我们人类的常识来判断，说有一万个点都符合某种规律（因而线性可分），有一个点不符合，那这一个点是否就代表了分类规则中我们没有考虑到的方面呢（因而规则应该为它而做出修改）？</p>
<p>其实我们会觉得，更有可能的是，这个样本点压根就是错误，是噪声，是提供训练集的同学人工分类时一打瞌睡错放进去的。所以我们会简单的忽略这个样本点，仍然使用原来的分类器，其效果丝毫不受影响。</p>
<p>但这种对噪声的容错性是人的思维带来的，我们的程序可没有。由于我们原本的优化问题的表达式中，确实要考虑所有的样本点（不能忽略某一个，因为程序它怎么知道该忽略哪一个呢？），在此基础上寻找正负类之间的最大几何间隔，而几何间隔本身代表的是距离，是非负的，像上面这种有噪声的情况会使得整个问题无解。这种解法其实也叫做“硬间隔”分类法，因为他硬性的要求所有样本点都满足和分类平面间的距离必须大于某个值。</p>
<p>因此由上面的例子中也可以看出，硬间隔的分类法其结果容易受少数点的控制，这是很危险的（尽管有句话说真理总是掌握在少数人手中，但那不过是那一小撮人聊以自慰的词句罢了，咱还是得民主）。</p>
<p>但解决方法也很明显，就是仿照人的思路，允许一些点到分类平面的距离不满足原先的要求。由于不同的训练集各点的间距尺度不太一样，因此用间隔（而不是几何间隔）来衡量有利于我们表达形式的简洁。我们原先对样本点的要求是：<img src="/2020/07/06/svm-ru-men-ba-song-chi-bian-liang/clip_image002_thumb.gif" class="">                                                                                     </p>
<p>意思是说离分类面最近的样本点函数间隔也要比1大。如果要引入容错性，就给1这个硬性的阈值加一个松弛变量，即允许 <img src="/2020/07/06/svm-ru-men-ba-song-chi-bian-liang/clip_image002%5B5%5D_thumb.gif" class="">            </p>
<p>因为松弛变量是非负的，因此最终的结果是要求间隔可以比1小。但是当某些点出现这种间隔比1小的情况时（这些点也叫离群点），意味着我们放弃了对这些点的精确分类，而这对我们的分类器来说是种损失。但是放弃这些点也带来了好处，那就是使分类面不必向这些点的方向移动，因而可以得到更大的几何间隔（在低维空间看来，分类边界也更平滑）。显然我们必须权衡这种损失和好处。好处很明显，我们得到的分类间隔越大，好处就越多。回顾我们原始的硬间隔分类对应的优化问题：<img src="/2020/07/06/svm-ru-men-ba-song-chi-bian-liang/clip_image002%5B7%5D_thumb.gif" class="">                  </p>
<p>||w||2就是我们的目标函数（当然系数可有可无），希望它越小越好，因而损失就必然是一个能使之变大的量（能使它变小就不叫损失了，我们本来就希望目标函数值越小越好）。那如何来衡量损失，有两种常用的方式，有人喜欢用 <img src="/2020/07/06/svm-ru-men-ba-song-chi-bian-liang/clip_image002%5B9%5D_thumb.gif" class="">  </p>
<p>而有人喜欢用 <img src="/2020/07/06/svm-ru-men-ba-song-chi-bian-liang/clip_image002%5B11%5D_thumb.gif" class=""></p>
<p>其中l都是样本的数目。两种方法没有大的区别。如果选择了第一种，得到的方法的就叫做二阶软间隔分类器，第二种就叫做一阶软间隔分类器。把损失加入到目标函数里的时候，就需要一个<code>惩罚因子</code>（cost，也就是libSVM的诸多参数中的C），原来的优化问题就变成了下面这样：<img src="/2020/07/06/svm-ru-men-ba-song-chi-bian-liang/clip_image002%5B13%5D_thumb.gif" class=""></p>
<p>这个式子有这么几点要注意：</p>
<p>一是并非所有的样本点都有一个松弛变量与其对应。实际上只有“离群点”才有，或者也可以这么看，所有没离群的点松弛变量都等于0（对负类来说，离群点就是在前面图中，跑到H2右侧的那些负样本点，对正类来说，就是跑到H1左侧的那些正样本点）。</p>
<p>二是松弛变量的值实际上标示出了对应的点到底离群有多远，值越大，点就越远。</p>
<p>三是惩罚因子C决定了你有多重视离群点带来的损失，显然当所有离群点的松弛变量的和一定时，你定的C越大，对目标函数的损失也越大，此时就暗示着你非常不愿意放弃这些离群点，最极端的情况是你把C定为无限大，这样只要稍有一个点离群，目标函数的值马上变成无限大，马上让问题变成无解，这就退化成了硬间隔问题。</p>
<p>四是惩罚因子C不是一个变量，整个优化问题在解的时候，C是一个你必须事先指定的值，指定这个值以后，解一下，得到一个分类器，然后用测试数据看看结果怎么样，如果不够好，换一个C的值，再解一次优化问题，得到另一个分类器，再看看效果，如此就是一个参数寻优的过程，但这和优化问题本身决不是一回事，优化问题在解的过程中，C一直是定值，要记住。</p>
<p>五是尽管加了松弛变量这么一说，但这个优化问题仍然是一个优化问题（汗，这不废话么），解它的过程比起原始的硬间隔问题来说，没有任何更加特殊的地方。</p>
<p>从大的方面说优化问题解的过程，就是先试着确定一下w，也就是确定了前面图中的三条直线，这时看看间隔有多大，又有多少点离群，把目标函数的值算一算，再换一组三条直线（你可以看到，分类的直线位置如果移动了，有些原来离群的点会变得不再离群，而有的本来不离群的点会变成离群点），再把目标函数的值算一算，如此往复（迭代），直到最终找到目标函数最小时的w。</p>
<p>啰嗦了这么多，读者一定可以马上自己总结出来，松弛变量也就是个解决线性不可分问题的方法罢了，但是回想一下，核函数的引入不也是为了解决线性不可分的问题么？为什么要为了一个问题使用两种方法呢？</p>
<p>其实两者还有微妙的不同。一般的过程应该是这样，还以文本分类为例。在原始的低维空间中，样本相当的不可分，无论你怎么找分类平面，总会有大量的离群点，此时用核函数向高维空间映射一下，虽然结果仍然是不可分的，但比原始空间里的要更加接近线性可分的状态（就是达到了近似线性可分的状态），此时再用松弛变量处理那些少数“冥顽不化”的离群点，就简单有效得多啦。</p>
<p>本节中的（式1）也确实是支持向量机最最常用的形式。至此一个比较完整的支持向量机框架就有了，简单说来，支持向量机就是使用了核函数的软间隔线性分类法。</p>
<p>下一节会说说松弛变量剩下的一点点东西，顺便搞个读者调查，看看大家还想侃侃SVM的哪些方面。</p>
<hr>
<img src="/2020/07/06/svm-ru-men-ba-song-chi-bian-liang/hi.png" class="">







</div><div class="post-copyright"><blockquote><p>原文作者: 贺同学</p><p>原文链接: <a href="http://clarkhedi.github.io/2020/07/06/svm-ru-men-ba-song-chi-bian-liang/">http://clarkhedi.github.io/2020/07/06/svm-ru-men-ba-song-chi-bian-liang/</a></p><p>版权声明: 转载请注明出处(必须保留原文作者署名原文链接)</p></blockquote></div><div class="tags"><a href="/tags/SVM/">SVM</a></div><div class="post-share"><div class="social-share"><span>分享到:</span></div><div class="bdsharebuttonbox"><span style="float:left;line-height: 28px;height: 28px;font-size:16px;font-weight:blod">分享到:</span><a href="#" data-cmd="more" class="bds_more"></a><a href="#" data-cmd="mshare" title="分享到一键分享" class="bds_mshare"></a><a href="#" data-cmd="fbook" title="分享到Facebook" class="bds_fbook"></a><a href="#" data-cmd="twi" title="分享到Twitter" class="bds_twi"></a><a href="#" data-cmd="linkedin" title="分享到linkedin" class="bds_linkedin"></a><a href="#" data-cmd="youdao" title="分享到有道云笔记" class="bds_youdao"></a><a href="#" data-cmd="evernotecn" title="分享到印象笔记" class="bds_evernotecn"></a><a href="#" data-cmd="weixin" title="分享到微信" class="bds_weixin"></a><a href="#" data-cmd="qzone" title="分享到QQ空间" class="bds_qzone"></a><a href="#" data-cmd="tsina" title="分享到新浪微博" class="bds_tsina"></a></div></div><div class="post-nav"><a href="/2020/07/06/svm-ru-men-jiu-song-chi-bian-liang-xu/" class="pre">SVM入门（九）松弛变量（续）</a><a href="/2020/07/06/svm-ru-men-qi-wei-he-xu-yao-he-han-shu/" class="next">SVM入门（七）为何需要核函数</a></div><div id="comments"><div id="container"><script type="text/javascript" src="https://unpkg.com/gitalk/dist/gitalk.min.js?v=2.0.5"></script><script type="text/javascript" src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js?v=2.0.5"></script><script>var gitalk = new Gitalk({
  clientID: 'd6d4fb51a5284e4df5fd',
  clientSecret: '80ba8b4586bfce6df672e814df089b31e49a5549',
  repo: 'Gitalk',
  owner: 'clarkhedi',
  admin: ['clarkhedi'],
  id: md5(window.location.pathname),
  distractionFreeMode: false,
  language: 'zh-CN',
  pagerDirection: 'last'
})
gitalk.render('container')</script></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2022/11/18/hexo-start/">Hexo Start</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/16/ge-xing-hua-ding-zhi-ni-de-github-zhu-ye/">2021年，教程 | 个性化定制你的 GitHub 主页</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/07/you-mei-de-sublime-text/">优美的Sublime Text</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/05/08/pyqt5-xue-xi-bi-ji-yi/">PyQt5学习笔记（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/17/kaiming-he-chu-shi-hua-de-xue-xi/">Kaiming He初始化的学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/05/autograd-yu-luo-ji-hui-gui/">autograd与逻辑回归</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/05/ji-suan-tu-yu-dong-tai-tu-ji-zhi/">计算图与动态图机制</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/05/zhang-liang-cao-zuo-yu-xian-xing-hui-gui/">张量操作与线性回归</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/05/tensor-zhang-liang-jie-shao/">Tensor（张量）介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/13/triplet-loss-xue-xi/">triplet-loss学习</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/GitHub%E5%AD%A6%E4%B9%A0/">GitHub学习</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo%E5%AD%A6%E4%B9%A0/">Hexo学习</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Jupyter%E8%AF%AD%E6%B3%95/">Jupyter语法</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux%E5%AD%A6%E4%B9%A0/">Linux学习</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/OpenCV-Python%E6%89%8B%E8%AE%B0/">OpenCV-Python手记</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">Python学习笔记</a><span class="category-list-count">8</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/PyQt5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">PyQt5学习笔记</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">Pytorch学习笔记</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%86%E7%B1%BB%E6%8A%80%E6%9C%AF/">分类技术</a><span class="category-list-count">14</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%86%E7%B1%BB%E6%8A%80%E6%9C%AF/LBP%E5%AD%A6%E4%B9%A0/">LBP学习</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%86%E7%B1%BB%E6%8A%80%E6%9C%AF/SVM%E5%85%AB%E8%82%A1/">SVM八股</a><span class="category-list-count">10</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">图像处理学习笔记</a><span class="category-list-count">7</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%AB/">车牌识别</a><span class="category-list-count">7</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AE%9E%E9%AA%8C%E6%A5%BC%E5%AD%A6%E4%B9%A0/">实验楼学习</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9D%82%E9%A1%B9/">杂项</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E8%B8%A9%E5%9D%91/">环境搭建踩坑</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/">英语学习</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">论文学习笔记</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/CLBP/" style="font-size: 15px;">CLBP</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">论文学习</a> <a href="/tags/vim/" style="font-size: 15px;">vim</a> <a href="/tags/OpenCV/" style="font-size: 15px;">OpenCV</a> <a href="/tags/PyQt5/" style="font-size: 15px;">PyQt5</a> <a href="/tags/GUI/" style="font-size: 15px;">GUI</a> <a href="/tags/%E8%AE%B0%E5%8D%95%E8%AF%8D/" style="font-size: 15px;">记单词</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/TensorFlow/" style="font-size: 15px;">TensorFlow</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 15px;">损失函数</a> <a href="/tags/GitHub/" style="font-size: 15px;">GitHub</a> <a href="/tags/Resume/" style="font-size: 15px;">Resume</a> <a href="/tags/LBP/" style="font-size: 15px;">LBP</a> <a href="/tags/LPR/" style="font-size: 15px;">LPR</a> <a href="/tags/Numpy/" style="font-size: 15px;">Numpy</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/">2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/">2021</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/">2020</a><span class="archive-list-count">36</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/">2019</a><span class="archive-list-count">5</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-you"> 友情链接</i></div><ul></ul><a href="https://github.com/chaooo/hexo-theme-BlueLake" title="BlueLake主题" target="_blank">BlueLake主题</a><ul></ul><a href="https://mp.weixin.qq.com/s?__biz=MzIyNjM2MzQyNg==&amp;mid=2247484443&amp;idx=1&amp;sn=7110e42ef9e95a8c16064dde5b897960&amp;chksm=e870d556df075c4053a90d207c078e5fe965b5f9004de7f34dee09fccf1a37977aa3860b3a96&amp;mpshare=1&amp;scene=23&amp;srcid=0428XfRkvl0HsaHMU71k04dq#rd" title="重磅|完备的AI学习路线,最详细的资源整理！" target="_blank">重磅|完备的AI学习路线,最详细的资源整理！</a><ul></ul><a href="https://mp.weixin.qq.com/s?__biz=MzI5NDY1MjQzNA==&amp;mid=2247489096&amp;idx=1&amp;sn=ca2e1d72c9decd021c0365cc9e93a539&amp;chksm=ec5ec935db2940237482c5581b7a45f2bd50b138efa6488ed9b942c182486a4e74131e9af523&amp;mpshare=1&amp;scene=23&amp;srcid=#rd" title="推荐|机器学习入门方法和资料合集" target="_blank">推荐|机器学习入门方法和资料合集</a><ul></ul><a href="https://mp.weixin.qq.com/s?__biz=MzU4NTY4Mzg1Mw==&amp;mid=100000497&amp;idx=1&amp;sn=96cc795f1c22f7da2f3260d4ea364ff3&amp;chksm=7d8784134af00d05e41da36475bca417851535ed9710c7bd44ae7365cf40857015d922671c95&amp;mpshare=1&amp;scene=23&amp;srcid=04138MekLgFi3vNAz2E2rTrv#rd" title="良心推荐：机器学习入门资料汇总及学习建议（2018版）" target="_blank">良心推荐：机器学习入门资料汇总及学习建议（2018版）</a><ul></ul><a href="https://mp.weixin.qq.com/s?__biz=MzA3NDIyMjM1NA==&amp;mid=2649032678&amp;idx=1&amp;sn=7ce30241f24dae790f7361173132ee04&amp;chksm=8712b99bb065308d6626ac71d358d386199f5fdcc0d20f48b9ff7f7f84f32892325075413d78&amp;mpshare=1&amp;scene=1&amp;srcid=1213VnRvWgKRhAswA6qj9C6U&amp;sharer_sharetime=1607823235596&amp;sharer_shareid=6f3d2b6e1888cc6674af1cb9d8f856b5&amp;key=94e16379e8fc498f20603adf1c7c1474460f32c861df423924a01860bf66b23e3b54ec715f59513ed57f7be44b91602324165303caa8015279359147bf99dc0ac5c9482bbf323df6415707db1df1dbb44795972834805221b6810c0783bc61213b424afc1f9c747d8eddfe17782e3165ddfff5144eff7867ea82ee34ab2e6e44&amp;ascene=1&amp;uin=MzMyMzAzNzE5OA%3D%3D&amp;devicetype=Windows+10+x64&amp;version=6300002f&amp;lang=en&amp;exportkey=A%2Fn4vOWzACQbiXdS3ts1%2BmU%3D&amp;pass_ticket=X0sXcXVfthe9ne%2BkdsNidLJDaUos8pPBg0qSPgQJE8kY3CQmybx%2FB2TVL1w9Glu6&amp;wx_header=0" title="深度学习CV算法工程师从入门到初级面试" target="_blank">深度学习CV算法工程师从入门到初级面试</a></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">网站地图</a> |  <a href="/atom.xml">订阅本站</a> |  <a href="/about/">联系博主</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次，本站总访客数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人</p><p><span> Copyright &copy;<a href="/." rel="nofollow">贺同学.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a target="_blank" rel="noopener" href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.json.js?v=2.0.5"></script><div id="fullscreen-img" class="hide"><span class="close"></span></div><script type="text/javascript" src="/js/imgview.js?v=2.0.5" async></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.5" async></script><link rel="stylesheet" type="text/css" href="/share/css/share.css"><script type="text/javascript" src="/share/js/social-share.js" charset="utf-8"></script><script type="text/javascript" src="/share/js/qrcode.js" charset="utf-8"></script><script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":["mshare","weixin","tsina","qzone","linkedin","fbook","twi","print","renren","sqq","evernotecn","bdysc","tqq","tqf","bdxc","kaixin001","tieba","douban","bdhome","thx","ibaidu","meilishuo","mogujie","diandian","huaban","duitang","hx","fx","youdao","sdo","qingbiji","people","xinhua","mail","isohu","yaolan","wealink","ty","iguba","h163","copy"],"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"]}};with(document)0[(getElementsByTagName('head')[0]||head).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script></body></html>
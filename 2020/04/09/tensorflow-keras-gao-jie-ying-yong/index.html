<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><link rel="stylesheet" type="text/css" href="//fonts.loli.net/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.5"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.5"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><link rel="stylesheet" type="text/css" href="https://unpkg.com/gitalk/dist/gitalk.css?v=2.0.5"><title>TensorFlow Keras 高阶应用 | 我中意你23332</title><meta name="generator" content="Hexo 5.2.0"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">TensorFlow Keras 高阶应用</h1><a id="logo" href="/.">我中意你23332</a><p class="description">Tomorrow comes never.</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="搜索"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">TensorFlow Keras 高阶应用</h1><div class="post-meta"><a href="/2020/04/09/tensorflow-keras-gao-jie-ying-yong/#comments" class="comment-count"></a><p><span class="date">Apr 09, 2020</span><span><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" class="category">深度学习笔记</a><a href="/categories/%E5%AE%9E%E9%AA%8C%E6%A5%BC%E5%AD%A6%E4%B9%A0/" class="category">实验楼学习</a></span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><h4 id="总体介绍"><a href="#总体介绍" class="headerlink" title="总体介绍"></a>总体介绍</h4><p>上一讲主要讲解了 TensorFlow 中的一些基本概念与一些低阶 API ，在工业使用时，为了能够快速搭建出模型，人们往往更愿意去选择高阶 API。因此，本次主要讲解 TensorFlow 中常用的高阶 API。</p>
<h4 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a>知识点</h4><ul>
<li>TensorFlow</li>
<li>Keras</li>
</ul>
<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>TensorFlow 中的高阶 API 主要有 Keras 和 Estimators 这两个模块。由于 Keras 入门简单，功能强大，所以本次主要讲解 Keras。</p>
<p><img src="https://dn-simplecloud.shiyanlou.com/questions/uid958100-20190617-1560755002839" alt="img"></p>
<h3 id="Keras"><a href="#Keras" class="headerlink" title="Keras"></a>Keras</h3><p>Keras 是一个用于构建和训练深度学习模型的高阶 API。它可用于快速设计原型、高级研究和生产，具有以下三个主要优势：</p>
<ul>
<li>方便用户使用：Keras 具有针对常见用例做出优化的简单而一致的界面。它可针对用户错误提供切实可行的清晰反馈。</li>
<li>模块化和可组合：将可配置的构造块连接在一起就可以构建 Keras 模型，并且几乎不受限制。</li>
<li>易于扩展：可以编写自定义构造块以表达新的研究创意，并且可以创建新层、损失函数并开发先进的模型。</li>
</ul>
<h3 id="导入-tf-keras"><a href="#导入-tf-keras" class="headerlink" title="导入 tf.keras"></a>导入 tf.keras</h3><p><a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras"><code>tf.keras</code></a> 是 TensorFlow 对 <a target="_blank" rel="noopener" href="https://keras.io/"> <em>Keras API 规范</em></a> 的实现。这是一个用于构建和训练模型的高阶 API，包含对 TensorFlow 特定功能（例如 <a target="_blank" rel="noopener" href="https://notebook.shiyanlou.com/land-eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJob3N0IjoiMTcyLjE2LjU2LjIyIiwicG9ydCI6IjUxNTg5In0.gno4sJ6W90ILT0FFrAuWP-25iXs2olucq-489nPO4mY/notebooks/lab.ipynb#eager_execution"> <em>Eager Execution</em></a>、<a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/data"><code>tf.data</code></a> 管道和 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/guide/estimators"> <em>Estimator</em></a>）的顶级支持。 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras"><code>tf.keras</code></a> 使 TensorFlow 更易于使用，并且不会牺牲灵活性和性能。</p>
<p>首先，导入 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras"><code>tf.keras</code></a> 以设置 TensorFlow 程序：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">print(tf.VERSION)</span><br><span class="line">print(tf.keras.__version__)</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras"><code>tf.keras</code></a> 可以运行任何与 Keras 兼容的代码，但请注意：</p>
<ul>
<li>最新版 TensorFlow 中的 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras"><code>tf.keras</code></a> 版本可能与 PyPI 中的最新 <code>keras</code> 版本不同。请查看 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras#__version__"><code>tf.keras.__version__</code></a>。</li>
<li><a target="_blank" rel="noopener" href="https://notebook.shiyanlou.com/land-eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJob3N0IjoiMTcyLjE2LjU2LjIyIiwicG9ydCI6IjUxNTg5In0.gno4sJ6W90ILT0FFrAuWP-25iXs2olucq-489nPO4mY/notebooks/lab.ipynb#weights_only"> <em>保存模型的权重</em></a>时，<a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras"><code>tf.keras</code></a> 默认采用 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/guide/checkpoints"> <em>检查点格式</em></a>。请传递 <code>save_format=&#39;h5&#39;</code> 以使用 HDF5。</li>
</ul>
<h3 id="构建简单的模型"><a href="#构建简单的模型" class="headerlink" title="构建简单的模型"></a>构建简单的模型</h3><p>在 Keras 中，可以通过组合层来构建模型。模型通常是由层构成的图。最常见的模型类型是层的堆叠：<a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/models/Sequential"><code>tf.keras.Sequential</code></a> 模型。</p>
<p>现在我们使用 <code>tf.keras.Sequential()</code> 来构建一个简单的全连接网络，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.Sequential()  <span class="comment"># 定义模型</span></span><br><span class="line"><span class="comment"># 添加 Dense 层，输入为 100，输出为 64 个单元，激活函数选用 Relu 函数</span></span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, input_shape=(<span class="number">100</span>,), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line"><span class="comment"># 添加 Dense 层，输出为 10 个单元，激活函数选用 softmax 函数</span></span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br></pre></td></tr></table></figure>

<p>同通过上面仅 4 行代码，我们已经构建出了一个简单的神经网络模型，下面我们可以通过 <code>summary</code> 方法来查看所构建的模型信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<h4 id="配置层"><a href="#配置层" class="headerlink" title="配置层"></a>配置层</h4><p>上面主要讲述使用 <code>tf.keras.Sequential()</code> 来构建模型，现在讲解另一种 Keras 常用的构建模型方法： <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/layers"><code>tf.keras.layers</code></a>，与 <code>tf.keras.Sequential()</code> 方法差不多，这两者都具有一些相同的构造函数参数：</p>
<ul>
<li><code>activation</code>：设置层的激活函数。此参数由内置函数的名称指定，或指定为可调用对象。默认情况下，系统不会应用任何激活函数。</li>
<li><code>kernel_initializer</code> 和 <code>bias_initializer</code>：创建层权重的初始化方案。此参数是一个名称或可调用对象，默认为 <code>&quot;Glorot uniform&quot;</code> 初始化器。</li>
<li><code>kernel_regularizer</code> 和 <code>bias_regularizer</code>：应用层权重的正则化方案，例如 L1 或 L2 正则化。默认情况下，系统不会应用正则化函数。</li>
</ul>
<p>以下代码使用构造函数参数实例化 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/layers/Dense"><code>tf.keras.layers. Dense</code></a> 层：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个层，输出单元为 64 ，激活函数为 sigmoid 函数</span></span><br><span class="line">layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line"><span class="comment"># 创建一个层，使用 L1 正则化</span></span><br><span class="line">layers.Dense(<span class="number">64</span>, kernel_regularizer=tf.keras.regularizers.l1(<span class="number">0.01</span>))</span><br><span class="line"><span class="comment"># 创建一个层，使用 L2 正则化</span></span><br><span class="line">layers.Dense(<span class="number">64</span>, bias_regularizer=tf.keras.regularizers.l2(<span class="number">0.01</span>))</span><br><span class="line"><span class="comment"># 创建一个层，偏置参数的初始值设置为 2</span></span><br><span class="line">layers.Dense(<span class="number">64</span>, bias_initializer=tf.keras.initializers.constant(<span class="number">2.0</span>))</span><br></pre></td></tr></table></figure>

<h4 id="训练和评估"><a href="#训练和评估" class="headerlink" title="训练和评估"></a>训练和评估</h4><p>上面主要讲述 Keras 两种常用构建神经网络层的方法。两者也可以合起来使用，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.Sequential([</span><br><span class="line">    <span class="comment"># 添加一个 Dense 层，输出为 64 ，激活函数为 Rule</span></span><br><span class="line">    layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    <span class="comment"># 添加一个 Dense 层，输出为 10 ，激活函数为 softmax</span></span><br><span class="line">    layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)])</span><br></pre></td></tr></table></figure>

<p>构建好模型后，通过调用 <code>compile</code> 方法配置该模型的学习流程：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.train.AdamOptimizer(<span class="number">0.001</span>),</span><br><span class="line">              loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/Model#compile"><code>tf.keras.Model.compile</code></a> 主要含有三个重要参数：</p>
<ul>
<li><code>optimizer</code>：此对象会指定训练过程。从 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/train"><code>tf.train</code></a> 模块向其传递优化器实例，例如 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/train/AdamOptimizer"><code>tf.train.AdamOptimizer</code></a>、<a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/train/RMSPropOptimizer"><code>tf.train.RMSPropOptimizer</code></a> 或 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/train/GradientDescentOptimizer"><code>tf.train.GradientDescentOptimizer</code></a>。</li>
<li><code>loss</code>：要在优化期间最小化的函数。常见选择包括均方误差 (<code>mse</code>)、<code>categorical_crossentropy</code> 和 <code>binary_crossentropy</code>。损失函数由名称或通过从 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/losses"><code>tf.keras.losses</code></a> 模块传递可调用对象来指定。</li>
<li><code>metrics</code>：用于监控训练。它们是 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/metrics"><code>tf.keras.metrics</code></a> 模块中的字符串名称或可调用对象。</li>
</ul>
<p>以下代码展示了配置模型以进行训练的几个示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.train.AdamOptimizer(<span class="number">0.01</span>),  <span class="comment"># 使用 Adam 优化算法</span></span><br><span class="line">              loss=<span class="string">&#x27;mse&#x27;</span>,       <span class="comment"># 损失函数选用均方差损失</span></span><br><span class="line">              metrics=[<span class="string">&#x27;mse&#x27;</span>])  <span class="comment"># 使用均方差来评估模型</span></span><br></pre></td></tr></table></figure>

<h4 id="输入-NumPy-数据"><a href="#输入-NumPy-数据" class="headerlink" title="输入 NumPy 数据"></a>输入 NumPy 数据</h4><p>当构建好模型之后，需要对其进行训练，而训练时需要加载数据。对于小型数据集，可以直接使用 <a target="_blank" rel="noopener" href="https://www.numpy.org/"> <em>NumPy</em></a> 数组训练和评估模型。使用 <code>fit</code> 方法来训练模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">data = np.random.random((<span class="number">1000</span>, <span class="number">32</span>))</span><br><span class="line">labels = np.random.random((<span class="number">1000</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">model.fit(data, labels, epochs=<span class="number">10</span>, batch_size=<span class="number">32</span>)</span><br></pre></td></tr></table></figure>

<p>在训练时输出的日志中，sample - loss: 11.6251 表示损失值，categorical_accuracy: 0.1100 表示正确率，在该例子中，使用的数据集是随机产生的，因此准确率并不高。</p>
<p><a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/Model#fit"><code>tf.keras.Model.fit</code></a> 采用三个重要参数：</p>
<ul>
<li><code>epochs</code>：以周期为单位进行训练。一个周期是对整个输入数据的一次迭代（以较小的批次完成迭代）。</li>
<li><code>batch_size</code>：当传递 NumPy 数据时，模型将数据分成较小的批次，并在训练期间迭代这些批次。此整数指定每个批次的大小。请注意，如果样本总数不能被批次大小整除，则最后一个批次可能更小。</li>
<li><code>validation_data</code>：在对模型进行原型设计时，你需要轻松监控该模型在某些验证数据上达到的效果。传递此参数（输入和标签元组）可以让该模型在每个周期结束时以推理模式显示所传递数据的损失和指标。即我们通常所说的验证集或测试集。</li>
</ul>
<p>下面是使用 validation_data 的示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">data = np.random.random((<span class="number">1000</span>, <span class="number">32</span>))</span><br><span class="line">labels = np.random.random((<span class="number">1000</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">val_data = np.random.random((<span class="number">100</span>, <span class="number">32</span>))</span><br><span class="line">val_labels = np.random.random((<span class="number">100</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">model.fit(data, labels, epochs=<span class="number">10</span>, batch_size=<span class="number">32</span>,</span><br><span class="line">          validation_data=(val_data, val_labels))</span><br></pre></td></tr></table></figure>

<h4 id="输入-tf-data-数据集"><a href="#输入-tf-data-数据集" class="headerlink" title="输入 tf.data 数据集"></a>输入 tf.data 数据集</h4><p>传入数据集还有另一种方法，就是使用 TensorFlow 提供的接口 <code>tf.data</code>。 其提供的 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/guide/datasets"> <em>Datasets API</em></a> 可扩展为大型数据集或多设备训练。将 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/data/Dataset"><code>tf.data.Dataset</code></a> 实例传递到 <code>fit</code> 方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#  加载数据集</span></span><br><span class="line">dataset = tf.data.Dataset.from_tensor_slices((data, labels))</span><br><span class="line">dataset = dataset.batch(<span class="number">32</span>)</span><br><span class="line">dataset = dataset.repeat()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(dataset, epochs=<span class="number">10</span>, steps_per_epoch=<span class="number">30</span>)</span><br></pre></td></tr></table></figure>

<p>在上方代码中，fit 方法使用了 steps_per_epoch 参数表示模型在进入下一个周期之前运行的训练步数。由于 Dataset 会生成批次数据，因此该代码段不需要设置 batch_size。</p>
<p>同样该方法传入的数据集也可用于验证：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">dataset = tf.data.Dataset.from_tensor_slices((data, labels))</span><br><span class="line">dataset = dataset.batch(<span class="number">32</span>).repeat()</span><br><span class="line"></span><br><span class="line">val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_labels))</span><br><span class="line">val_dataset = val_dataset.batch(<span class="number">32</span>).repeat()</span><br><span class="line"></span><br><span class="line">model.fit(dataset, epochs=<span class="number">10</span>, steps_per_epoch=<span class="number">30</span>,</span><br><span class="line">          validation_data=val_dataset,</span><br><span class="line">          validation_steps=<span class="number">3</span>)</span><br></pre></td></tr></table></figure>

<h4 id="评估和预测"><a href="#评估和预测" class="headerlink" title="评估和预测"></a>评估和预测</h4><p>当模型训练完，我们需要对所训练完的模型进行评估时，可以使用 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/Model#evaluate"><code>tf.keras.Model.evaluate</code></a> 和 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/Model#predict"><code>tf.keras.Model.predict</code></a> 方法，并且这两种方法同样可以使用 NumPy 数据和 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/data/Dataset"><code>tf.data.Dataset</code></a> 提供的数据。</p>
<p>要评估所提供数据的推理模式损失和指标，可以运行以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = np.random.random((<span class="number">1000</span>, <span class="number">32</span>))</span><br><span class="line">labels = np.random.random((<span class="number">1000</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line">model.evaluate(data, labels, batch_size=<span class="number">32</span>)</span><br></pre></td></tr></table></figure>

<p>同样的方法，采用 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/data/Dataset"><code>tf.data.Dataset</code></a> 提供的数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.evaluate(dataset, steps=<span class="number">30</span>)</span><br></pre></td></tr></table></figure>

<p>要在所提供数据（采用 NumPy 数组形式）的推理中预测最后一层的输出，可以运行以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = model.predict(data, batch_size=<span class="number">32</span>)</span><br><span class="line">result.shape</span><br></pre></td></tr></table></figure>

<h4 id="构建高级模型"><a href="#构建高级模型" class="headerlink" title="构建高级模型"></a>构建高级模型</h4><p>上面所讲述的 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/models/Sequential"><code>tf.keras.Sequential</code></a> 模型是层的简单堆叠，这种方法构建模型简单，但往往无法构建出复杂模型。在 Keras 中，通常使用 <a target="_blank" rel="noopener" href="https://keras.io/getting-started/functional-api-guide/"> <em>Keras 函数式 API</em></a> 来构建复杂的模型，例如：</p>
<ul>
<li>多输入模型，</li>
<li>多输出模型，</li>
<li>具有共享层的模型（同一层被调用多次），</li>
<li>具有非序列数据流的模型（例如，剩余连接）。</li>
</ul>
<p>使用函数式 API 构建的模型具有以下特征：</p>
<ol>
<li>层实例可调用并返回张量。</li>
<li>输入张量和输出张量用于定义 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/models/Model"><code>tf.keras.Model</code></a> 实例。</li>
<li>此模型的训练方式和 <code>Sequential</code> 模型一样。</li>
</ol>
<p>以下示例使用函数式 API 构建一个简单的全连接网络：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">inputs = tf.keras.Input(shape=(<span class="number">32</span>,))  <span class="comment"># 创建一个输入层</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 Dense 层</span></span><br><span class="line">x = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(inputs)</span><br><span class="line">x = layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">predictions = layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)(x)</span><br><span class="line">predictions</span><br></pre></td></tr></table></figure>

<p>在给定输入和输出的情况下实例化模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实例化模型</span></span><br><span class="line">model = tf.keras.Model(inputs=inputs, outputs=predictions)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译模型，指的优化算法，损失函数等相关的参数</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.train.RMSPropOptimizer(<span class="number">0.001</span>),</span><br><span class="line">              loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(data, labels, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<h4 id="模型子类化"><a href="#模型子类化" class="headerlink" title="模型子类化"></a>模型子类化</h4><p>我们也可以通过对 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/models/Model"><code>tf.keras.Model</code></a> 进行子类化并定义前向传播来构建完全可自定义的模型。这种方法需要在 <code>__init__</code> 方法中创建层并将它们设置为类实例的属性。此外，需要在 <code>call</code> 方法中定义前向传播。</p>
<p>在启用 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/guide/eager"> <em>Eager Execution</em></a> 时，模型子类化特别有用，因为可以命令式地编写前向传播。</p>
<p>虽然模型子类化较为灵活，但代价是复杂性更高且用户出错率更高。如果可能，请首选函数式 API。</p>
<p>以下示例展示了使用自定义前向传播进行子类化的 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/models/Model"><code>tf.keras.Model</code></a>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModel</span>(<span class="params">tf.keras.Model</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes=<span class="number">10</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MyModel, self).__init__(name=<span class="string">&#x27;my_model&#x27;</span>)</span><br><span class="line">        self.num_classes = num_classes</span><br><span class="line">        <span class="comment"># 定义所想要构建模型的层</span></span><br><span class="line">        self.dense_1 = layers.Dense(<span class="number">32</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.dense_2 = layers.Dense(num_classes, activation=<span class="string">&#x27;sigmoid&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">        <span class="comment"># 定义模型的前向传播</span></span><br><span class="line">        x = self.dense_1(inputs)</span><br><span class="line">        <span class="keyword">return</span> self.dense_2(x)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_output_shape</span>(<span class="params">self, input_shape</span>):</span></span><br><span class="line">        <span class="comment"># 计算模型的输出</span></span><br><span class="line">        shape = tf.TensorShape(input_shape).as_list()</span><br><span class="line">        shape[<span class="number">-1</span>] = self.num_classes</span><br><span class="line">        <span class="keyword">return</span> tf.TensorShape(shape)</span><br></pre></td></tr></table></figure>

<p>实例化新模型类：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model = MyModel(num_classes=<span class="number">10</span>)  <span class="comment"># 模型实例化</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译模型，指的优化算法，损失函数等相关的参数</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.train.RMSPropOptimizer(<span class="number">0.001</span>),</span><br><span class="line">              loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(data, labels, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<h4 id="自定义层"><a href="#自定义层" class="headerlink" title="自定义层"></a>自定义层</h4><p>在我们构建模型时，有时候 Keras 提供的接口并不能满足我们的要求。因此可以通过对 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/layers/Layer"><code>tf.keras.layers.Layer</code></a> 进行子类化并实现以下方法来创建自定义层：</p>
<ul>
<li><code>build</code>：创建层的权重。使用 <code>add_weight</code> 方法添加权重。</li>
<li><code>call</code>：定义前向传播。</li>
<li><code>compute_output_shape</code>：指定在给定输入形状的情况下如何计算层的输出形状。</li>
<li>或者，可以通过实现 <code>get_config</code> 方法和 <code>from_config</code> 类方法序列化层。</li>
</ul>
<p>下面是一个使用核矩阵实现输入 matmul 的自定义层示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyLayer</span>(<span class="params">layers.Layer</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, output_dim, **kwargs</span>):</span></span><br><span class="line">        self.output_dim = output_dim</span><br><span class="line">        <span class="built_in">super</span>(MyLayer, self).__init__(**kwargs)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build</span>(<span class="params">self, input_shape</span>):</span></span><br><span class="line">        shape = tf.TensorShape((input_shape[<span class="number">1</span>], self.output_dim))</span><br><span class="line">        <span class="comment"># 创建一个层所使用的权重值.</span></span><br><span class="line">        self.kernel = self.add_weight(name=<span class="string">&#x27;kernel&#x27;</span>,</span><br><span class="line">                                      shape=shape,</span><br><span class="line">                                      initializer=<span class="string">&#x27;uniform&#x27;</span>,</span><br><span class="line">                                      trainable=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># 需要对其进行声明</span></span><br><span class="line">        <span class="built_in">super</span>(MyLayer, self).build(input_shape)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, inputs</span>):</span></span><br><span class="line">        <span class="keyword">return</span> tf.matmul(inputs, self.kernel)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_output_shape</span>(<span class="params">self, input_shape</span>):</span></span><br><span class="line">        shape = tf.TensorShape(input_shape).as_list()</span><br><span class="line">        shape[<span class="number">-1</span>] = self.output_dim</span><br><span class="line">        <span class="keyword">return</span> tf.TensorShape(shape)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_config</span>(<span class="params">self</span>):</span></span><br><span class="line">        base_config = <span class="built_in">super</span>(MyLayer, self).get_config()</span><br><span class="line">        base_config[<span class="string">&#x27;output_dim&#x27;</span>] = self.output_dim</span><br><span class="line">        <span class="keyword">return</span> base_config</span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">from_config</span>(<span class="params">cls, config</span>):</span></span><br><span class="line">        <span class="keyword">return</span> cls(**config)</span><br></pre></td></tr></table></figure>

<p>使用自定义层创建模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.Sequential([</span><br><span class="line">    MyLayer(<span class="number">10</span>),</span><br><span class="line">    layers.Activation(<span class="string">&#x27;softmax&#x27;</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译模型，指定优化算法等参数</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.train.RMSPropOptimizer(<span class="number">0.001</span>),</span><br><span class="line">              loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">model.fit(data, labels, batch_size=<span class="number">32</span>,  epochs=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<h4 id="回调"><a href="#回调" class="headerlink" title="回调"></a>回调</h4><p>回调是传递给模型的对象，用于在训练期间记录模型日志或防止模型出现意外等。你可以编写自定义回调，也可以使用包含以下方法的内置 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks"><code>tf.keras.callbacks</code></a>：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/ModelCheckpoint"><code>tf.keras.callbacks.ModelCheckpoint</code></a>：定期保存模型的检查点。</li>
<li><a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/LearningRateScheduler"><code>tf.keras.callbacks.LearningRateScheduler</code></a>：动态更改学习速率。</li>
<li><a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/EarlyStopping"><code>tf.keras.callbacks.EarlyStopping</code></a>：在验证效果不再改进时中断训练。</li>
<li><a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/TensorBoard"><code>tf.keras.callbacks.TensorBoard</code></a>：使用 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/guide/summaries_and_tensorboard"> <em>TensorBoard</em></a> 监控模型的行为。</li>
</ul>
<p>要使用 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/callbacks/Callback"><code>tf.keras.callbacks.Callback</code></a>，请将其传递给模型的 <code>fit</code> 方法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">callbacks = [</span><br><span class="line">    <span class="comment"># 如果在 2 epochs 内损失值没有变化，则中断训练</span></span><br><span class="line">    tf.keras.callbacks.EarlyStopping(patience=<span class="number">2</span>, monitor=<span class="string">&#x27;val_loss&#x27;</span>),</span><br><span class="line">    <span class="comment"># 记录日志</span></span><br><span class="line">    tf.keras.callbacks.TensorBoard(log_dir=<span class="string">&#x27;./logs&#x27;</span>)</span><br><span class="line">]</span><br><span class="line">model.fit(data, labels, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, callbacks=callbacks,</span><br><span class="line">          validation_data=(val_data, val_labels))</span><br></pre></td></tr></table></figure>

<h3 id="保存和恢复"><a href="#保存和恢复" class="headerlink" title="保存和恢复"></a>保存和恢复</h3><p>在 Keras 中，可以使用 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/Model#save_weights"><code>tf.keras.Model.save_weights</code></a> 保存并加载模型的权重：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.Sequential([</span><br><span class="line">    layers.Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)])</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.train.AdamOptimizer(<span class="number">0.001</span>),</span><br><span class="line">              loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">model.save_weights(<span class="string">&#x27;./weights/my_model&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line">model.load_weights(<span class="string">&#x27;./weights/my_model&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>默认情况下，会以 <a target="_blank" rel="noopener" href="https://tensorflow.google.cn/guide/checkpoints"> <em>TensorFlow 检查点</em></a> 文件格式保存模型的权重。权重也可以另存为 Keras HDF5 格式（Keras 多后端实现的默认格式）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># S 保存为 HDF5 文件</span></span><br><span class="line">model.save_weights(<span class="string">&#x27;my_model.h5&#x27;</span>, save_format=<span class="string">&#x27;h5&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line">model.load_weights(<span class="string">&#x27;my_model.h5&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="保存配置"><a href="#保存配置" class="headerlink" title="保存配置"></a>保存配置</h4><p>可以保存模型的配置，此操作会对模型架构（不含任何权重）进行序列化。即使没有定义原始模型的代码，保存的配置也可以重新创建并初始化相同的模型。Keras 支持 JSON 和 YAML 序列化格式：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 序列化模型为 json 形式</span></span><br><span class="line">json_string = model.to_json()</span><br><span class="line">json_string</span><br></pre></td></tr></table></figure>

<p>输出为:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#39;&#123;&quot;class_name&quot;: &quot;Sequential&quot;, &quot;config&quot;: &#123;&quot;name&quot;: &quot;sequential_6&quot;, &quot;layers&quot;: [&#123;&quot;class_name&quot;: &quot;Dense&quot;, &quot;config&quot;: &#123;&quot;name&quot;: &quot;dense_24&quot;, &quot;trainable&quot;: true, &quot;dtype&quot;: null, &quot;units&quot;: 64, &quot;activation&quot;: &quot;relu&quot;, &quot;use_bias&quot;: true, &quot;kernel_initializer&quot;: &#123;&quot;class_name&quot;: &quot;GlorotUniform&quot;, &quot;config&quot;: &#123;&quot;seed&quot;: null, &quot;dtype&quot;: &quot;float32&quot;&#125;&#125;, &quot;bias_initializer&quot;: &#123;&quot;class_name&quot;: &quot;Zeros&quot;, &quot;config&quot;: &#123;&quot;dtype&quot;: &quot;float32&quot;&#125;&#125;, &quot;kernel_regularizer&quot;: null, &quot;bias_regularizer&quot;: null, &quot;activity_regularizer&quot;: null, &quot;kernel_constraint&quot;: null, &quot;bias_constraint&quot;: null&#125;&#125;, &#123;&quot;class_name&quot;: &quot;Dense&quot;, &quot;config&quot;: &#123;&quot;name&quot;: &quot;dense_25&quot;, &quot;trainable&quot;: true, &quot;dtype&quot;: null, &quot;units&quot;: 10, &quot;activation&quot;: &quot;softmax&quot;, &quot;use_bias&quot;: true, &quot;kernel_initializer&quot;: &#123;&quot;class_name&quot;: &quot;GlorotUniform&quot;, &quot;config&quot;: &#123;&quot;seed&quot;: null, &quot;dtype&quot;: &quot;float32&quot;&#125;&#125;, &quot;bias_initializer&quot;: &#123;&quot;class_name&quot;: &quot;Zeros&quot;, &quot;config&quot;: &#123;&quot;dtype&quot;: &quot;float32&quot;&#125;&#125;, &quot;kernel_regularizer&quot;: null, &quot;bias_regularizer&quot;: null, &quot;activity_regularizer&quot;: null, &quot;kernel_constraint&quot;: null, &quot;bias_constraint&quot;: null&#125;&#125;]&#125;, &quot;keras_version&quot;: &quot;2.1.6-tf&quot;, &quot;backend&quot;: &quot;tensorflow&quot;&#125;&#39;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> pprint</span><br><span class="line">pprint.pprint(json.loads(json_string))</span><br></pre></td></tr></table></figure>

<p>输出为:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#39;backend&#39;: &#39;tensorflow&#39;,</span><br><span class="line"> &#39;class_name&#39;: &#39;Sequential&#39;,</span><br><span class="line"> &#39;config&#39;: &#123;&#39;layers&#39;: [&#123;&#39;class_name&#39;: &#39;Dense&#39;,</span><br><span class="line">                        &#39;config&#39;: &#123;&#39;activation&#39;: &#39;relu&#39;,</span><br><span class="line">                                   &#39;activity_regularizer&#39;: None,</span><br><span class="line">                                   &#39;bias_constraint&#39;: None,</span><br><span class="line">                                   &#39;bias_initializer&#39;: &#123;&#39;class_name&#39;: &#39;Zeros&#39;,</span><br><span class="line">                                                        &#39;config&#39;: &#123;&#39;dtype&#39;: &#39;float32&#39;&#125;&#125;,</span><br><span class="line">                                   &#39;bias_regularizer&#39;: None,</span><br><span class="line">                                   &#39;dtype&#39;: None,</span><br><span class="line">                                   &#39;kernel_constraint&#39;: None,</span><br><span class="line">                                   &#39;kernel_initializer&#39;: &#123;&#39;class_name&#39;: &#39;GlorotUniform&#39;,</span><br><span class="line">                                                          &#39;config&#39;: &#123;&#39;dtype&#39;: &#39;float32&#39;,</span><br><span class="line">                                                                     &#39;seed&#39;: None&#125;&#125;,</span><br><span class="line">                                   &#39;kernel_regularizer&#39;: None,</span><br><span class="line">                                   &#39;name&#39;: &#39;dense_24&#39;,</span><br><span class="line">                                   &#39;trainable&#39;: True,</span><br><span class="line">                                   &#39;units&#39;: 64,</span><br><span class="line">                                   &#39;use_bias&#39;: True&#125;&#125;,</span><br><span class="line">                       &#123;&#39;class_name&#39;: &#39;Dense&#39;,</span><br><span class="line">                        &#39;config&#39;: &#123;&#39;activation&#39;: &#39;softmax&#39;,</span><br><span class="line">                                   &#39;activity_regularizer&#39;: None,</span><br><span class="line">                                   &#39;bias_constraint&#39;: None,</span><br><span class="line">                                   &#39;bias_initializer&#39;: &#123;&#39;class_name&#39;: &#39;Zeros&#39;,</span><br><span class="line">                                                        &#39;config&#39;: &#123;&#39;dtype&#39;: &#39;float32&#39;&#125;&#125;,</span><br><span class="line">                                   &#39;bias_regularizer&#39;: None,</span><br><span class="line">                                   &#39;dtype&#39;: None,</span><br><span class="line">                                   &#39;kernel_constraint&#39;: None,</span><br><span class="line">                                   &#39;kernel_initializer&#39;: &#123;&#39;class_name&#39;: &#39;GlorotUniform&#39;,</span><br><span class="line">                                                          &#39;config&#39;: &#123;&#39;dtype&#39;: &#39;float32&#39;,</span><br><span class="line">                                                                     &#39;seed&#39;: None&#125;&#125;,</span><br><span class="line">                                   &#39;kernel_regularizer&#39;: None,</span><br><span class="line">                                   &#39;name&#39;: &#39;dense_25&#39;,</span><br><span class="line">                                   &#39;trainable&#39;: True,</span><br><span class="line">                                   &#39;units&#39;: 10,</span><br><span class="line">                                   &#39;use_bias&#39;: True&#125;&#125;],</span><br><span class="line">            &#39;name&#39;: &#39;sequential_6&#39;&#125;,</span><br><span class="line"> &#39;keras_version&#39;: &#39;2.1.6-tf&#39;&#125;</span><br></pre></td></tr></table></figure>

<p>从 json 重新创建模型（刚刚初始化）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line">fresh_model = tf.keras.models.model_from_json(json_string)</span><br></pre></td></tr></table></figure>

<p>将模型序列化为 YAML 格式。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yaml_string = model.to_yaml()</span><br><span class="line">print(yaml_string)</span><br></pre></td></tr></table></figure>

<p>输出为:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">backend: tensorflow</span><br><span class="line">class_name: Sequential</span><br><span class="line">config:</span><br><span class="line">  layers:</span><br><span class="line">  - class_name: Dense</span><br><span class="line">    config:</span><br><span class="line">      activation: relu</span><br><span class="line">      activity_regularizer: null</span><br><span class="line">      bias_constraint: null</span><br><span class="line">      bias_initializer:</span><br><span class="line">        class_name: Zeros</span><br><span class="line">        config: &#123;dtype: float32&#125;</span><br><span class="line">      bias_regularizer: null</span><br><span class="line">      dtype: null</span><br><span class="line">      kernel_constraint: null</span><br><span class="line">      kernel_initializer:</span><br><span class="line">        class_name: GlorotUniform</span><br><span class="line">        config: &#123;dtype: float32, seed: null&#125;</span><br><span class="line">      kernel_regularizer: null</span><br><span class="line">      name: dense_24</span><br><span class="line">      trainable: true</span><br><span class="line">      units: 64</span><br><span class="line">      use_bias: true</span><br><span class="line">  - class_name: Dense</span><br><span class="line">    config:</span><br><span class="line">      activation: softmax</span><br><span class="line">      activity_regularizer: null</span><br><span class="line">      bias_constraint: null</span><br><span class="line">      bias_initializer:</span><br><span class="line">        class_name: Zeros</span><br><span class="line">        config: &#123;dtype: float32&#125;</span><br><span class="line">      bias_regularizer: null</span><br><span class="line">      dtype: null</span><br><span class="line">      kernel_constraint: null</span><br><span class="line">      kernel_initializer:</span><br><span class="line">        class_name: GlorotUniform</span><br><span class="line">        config: &#123;dtype: float32, seed: null&#125;</span><br><span class="line">      kernel_regularizer: null</span><br><span class="line">      name: dense_25</span><br><span class="line">      trainable: true</span><br><span class="line">      units: 10</span><br><span class="line">      use_bias: true</span><br><span class="line">  name: sequential_6</span><br><span class="line">keras_version: 2.1.6-tf</span><br></pre></td></tr></table></figure>

<p>从 YAML 重新创建模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fresh_model = tf.keras.models.model_from_yaml(yaml_string)</span><br><span class="line">fresh_model</span><br></pre></td></tr></table></figure>

<h4 id="整个模型"><a href="#整个模型" class="headerlink" title="整个模型"></a>整个模型</h4><p>整个模型可以保存到一个文件中，其中包含权重值、模型配置乃至优化器配置。这样就可以对模型设置检查点并稍后从完全相同的状态继续训练，而无需访问原始代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个模型</span></span><br><span class="line">model = tf.keras.Sequential([</span><br><span class="line">    layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>,</span><br><span class="line">                 input_shape=(<span class="number">32</span>,)),</span><br><span class="line">    layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;rmsprop&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(data, labels, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存整个模型为 HDF5 文件</span></span><br><span class="line">model.save(<span class="string">&#x27;my_model.h5&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载整个模型</span></span><br><span class="line">model = tf.keras.models.load_model(<span class="string">&#x27;my_model.h5&#x27;</span>)</span><br><span class="line">model</span><br></pre></td></tr></table></figure>

<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>本次主要讲解了 TensorFlow 常用的高阶 API，并对其集成的 Keras 进行详细的讲解。相对于低阶 API ，高阶 API 往往会更加简单，因为其只要定义层即可。这也是 TensorFlow 官方极力推荐广大开发者使用高阶 API 的原因。</p>
<hr>
<img src="/2020/04/09/tensorflow-keras-gao-jie-ying-yong/hi.png" class=""></div><div class="post-copyright"><blockquote><p>原文作者: 贺同学</p><p>原文链接: <a href="http://clarkhedi.github.io/2020/04/09/tensorflow-keras-gao-jie-ying-yong/">http://clarkhedi.github.io/2020/04/09/tensorflow-keras-gao-jie-ying-yong/</a></p><p>版权声明: 转载请注明出处(必须保留原文作者署名原文链接)</p></blockquote></div><div class="tags"><a href="/tags/Python/">Python</a><a href="/tags/TensorFlow/">TensorFlow</a></div><div class="post-share"><div class="social-share"><span>分享到:</span></div><div class="bdsharebuttonbox"><span style="float:left;line-height: 28px;height: 28px;font-size:16px;font-weight:blod">分享到:</span><a href="#" data-cmd="more" class="bds_more"></a><a href="#" data-cmd="mshare" title="分享到一键分享" class="bds_mshare"></a><a href="#" data-cmd="fbook" title="分享到Facebook" class="bds_fbook"></a><a href="#" data-cmd="twi" title="分享到Twitter" class="bds_twi"></a><a href="#" data-cmd="linkedin" title="分享到linkedin" class="bds_linkedin"></a><a href="#" data-cmd="youdao" title="分享到有道云笔记" class="bds_youdao"></a><a href="#" data-cmd="evernotecn" title="分享到印象笔记" class="bds_evernotecn"></a><a href="#" data-cmd="weixin" title="分享到微信" class="bds_weixin"></a><a href="#" data-cmd="qzone" title="分享到QQ空间" class="bds_qzone"></a><a href="#" data-cmd="tsina" title="分享到新浪微博" class="bds_tsina"></a></div></div><div class="post-nav"><a href="/2020/04/09/numpy-ji-chu-ru-men/" class="pre">Numpy基础入门</a><a href="/2020/04/09/tensorflow-ji-ben-gai-nian-ji-gou-jian/" class="next">TensorFlow 基本概念及构建</a></div><div id="comments"><div id="container"><script type="text/javascript" src="https://unpkg.com/gitalk/dist/gitalk.min.js?v=2.0.5"></script><script type="text/javascript" src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js?v=2.0.5"></script><script>var gitalk = new Gitalk({
  clientID: 'd6d4fb51a5284e4df5fd',
  clientSecret: '80ba8b4586bfce6df672e814df089b31e49a5549',
  repo: 'Gitalk',
  owner: 'clarkhedi',
  admin: ['clarkhedi'],
  id: md5(window.location.pathname),
  distractionFreeMode: false,
  language: 'zh-CN',
  pagerDirection: 'last'
})
gitalk.render('container')</script></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div><ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E4%BD%93%E4%BB%8B%E7%BB%8D"><span class="toc-text">总体介绍</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E7%82%B9"><span class="toc-text">知识点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-text">简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Keras"><span class="toc-text">Keras</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%BC%E5%85%A5-tf-keras"><span class="toc-text">导入 tf.keras</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E7%AE%80%E5%8D%95%E7%9A%84%E6%A8%A1%E5%9E%8B"><span class="toc-text">构建简单的模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E5%B1%82"><span class="toc-text">配置层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E5%92%8C%E8%AF%84%E4%BC%B0"><span class="toc-text">训练和评估</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BE%93%E5%85%A5-NumPy-%E6%95%B0%E6%8D%AE"><span class="toc-text">输入 NumPy 数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BE%93%E5%85%A5-tf-data-%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-text">输入 tf.data 数据集</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%84%E4%BC%B0%E5%92%8C%E9%A2%84%E6%B5%8B"><span class="toc-text">评估和预测</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9E%84%E5%BB%BA%E9%AB%98%E7%BA%A7%E6%A8%A1%E5%9E%8B"><span class="toc-text">构建高级模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%AD%90%E7%B1%BB%E5%8C%96"><span class="toc-text">模型子类化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%B1%82"><span class="toc-text">自定义层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9B%9E%E8%B0%83"><span class="toc-text">回调</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%9D%E5%AD%98%E5%92%8C%E6%81%A2%E5%A4%8D"><span class="toc-text">保存和恢复</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BF%9D%E5%AD%98%E9%85%8D%E7%BD%AE"><span class="toc-text">保存配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B4%E4%B8%AA%E6%A8%A1%E5%9E%8B"><span class="toc-text">整个模型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-text">总结</span></a></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2022/11/18/hexo-start/">Hexo Start</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/16/ge-xing-hua-ding-zhi-ni-de-github-zhu-ye/">2021年，教程 | 个性化定制你的 GitHub 主页</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/06/07/you-mei-de-sublime-text/">优美的Sublime Text</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/05/08/pyqt5-xue-xi-bi-ji-yi/">PyQt5学习笔记（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/17/kaiming-he-chu-shi-hua-de-xue-xi/">Kaiming He初始化的学习</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/05/autograd-yu-luo-ji-hui-gui/">autograd与逻辑回归</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/05/ji-suan-tu-yu-dong-tai-tu-ji-zhi/">计算图与动态图机制</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/05/zhang-liang-cao-zuo-yu-xian-xing-hui-gui/">张量操作与线性回归</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/04/05/tensor-zhang-liang-jie-shao/">Tensor（张量）介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/13/triplet-loss-xue-xi/">triplet-loss学习</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-gui"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/GitHub%E5%AD%A6%E4%B9%A0/">GitHub学习</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Hexo%E5%AD%A6%E4%B9%A0/">Hexo学习</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Jupyter%E8%AF%AD%E6%B3%95/">Jupyter语法</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux%E5%AD%A6%E4%B9%A0/">Linux学习</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/OpenCV-Python%E6%89%8B%E8%AE%B0/">OpenCV-Python手记</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">Python学习笔记</a><span class="category-list-count">8</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/PyQt5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">PyQt5学习笔记</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Pytorch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">Pytorch学习笔记</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%86%E7%B1%BB%E6%8A%80%E6%9C%AF/">分类技术</a><span class="category-list-count">14</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%86%E7%B1%BB%E6%8A%80%E6%9C%AF/LBP%E5%AD%A6%E4%B9%A0/">LBP学习</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%86%E7%B1%BB%E6%8A%80%E6%9C%AF/SVM%E5%85%AB%E8%82%A1/">SVM八股</a><span class="category-list-count">10</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">图像处理学习笔记</a><span class="category-list-count">7</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%AB/">车牌识别</a><span class="category-list-count">7</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AE%9E%E9%AA%8C%E6%A5%BC%E5%AD%A6%E4%B9%A0/">实验楼学习</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9D%82%E9%A1%B9/">杂项</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">深度学习笔记</a><span class="category-list-count">7</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E8%B8%A9%E5%9D%91/">环境搭建踩坑</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%8B%B1%E8%AF%AD%E5%AD%A6%E4%B9%A0/">英语学习</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a><span class="category-list-count">9</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">论文学习笔记</a><span class="category-list-count">1</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"><a href="/tags/SVM/" style="font-size: 15px;">SVM</a> <a href="/tags/CLBP/" style="font-size: 15px;">CLBP</a> <a href="/tags/Hexo/" style="font-size: 15px;">Hexo</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">论文学习</a> <a href="/tags/vim/" style="font-size: 15px;">vim</a> <a href="/tags/OpenCV/" style="font-size: 15px;">OpenCV</a> <a href="/tags/PyQt5/" style="font-size: 15px;">PyQt5</a> <a href="/tags/GUI/" style="font-size: 15px;">GUI</a> <a href="/tags/%E8%AE%B0%E5%8D%95%E8%AF%8D/" style="font-size: 15px;">记单词</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a> <a href="/tags/TensorFlow/" style="font-size: 15px;">TensorFlow</a> <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" style="font-size: 15px;">损失函数</a> <a href="/tags/GitHub/" style="font-size: 15px;">GitHub</a> <a href="/tags/Resume/" style="font-size: 15px;">Resume</a> <a href="/tags/LBP/" style="font-size: 15px;">LBP</a> <a href="/tags/LPR/" style="font-size: 15px;">LPR</a> <a href="/tags/Numpy/" style="font-size: 15px;">Numpy</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/">2022</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/">2021</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/">2020</a><span class="archive-list-count">36</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/">2019</a><span class="archive-list-count">5</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-you"> 友情链接</i></div><ul></ul><a href="https://github.com/chaooo/hexo-theme-BlueLake" title="BlueLake主题" target="_blank">BlueLake主题</a><ul></ul><a href="https://mp.weixin.qq.com/s?__biz=MzIyNjM2MzQyNg==&amp;mid=2247484443&amp;idx=1&amp;sn=7110e42ef9e95a8c16064dde5b897960&amp;chksm=e870d556df075c4053a90d207c078e5fe965b5f9004de7f34dee09fccf1a37977aa3860b3a96&amp;mpshare=1&amp;scene=23&amp;srcid=0428XfRkvl0HsaHMU71k04dq#rd" title="重磅|完备的AI学习路线,最详细的资源整理！" target="_blank">重磅|完备的AI学习路线,最详细的资源整理！</a><ul></ul><a href="https://mp.weixin.qq.com/s?__biz=MzI5NDY1MjQzNA==&amp;mid=2247489096&amp;idx=1&amp;sn=ca2e1d72c9decd021c0365cc9e93a539&amp;chksm=ec5ec935db2940237482c5581b7a45f2bd50b138efa6488ed9b942c182486a4e74131e9af523&amp;mpshare=1&amp;scene=23&amp;srcid=#rd" title="推荐|机器学习入门方法和资料合集" target="_blank">推荐|机器学习入门方法和资料合集</a><ul></ul><a href="https://mp.weixin.qq.com/s?__biz=MzU4NTY4Mzg1Mw==&amp;mid=100000497&amp;idx=1&amp;sn=96cc795f1c22f7da2f3260d4ea364ff3&amp;chksm=7d8784134af00d05e41da36475bca417851535ed9710c7bd44ae7365cf40857015d922671c95&amp;mpshare=1&amp;scene=23&amp;srcid=04138MekLgFi3vNAz2E2rTrv#rd" title="良心推荐：机器学习入门资料汇总及学习建议（2018版）" target="_blank">良心推荐：机器学习入门资料汇总及学习建议（2018版）</a><ul></ul><a href="https://mp.weixin.qq.com/s?__biz=MzA3NDIyMjM1NA==&amp;mid=2649032678&amp;idx=1&amp;sn=7ce30241f24dae790f7361173132ee04&amp;chksm=8712b99bb065308d6626ac71d358d386199f5fdcc0d20f48b9ff7f7f84f32892325075413d78&amp;mpshare=1&amp;scene=1&amp;srcid=1213VnRvWgKRhAswA6qj9C6U&amp;sharer_sharetime=1607823235596&amp;sharer_shareid=6f3d2b6e1888cc6674af1cb9d8f856b5&amp;key=94e16379e8fc498f20603adf1c7c1474460f32c861df423924a01860bf66b23e3b54ec715f59513ed57f7be44b91602324165303caa8015279359147bf99dc0ac5c9482bbf323df6415707db1df1dbb44795972834805221b6810c0783bc61213b424afc1f9c747d8eddfe17782e3165ddfff5144eff7867ea82ee34ab2e6e44&amp;ascene=1&amp;uin=MzMyMzAzNzE5OA%3D%3D&amp;devicetype=Windows+10+x64&amp;version=6300002f&amp;lang=en&amp;exportkey=A%2Fn4vOWzACQbiXdS3ts1%2BmU%3D&amp;pass_ticket=X0sXcXVfthe9ne%2BkdsNidLJDaUos8pPBg0qSPgQJE8kY3CQmybx%2FB2TVL1w9Glu6&amp;wx_header=0" title="深度学习CV算法工程师从入门到初级面试" target="_blank">深度学习CV算法工程师从入门到初级面试</a></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">网站地图</a> |  <a href="/atom.xml">订阅本站</a> |  <a href="/about/">联系博主</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次，本站总访客数:<i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>人</p><p><span> Copyright &copy;<a href="/." rel="nofollow">贺同学.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a target="_blank" rel="noopener" href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.json.js?v=2.0.5"></script><div id="fullscreen-img" class="hide"><span class="close"></span></div><script type="text/javascript" src="/js/imgview.js?v=2.0.5" async></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.5" async></script><link rel="stylesheet" type="text/css" href="/share/css/share.css"><script type="text/javascript" src="/share/js/social-share.js" charset="utf-8"></script><script type="text/javascript" src="/share/js/qrcode.js" charset="utf-8"></script><script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":["mshare","weixin","tsina","qzone","linkedin","fbook","twi","print","renren","sqq","evernotecn","bdysc","tqq","tqf","bdxc","kaixin001","tieba","douban","bdhome","thx","ibaidu","meilishuo","mogujie","diandian","huaban","duitang","hx","fx","youdao","sdo","qingbiji","people","xinhua","mail","isohu","yaolan","wealink","ty","iguba","h163","copy"],"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"]}};with(document)0[(getElementsByTagName('head')[0]||head).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script></body></html>